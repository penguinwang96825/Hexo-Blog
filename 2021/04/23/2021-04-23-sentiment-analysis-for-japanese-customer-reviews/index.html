<!DOCTYPE HTML>
<html lang="en">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Sentiment Analysis for Japanese Customer Reviews, Yang&#39;s Blog">
    <meta name="description" content="CS Major / NLP Researcher / Tireless Coder">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Sentiment Analysis for Japanese Customer Reviews | Yang&#39;s Blog</title>
    <link rel="icon" type="image/png" href="/Yang-Tech-Blog/favicon.png">

    <link rel="stylesheet" type="text/css" href="/Yang-Tech-Blog/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/Yang-Tech-Blog/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/Yang-Tech-Blog/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/Yang-Tech-Blog/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/Yang-Tech-Blog/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/Yang-Tech-Blog/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/Yang-Tech-Blog/css/my.css">
    
    <script src="/Yang-Tech-Blog/libs/jquery/jquery.min.js"></script>

    <script src='http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default'>
    </script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [['$','$'], ['\\(','\\)']],
                displayMath: [['$$','$$'], ['\\[','\\]']],
                processEscapes: true,
                processEnvironments: true,
            }
        });
    </script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css">
    <script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js">
    </script>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.1"></head>




<body>
    
        <!--  加载动画，强制加载0.5s  -->
        <style type="text/css">
    #loading-container{
    position: fixed;
    top: 0;
    left: 0;
    min-height: 100vh;
    width: 100vw;
    z-index: 9999;
    display: flex;
    flex-direction: column;
    justify-content: center;
    align-items: center;
    background: #FFF;
    text-align: center;
    /* loader页面消失采用渐隐的方式*/
    -webkit-transition: opacity 1s ease;
    -moz-transition: opacity 1s ease;
    -o-transition: opacity 1s ease;
    transition: opacity 1s ease;
}
.loading-image{
    width: 120px;
    height: 50px;
    transform: translate(-50%);
}

.loading-image div:nth-child(2) {
    -webkit-animation: pacman-balls 1s linear 0s infinite;
    animation: pacman-balls 1s linear 0s infinite
}

.loading-image div:nth-child(3) {
    -webkit-animation: pacman-balls 1s linear .33s infinite;
    animation: pacman-balls 1s linear .33s infinite
}

.loading-image div:nth-child(4) {
    -webkit-animation: pacman-balls 1s linear .66s infinite;
    animation: pacman-balls 1s linear .66s infinite
}

.loading-image div:nth-child(5) {
    -webkit-animation: pacman-balls 1s linear .99s infinite;
    animation: pacman-balls 1s linear .99s infinite
}

.loading-image div:first-of-type {
    width: 0;
    height: 0;
    border: 25px solid #49b1f5;
    border-right-color: transparent;
    border-radius: 25px;
    -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
    animation: rotate_pacman_half_up .5s 0s infinite;
}
.loading-image div:nth-child(2) {
    width: 0;
    height: 0;
    border: 25px solid #49b1f5;
    border-right-color: transparent;
    border-radius: 25px;
    -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
    animation: rotate_pacman_half_down .5s 0s infinite;
    margin-top: -50px;
}
@-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

@keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

@-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

@keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

@-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

@keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


.loading-image div:nth-child(3),
.loading-image div:nth-child(4),
.loading-image div:nth-child(5),
.loading-image div:nth-child(6){
    background-color: #49b1f5;
    width: 15px;
    height: 15px;
    border-radius: 100%;
    margin: 2px;
    width: 10px;
    height: 10px;
    position: absolute;
    transform: translateY(-6.25px);
    top: 25px;
    left: 100px;
}
.loading-text{
    margin-bottom: 20vh;
    text-align: center;
    color: #2c3e50;
    font-size: 2rem;
    box-sizing: border-box;
    padding: 0 10px;
    text-shadow: 0 2px 10px rgba(0,0,0,0.2);
}
@media only screen and (max-width: 500px) {
    .loading-text{
        font-size: 1.5rem;
    }
}
.fadeout {
    opacity: 0;
    filter: alpha(opacity=0);
}
/* logo出现动画 */
@-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
@keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
</style>
<div id="loading-container">
    <p class="loading-text">Stealing pages from the server... </p>
    <div class="loading-image">
        <div></div>
        <div></div>
        <div></div>
        <div></div>
        <div></div>
        <div></div>
    </div>
</div>
<script>
    (function () {
        const loaded = function () {
            setTimeout(function () {
                const loader = document.getElementById("loading-container");
                loader.className = "fadeout";
                setTimeout(function () {
                    loader.style.display = "none";
                }, 500);
            }, 500);
        };
        loaded();
    })();
</script>
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Yang-Tech-Blog/" class="waves-effect waves-light">
                    
                    <img src="/Yang-Tech-Blog/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Yang&#39;s Blog</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Yang-Tech-Blog/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>Index</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Yang-Tech-Blog/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>Tags</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Yang-Tech-Blog/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>Categories</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Yang-Tech-Blog/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>Archives</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Yang-Tech-Blog/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>About</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Yang-Tech-Blog/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>Contact</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="" class="waves-effect waves-light">

      
      <i class="fas fa-list" style="zoom: 0.6;"></i>
      
      <span>Medias</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="/Yang-Tech-Blog/papers">
          
          <i class="fas fa-book" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Papers</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="Search" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Yang-Tech-Blog/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Yang&#39;s Blog</div>
        <div class="logo-desc">
            
            CS Major / NLP Researcher / Tireless Coder
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Yang-Tech-Blog/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			Index
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Yang-Tech-Blog/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			Tags
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Yang-Tech-Blog/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			Categories
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Yang-Tech-Blog/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			Archives
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Yang-Tech-Blog/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			About
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Yang-Tech-Blog/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			Contact
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-list"></i>
			
			Medias
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>

                  <a href="/Yang-Tech-Blog/papers " style="margin-left:75px">
				  
				   <i class="fa fas fa-book" style="position: absolute;left:50px" ></i>
			      
		          <span>Papers</span>
                  </a>
                </li>
              
            </ul>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/penguinwang96825" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/penguinwang96825" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    
<script src="/Yang-Tech-Blog/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('Please enter the password to access this article!')).toString(CryptoJS.enc.Hex)) {
                alert('Wrong password, will return to the home page!');
                location.href = '/Yang-Tech-Blog/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('https://github.com/penguinwang96825/penguinwang96825.github.io/blob/master/2021/04/23/2021-04-23-sentiment-analysis-for-japanese-customer-reviews/wallhaven-y8xlo7.jpg?raw=true')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Sentiment Analysis for Japanese Customer Reviews</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/Yang-Tech-Blog/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Yang-Tech-Blog/tags/Python/">
                                <span class="chip bg-color">Python</span>
                            </a>
                        
                            <a href="/Yang-Tech-Blog/tags/PyTorch/">
                                <span class="chip bg-color">PyTorch</span>
                            </a>
                        
                            <a href="/Yang-Tech-Blog/tags/Sentiment-Analysis/">
                                <span class="chip bg-color">Sentiment Analysis</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Yang-Tech-Blog/categories/NLP/" class="post-category">
                                NLP
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>Publish Date:&nbsp;&nbsp;
                    2021-04-23
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>Word Count:&nbsp;&nbsp;
                    5.3k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>Read Times:&nbsp;&nbsp;
                    32 Min
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>Read Count:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/Yang-Tech-Blog/libs/prism/prism.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <link rel="stylesheet" type="text&#x2F;css" href="https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css"><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>The development of elec-tronic business is accelerated by the popularity of the internet. Millions of people buy products and post their reviews online. Public opinion analysis can be used with these reviews. Customers can make better decisions after reading other people’s product reviews. There is a pressing need for building the system which can perform the sentiment classification job. In this article, I’ll try to build a sentiment anaylsis model for Japanese customer reviews. </p>
<h1 id="Data"><a href="#Data" class="headerlink" title="Data"></a>Data</h1><p>The dataset can be download from Darkmap’s GitHub <a target="_blank" rel="noopener" href="https://github.com/Darkmap/japanese_sentiment">here</a>. The dataset used in this project consists of 20K reviews of commodities in various categories from Amazon Japan. The annotating is based on the rating of the reviews, since the scale of the corpus is too large for manual annotation. Reviews with rating 1 and 2 are considered negative while those with rating 4 and 5 are annotated as positive ones.</p>
<h2 id="Import-the-Libraries"><a href="#Import-the-Libraries" class="headerlink" title="Import the Libraries"></a>Import the Libraries</h2><p>We will use SpaCy as our tokeniser, and use PyTorch to build the model.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requests
<span class="token keyword">import</span> spacy
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> seaborn <span class="token keyword">as</span> sns
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm
<span class="token keyword">from</span> collections <span class="token keyword">import</span> Counter
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> metrics
ja <span class="token operator">=</span> spacy<span class="token punctuation">.</span>blank<span class="token punctuation">(</span><span class="token string">'ja'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset<span class="token punctuation">,</span> DataLoader<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="Load-the-Data"><a href="#Load-the-Data" class="headerlink" title="Load the Data"></a>Load the Data</h2><p>Utilise <code>requests</code> library to get the data.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">positive_url <span class="token operator">=</span> <span class="token string">"https://raw.githubusercontent.com/Darkmap/japanese_sentiment/master/data/10000positive.txt"</span>
negative_url <span class="token operator">=</span> <span class="token string">"https://raw.githubusercontent.com/Darkmap/japanese_sentiment/master/data/10000negative.txt"</span>
positive_res <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>positive_url<span class="token punctuation">)</span>
negative_res <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>negative_url<span class="token punctuation">)</span>
positive_data <span class="token operator">=</span> positive_res<span class="token punctuation">.</span>text
negative_data <span class="token operator">=</span> negative_res<span class="token punctuation">.</span>text<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>The size for both positive and negative reviews are 10000.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">positive_list <span class="token operator">=</span> positive_data<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">)</span>
positive_list <span class="token operator">=</span> positive_list<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">10000</span><span class="token punctuation">]</span>

negative_list <span class="token operator">=</span> negative_data<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">)</span>
negative_list <span class="token operator">=</span> negative_list<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">10000</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h1 id="Text-Pre-processing"><a href="#Text-Pre-processing" class="headerlink" title="Text Pre-processing"></a>Text Pre-processing</h1><p>Before text was used as an input through the model, it’s necessary to convert the tokenised input data into an appropriate format so that each sentence can be sent to the model to obtain the corresponding embedding. This article introduces how text pre-processing can be done step by step.</p>
<h2 id="Tokenisation"><a href="#Tokenisation" class="headerlink" title="Tokenisation"></a>Tokenisation</h2><p>SpaCy’s trained pipelines can be installed as Python packages. SpaCy also provides support for vast languages including Japanese. You can take a look at the <a target="_blank" rel="noopener" href="https://spacy.io/usage/models">documentation</a> for different language models. </p>
<p>There’s also another option to tokenise the Japanese sentence. <a target="_blank" rel="noopener" href="http://mecab.sourceforge.net/">MeCab</a> is a Japanese word segmentation system developed by Taku Kudo of Nara Institute of Science and Technology. The basic approach of the design is to use Conditional Random Fields (CRF) models for parameter estimation without relying on specific languages, dictionaries, and corpora. Furthermore. Furthermore, the average parsing speed is higher than those of ChaSen, Juman, KAKASI and other Japanese lexical parsers. By the way, MeCab (めかぶ) is the author’s favorite food.</p>
<p>The first hurdle in analysing Japanese text is tokenisation. You can separate all the word boundaries of the European languages and English. Japanese, however, has no spaces in its text, so there’s an extra pre-processing step required before we can start using these text analysis approaches. In essence, we want to turn a string like this: </p>
<blockquote>
<p>“今日はいい天気ですね。遊びに行かない？新宿で祭りがある！”</p>
</blockquote>
<p>into an list like this:</p>
<blockquote>
<p>[“今日”,　“は”,　“いい”,　“天気”,　“です”,　“ね”,　“遊び”,　“に”,　“行か”,　“ない”,　“新宿”,　“で”,　“祭り”,　“が”,　“ある”]</p>
</blockquote>
<p>The next step is to get SpaCy talking to Python. Try the following code:</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">positive_tokenised<span class="token punctuation">,</span> positive_part_of_speech <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> doc <span class="token keyword">in</span> positive_list<span class="token punctuation">:</span>
    temp_word<span class="token punctuation">,</span> temp_pos <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> word <span class="token keyword">in</span> ja<span class="token punctuation">(</span>doc<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        temp_word<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">)</span>
        temp_pos<span class="token punctuation">.</span>append<span class="token punctuation">(</span>word<span class="token punctuation">.</span>pos_<span class="token punctuation">)</span>
    positive_tokenised<span class="token punctuation">.</span>append<span class="token punctuation">(</span>temp_word<span class="token punctuation">)</span>
    positive_part_of_speech<span class="token punctuation">.</span>append<span class="token punctuation">(</span>temp_pos<span class="token punctuation">)</span>
    
negative_tokenised<span class="token punctuation">,</span> negative_part_of_speech <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> doc <span class="token keyword">in</span> negative_list<span class="token punctuation">:</span>
    temp_word<span class="token punctuation">,</span> temp_pos <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> word <span class="token keyword">in</span> ja<span class="token punctuation">(</span>doc<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        temp_word<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">)</span>
        temp_pos<span class="token punctuation">.</span>append<span class="token punctuation">(</span>word<span class="token punctuation">.</span>pos_<span class="token punctuation">)</span>
    negative_tokenised<span class="token punctuation">.</span>append<span class="token punctuation">(</span>temp_word<span class="token punctuation">)</span>
    negative_part_of_speech<span class="token punctuation">.</span>append<span class="token punctuation">(</span>temp_pos<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>Here in my experiment, I am trying to add more features in the model, so you can see that I also extract the part-of-speech tagging in the above code chunk. Later when building the model, I will employ some different features including part-of-speech tag (POS tag). The POS tag feature share the same characteristics as the word embedding feature. It has time series information and needs to be processed over time per-token.</p>
<h2 id="Extract-N-Grams"><a href="#Extract-N-Grams" class="headerlink" title="Extract N-Grams"></a>Extract N-Grams</h2><p>After tokenise all the sentences in the documents, next step is to extract all n-grams. First, I’ll implement the <code>extract_ngrams()</code> function. It takes as input: </p>
<ul>
<li><strong>x_raw</strong>: a string corresponding to the raw text of a document.</li>
<li><strong>ngram_range</strong>: a tuple of two integers denoting the type of n-grams you want to extract, e.g. (1, 2) denotes extracting unigrams and bigrams.</li>
<li><strong>stop_words</strong>: a list of stop words.</li>
<li><strong>vocab</strong>: a given vocabulary. It should be used to extract specific features.</li>
</ul>
<p>and returns a list of all extracted features.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">extract_ngrams</span><span class="token punctuation">(</span>x_raw<span class="token punctuation">,</span> 
                   ngram_range<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
                   stop_words<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
                   vocab<span class="token operator">=</span><span class="token builtin">set</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token comment"># First extract all unigrams by tokenising</span>
    x_uni <span class="token operator">=</span> <span class="token punctuation">[</span>w <span class="token keyword">for</span> w <span class="token keyword">in</span> x_raw<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> w <span class="token keyword">not</span> <span class="token keyword">in</span> stop_words<span class="token punctuation">]</span>
    
    <span class="token comment"># This is to store the ngrams to be returned</span>
    x <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    
    <span class="token keyword">if</span> ngram_range<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">==</span><span class="token number">1</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> x_uni

    <span class="token comment"># Generate n-grams from the available unigrams x_uni</span>
    ngrams <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> n <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>ngram_range<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ngram_range<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token comment"># Ignore unigrams</span>
        <span class="token keyword">if</span> n<span class="token operator">==</span><span class="token number">1</span><span class="token punctuation">:</span> <span class="token keyword">continue</span>

        <span class="token comment"># Pass a list of lists as an argument for zip</span>
        arg_list <span class="token operator">=</span> <span class="token punctuation">[</span>x_uni<span class="token punctuation">]</span><span class="token operator">+</span><span class="token punctuation">[</span>x_uni<span class="token punctuation">[</span>i<span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">]</span>

        <span class="token comment"># Extract tuples of n-grams using zip</span>
        x_ngram <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span><span class="token operator">*</span>arg_list<span class="token punctuation">)</span><span class="token punctuation">)</span>
        ngrams<span class="token punctuation">.</span>append<span class="token punctuation">(</span>x_ngram<span class="token punctuation">)</span>

    <span class="token keyword">for</span> n <span class="token keyword">in</span> ngrams<span class="token punctuation">:</span>
        <span class="token keyword">for</span> t <span class="token keyword">in</span> n<span class="token punctuation">:</span>
            x<span class="token punctuation">.</span>append<span class="token punctuation">(</span>t<span class="token punctuation">)</span>

    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span><span class="token operator">></span><span class="token number">0</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> <span class="token punctuation">[</span>w <span class="token keyword">for</span> w <span class="token keyword">in</span> x <span class="token keyword">if</span> w <span class="token keyword">in</span> vocab<span class="token punctuation">]</span>
        
    <span class="token keyword">return</span> x<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="Create-Vocabulary-of-N-Grams-and-POS-Tag"><a href="#Create-Vocabulary-of-N-Grams-and-POS-Tag" class="headerlink" title="Create Vocabulary of N-Grams and POS Tag"></a>Create Vocabulary of N-Grams and POS Tag</h2><p>Then the <code>get_vocab()</code> function will be used to (1) create a vocabulary of ngrams; (2) count the document frequencies of ngrams; (3) their raw frequency. It takes as input:</p>
<ul>
<li><strong>X_raw</strong>: a list of strings each corresponding to the raw text of a document.</li>
<li><strong>ngram_range</strong>: a tuple of two integers denoting the type of n-grams you want to extract, e.g. (1, 2) denotes extracting unigrams and bigrams.</li>
<li><strong>min_df</strong>: keep n-grams with a minimum document frequency.</li>
<li><strong>keep_topN</strong>: keep top-N more frequent n-grams.</li>
<li><strong>stop_words</strong>: a list of stop words.</li>
</ul>
<p>and returns:</p>
<ul>
<li><strong>vocab</strong>: a set of the n-grams that will be used as features.</li>
<li><strong>df</strong>: a Counter (or dict) that contains n-grams as keys and their corresponding document frequency as values.</li>
<li><strong>ngram_counts</strong>: counts of each n-gram in vocab.</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_vocab</span><span class="token punctuation">(</span>X_raw<span class="token punctuation">,</span> 
              ngram_range<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
              min_df<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> 
              keep_topN<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> 
              stop_words<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    df <span class="token operator">=</span> Counter<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ngram_counts <span class="token operator">=</span> Counter<span class="token punctuation">(</span><span class="token punctuation">)</span>
    vocab <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    <span class="token comment"># Iterate through each raw text</span>
    <span class="token keyword">for</span> x <span class="token keyword">in</span> X_raw<span class="token punctuation">:</span>
        
        x_ngram <span class="token operator">=</span> extract_ngrams<span class="token punctuation">(</span>x<span class="token punctuation">,</span> 
                                 ngram_range<span class="token operator">=</span>ngram_range<span class="token punctuation">,</span> 
                                 stop_words<span class="token operator">=</span>stop_words<span class="token punctuation">)</span>
        
        <span class="token comment"># Update doc and ngram frequencies </span>
        df<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">set</span><span class="token punctuation">(</span>x_ngram<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        ngram_counts<span class="token punctuation">.</span>update<span class="token punctuation">(</span>x_ngram<span class="token punctuation">)</span>

    <span class="token comment"># Obtain a vocabulary as a set. </span>
    <span class="token comment"># Keep elements with doc frequency > minimum doc freq (min_df)</span>
    <span class="token comment"># Note that df contains all te</span>
    vocab <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span><span class="token punctuation">[</span>w <span class="token keyword">for</span> w <span class="token keyword">in</span> df <span class="token keyword">if</span> df<span class="token punctuation">[</span>w<span class="token punctuation">]</span><span class="token operator">>=</span>min_df<span class="token punctuation">]</span><span class="token punctuation">)</span>
    
    <span class="token comment"># Keep the top N most freqent </span>
    <span class="token keyword">if</span> keep_topN <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>
        vocab <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span><span class="token punctuation">[</span>w<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> w <span class="token keyword">in</span> ngram_counts<span class="token punctuation">.</span>most_common<span class="token punctuation">(</span>keep_topN<span class="token punctuation">)</span> 
                     <span class="token keyword">if</span> w<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">in</span> vocab<span class="token punctuation">]</span><span class="token punctuation">)</span>
    
    <span class="token keyword">return</span> vocab<span class="token punctuation">,</span> df<span class="token punctuation">,</span> ngram_counts<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>Now we could use <code>get_vocab()</code> to create the vocabulary and get document and raw frequencies of n-grams:</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Create vocab for documents</span>
positive_doc <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">" "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>doc<span class="token punctuation">)</span> <span class="token keyword">for</span> doc <span class="token keyword">in</span> positive_tokenised<span class="token punctuation">]</span>
negative_doc <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">" "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>doc<span class="token punctuation">)</span> <span class="token keyword">for</span> doc <span class="token keyword">in</span> negative_tokenised<span class="token punctuation">]</span>
vocab<span class="token punctuation">,</span> df<span class="token punctuation">,</span> ngram_counts <span class="token operator">=</span> get_vocab<span class="token punctuation">(</span>positive_doc<span class="token operator">+</span>negative_doc<span class="token punctuation">,</span> 
                                    ngram_range<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
                                    min_df<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> 
                                    keep_topN<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> 
                                    stop_words<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># Create vocab for pos tag</span>
positive_doc_pos <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">" "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>doc<span class="token punctuation">)</span> <span class="token keyword">for</span> doc <span class="token keyword">in</span> positive_part_of_speech<span class="token punctuation">]</span>
negative_doc_pos <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">" "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>doc<span class="token punctuation">)</span> <span class="token keyword">for</span> doc <span class="token keyword">in</span> negative_part_of_speech<span class="token punctuation">]</span>
pos_vocab<span class="token punctuation">,</span> _<span class="token punctuation">,</span> _ <span class="token operator">=</span> get_vocab<span class="token punctuation">(</span>positive_doc_pos<span class="token operator">+</span>negative_doc_pos<span class="token punctuation">,</span> 
                            ngram_range<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
                            min_df<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> 
                            keep_topN<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> 
                            stop_words<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>The sizes of the vocabulary are 18347 and 17 of documents and pos tagging, respectively. </p>
<p>Then, you need to create vocabulary idx2word, word2idx, idx2pos, and pos2idx dictionaries for reference:</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">idx2word <span class="token operator">=</span> <span class="token punctuation">&#123;</span>k<span class="token operator">+</span><span class="token number">4</span><span class="token punctuation">:</span>v <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span><span class="token punctuation">&#125;</span>
idx2word<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"&lt;PAD>"</span>
idx2word<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"&lt;CLS>"</span>
idx2word<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"&lt;EOS>"</span>
idx2word<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"&lt;UNK>"</span>
word2idx <span class="token operator">=</span> <span class="token punctuation">&#123;</span>v<span class="token punctuation">:</span>k <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> idx2word<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span>

idx2pos <span class="token operator">=</span> <span class="token punctuation">&#123;</span>k<span class="token punctuation">:</span>v <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>pos_vocab<span class="token punctuation">)</span><span class="token punctuation">&#125;</span>
pos2idx <span class="token operator">=</span> <span class="token punctuation">&#123;</span>v<span class="token punctuation">:</span>k <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> idx2pos<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>where the first four tokens in idx2word represent:</p>
<ul>
<li><code>&lt;PAD&gt;</code>: your GPU (or CPU at worst) processes your training data in batches and all the sequences in your batch should have the same length. If the max length of your sequence is 8, your sentence <strong>You had me at hello</strong> will be padded from either side to fit this length: <strong>You had me at hello <PAD> <PAD> <PAD></strong></li>
<li><code>&lt;CLS&gt;</code>: CLS stands for “classification” and its there to represent sentence-level classification.</li>
<li><code>&lt;EOS&gt;</code>: EOS stands for “end of sentence”.</li>
<li><code>&lt;UNK&gt;</code>: UNK stands for “unknown token”, and is used to replace the rare words that did not fit in your vocabulary. So your sentence <strong>She suffered an extreme case of Kakorrhaphiophobia</strong> will be translated into <strong>She suffered an extreme case of <UNK></strong>.</li>
</ul>
<h2 id="Split-the-Dataset"><a href="#Split-the-Dataset" class="headerlink" title="Split the Dataset"></a>Split the Dataset</h2><p>The hold-out method is the simplest kind of cross validation. Hold-out is when you split up your dataset into several parts. In order to train and validate a model, you must first partition your dataset, which involves choosing what percentage of your data to use for the training, validation, and holdout sets.</p>
<p><strong>What is a Training Set?</strong></p>
<p>A training set is the subsection of a dataset from which the machine learning algorithm uncovers, or “learns”” relationships between the features and the target variable. In supervised machine learning, training data is labeled with known outcomes.</p>
<p><strong>What is a Validation Set?</strong></p>
<p>A validation set is another subset of the input data to which we apply the machine learning algorithm to see how accurately it identifies relationships between the known outcomes for the target variable and the dataset’s other features.</p>
<p><strong>What is a Holdout Set?</strong></p>
<p>Sometimes referred to as “testing” data, a holdout subset provides a final estimate of the machine learning model’s performance after it has been trained and validated. Holdout sets should never be used to make decisions about which algorithms to use or for improving or tuning algorithms.</p>
<h3 id="Hold-out-Validation-vs-Cross-Validation"><a href="#Hold-out-Validation-vs-Cross-Validation" class="headerlink" title="Hold-out Validation vs. Cross-Validation"></a>Hold-out Validation vs. Cross-Validation</h3><p>By the way, Andrew Ng mentioned in the CS229 class at University of Stanford regarding cross-validation. These are the practices that he follow in his own work. Let <em>m</em> be the number of samples in your dataset.</p>
<ol>
<li>If <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.312ex" xmlns="http://www.w3.org/2000/svg" width="7.266ex" height="1.819ex" role="img" focusable="false" viewBox="0 -666 3211.6 804" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-21-TEX-I-1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-21-TEX-N-2264" d="M674 636Q682 636 688 630T694 615T687 601Q686 600 417 472L151 346L399 228Q687 92 691 87Q694 81 694 76Q694 58 676 56H670L382 192Q92 329 90 331Q83 336 83 348Q84 359 96 365Q104 369 382 500T665 634Q669 636 674 636ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path><path id="MJX-21-TEX-N-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path id="MJX-21-TEX-N-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><use xlink:href="#MJX-21-TEX-I-1D45A"></use></g><g data-mml-node="mo" transform="translate(1155.8, 0)"><use xlink:href="#MJX-21-TEX-N-2264"></use></g><g data-mml-node="mn" transform="translate(2211.6, 0)"><use xlink:href="#MJX-21-TEX-N-32"></use><use xlink:href="#MJX-21-TEX-N-30" transform="translate(500, 0)"></use></g></g></g></svg></mjx-container>, then use Leave-one-out cross-validation.</li>
<li>If <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.312ex" xmlns="http://www.w3.org/2000/svg" width="13.677ex" height="1.819ex" role="img" focusable="false" viewBox="0 -666 6045.1 804" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-20-TEX-N-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path id="MJX-20-TEX-N-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path id="MJX-20-TEX-N-3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"></path><path id="MJX-20-TEX-I-1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-20-TEX-N-2264" d="M674 636Q682 636 688 630T694 615T687 601Q686 600 417 472L151 346L399 228Q687 92 691 87Q694 81 694 76Q694 58 676 56H670L382 192Q92 329 90 331Q83 336 83 348Q84 359 96 365Q104 369 382 500T665 634Q669 636 674 636ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path><path id="MJX-20-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mn"><use xlink:href="#MJX-20-TEX-N-32"></use><use xlink:href="#MJX-20-TEX-N-30" transform="translate(500, 0)"></use></g><g data-mml-node="mo" transform="translate(1277.8, 0)"><use xlink:href="#MJX-20-TEX-N-3C"></use></g><g data-mml-node="mi" transform="translate(2333.6, 0)"><use xlink:href="#MJX-20-TEX-I-1D45A"></use></g><g data-mml-node="mo" transform="translate(3489.3, 0)"><use xlink:href="#MJX-20-TEX-N-2264"></use></g><g data-mml-node="mn" transform="translate(4545.1, 0)"><use xlink:href="#MJX-20-TEX-N-31"></use><use xlink:href="#MJX-20-TEX-N-30" transform="translate(500, 0)"></use><use xlink:href="#MJX-20-TEX-N-30" transform="translate(1000, 0)"></use></g></g></g></svg></mjx-container>, then use k-fold cross-validation with a relatively large <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.312ex" xmlns="http://www.w3.org/2000/svg" width="6.182ex" height="1.882ex" role="img" focusable="false" viewBox="0 -694 2732.6 832" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-19-TEX-I-1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path><path id="MJX-19-TEX-N-2264" d="M674 636Q682 636 688 630T694 615T687 601Q686 600 417 472L151 346L399 228Q687 92 691 87Q694 81 694 76Q694 58 676 56H670L382 192Q92 329 90 331Q83 336 83 348Q84 359 96 365Q104 369 382 500T665 634Q669 636 674 636ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path><path id="MJX-19-TEX-I-1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><use xlink:href="#MJX-19-TEX-I-1D458"></use></g><g data-mml-node="mo" transform="translate(798.8, 0)"><use xlink:href="#MJX-19-TEX-N-2264"></use></g><g data-mml-node="mi" transform="translate(1854.6, 0)"><use xlink:href="#MJX-19-TEX-I-1D45A"></use></g></g></g></svg></mjx-container></li>
<li>If <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.312ex" xmlns="http://www.w3.org/2000/svg" width="19.333ex" height="1.819ex" role="img" focusable="false" viewBox="0 -666 8545.1 804" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-19-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJX-19-TEX-N-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path id="MJX-19-TEX-N-3C" d="M694 -11T694 -19T688 -33T678 -40Q671 -40 524 29T234 166L90 235Q83 240 83 250Q83 261 91 266Q664 540 678 540Q681 540 687 534T694 519T687 505Q686 504 417 376L151 250L417 124Q686 -4 687 -5Q694 -11 694 -19Z"></path><path id="MJX-19-TEX-I-1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-19-TEX-N-2264" d="M674 636Q682 636 688 630T694 615T687 601Q686 600 417 472L151 346L399 228Q687 92 691 87Q694 81 694 76Q694 58 676 56H670L382 192Q92 329 90 331Q83 336 83 348Q84 359 96 365Q104 369 382 500T665 634Q669 636 674 636ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mn"><use xlink:href="#MJX-19-TEX-N-31"></use><use xlink:href="#MJX-19-TEX-N-30" transform="translate(500, 0)"></use><use xlink:href="#MJX-19-TEX-N-30" transform="translate(1000, 0)"></use></g><g data-mml-node="mo" transform="translate(1777.8, 0)"><use xlink:href="#MJX-19-TEX-N-3C"></use></g><g data-mml-node="mi" transform="translate(2833.6, 0)"><use xlink:href="#MJX-19-TEX-I-1D45A"></use></g><g data-mml-node="mo" transform="translate(3989.3, 0)"><use xlink:href="#MJX-19-TEX-N-2264"></use></g><g data-mml-node="mn" transform="translate(5045.1, 0)"><use xlink:href="#MJX-19-TEX-N-31"></use><use xlink:href="#MJX-19-TEX-N-30" transform="translate(500, 0)"></use><use xlink:href="#MJX-19-TEX-N-30" transform="translate(1000, 0)"></use><use xlink:href="#MJX-19-TEX-N-30" transform="translate(1500, 0)"></use><use xlink:href="#MJX-19-TEX-N-30" transform="translate(2000, 0)"></use><use xlink:href="#MJX-19-TEX-N-30" transform="translate(2500, 0)"></use><use xlink:href="#MJX-19-TEX-N-30" transform="translate(3000, 0)"></use></g></g></g></svg></mjx-container>, then use regular k-fold cross-validation (<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex" xmlns="http://www.w3.org/2000/svg" width="5.327ex" height="1.756ex" role="img" focusable="false" viewBox="0 -694 2354.6 776" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-18-TEX-I-1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path><path id="MJX-18-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-18-TEX-N-35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><use xlink:href="#MJX-18-TEX-I-1D458"></use></g><g data-mml-node="mo" transform="translate(798.8, 0)"><use xlink:href="#MJX-18-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(1854.6, 0)"><use xlink:href="#MJX-18-TEX-N-35"></use></g></g></g></svg></mjx-container>). Or, if there is not enough computational power and <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.09ex" xmlns="http://www.w3.org/2000/svg" width="10.66ex" height="1.597ex" role="img" focusable="false" viewBox="0 -666 4711.6 706" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-18-TEX-I-1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-18-TEX-N-3E" d="M84 520Q84 528 88 533T96 539L99 540Q106 540 253 471T544 334L687 265Q694 260 694 250T687 235Q685 233 395 96L107 -40H101Q83 -38 83 -20Q83 -19 83 -17Q82 -10 98 -1Q117 9 248 71Q326 108 378 132L626 250L378 368Q90 504 86 509Q84 513 84 520Z"></path><path id="MJX-18-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJX-18-TEX-N-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><use xlink:href="#MJX-18-TEX-I-1D45A"></use></g><g data-mml-node="mo" transform="translate(1155.8, 0)"><use xlink:href="#MJX-18-TEX-N-3E"></use></g><g data-mml-node="mn" transform="translate(2211.6, 0)"><use xlink:href="#MJX-18-TEX-N-31"></use><use xlink:href="#MJX-18-TEX-N-30" transform="translate(500, 0)"></use><use xlink:href="#MJX-18-TEX-N-30" transform="translate(1000, 0)"></use><use xlink:href="#MJX-18-TEX-N-30" transform="translate(1500, 0)"></use><use xlink:href="#MJX-18-TEX-N-30" transform="translate(2000, 0)"></use></g></g></g></svg></mjx-container>, then use hold-out cross-validation.</li>
<li>If <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.312ex" xmlns="http://www.w3.org/2000/svg" width="12.922ex" height="1.819ex" role="img" focusable="false" viewBox="0 -666 5711.6 804" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-18-TEX-I-1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path id="MJX-18-TEX-N-2265" d="M83 616Q83 624 89 630T99 636Q107 636 253 568T543 431T687 361Q694 356 694 346T687 331Q685 329 395 192L107 56H101Q83 58 83 76Q83 77 83 79Q82 86 98 95Q117 105 248 167Q326 204 378 228L626 346L360 472Q291 505 200 548Q112 589 98 597T83 616ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path><path id="MJX-18-TEX-N-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path id="MJX-18-TEX-N-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><use xlink:href="#MJX-18-TEX-I-1D45A"></use></g><g data-mml-node="mo" transform="translate(1155.8, 0)"><use xlink:href="#MJX-18-TEX-N-2265"></use></g><g data-mml-node="mn" transform="translate(2211.6, 0)"><use xlink:href="#MJX-18-TEX-N-31"></use><use xlink:href="#MJX-18-TEX-N-30" transform="translate(500, 0)"></use><use xlink:href="#MJX-18-TEX-N-30" transform="translate(1000, 0)"></use><use xlink:href="#MJX-18-TEX-N-30" transform="translate(1500, 0)"></use><use xlink:href="#MJX-18-TEX-N-30" transform="translate(2000, 0)"></use><use xlink:href="#MJX-18-TEX-N-30" transform="translate(2500, 0)"></use><use xlink:href="#MJX-18-TEX-N-30" transform="translate(3000, 0)"></use></g></g></g></svg></mjx-container>, then use hold-out validation. But if computational power is available you can use k-fold cross-validation (<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.186ex" xmlns="http://www.w3.org/2000/svg" width="5.327ex" height="1.756ex" role="img" focusable="false" viewBox="0 -694 2354.6 776" xmlns:xlink="http://www.w3.org/1999/xlink"><defs><path id="MJX-17-TEX-I-1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path><path id="MJX-17-TEX-N-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path id="MJX-17-TEX-N-35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g data-mml-node="math"><g data-mml-node="mi"><use xlink:href="#MJX-17-TEX-I-1D458"></use></g><g data-mml-node="mo" transform="translate(798.8, 0)"><use xlink:href="#MJX-17-TEX-N-3D"></use></g><g data-mml-node="mn" transform="translate(1854.6, 0)"><use xlink:href="#MJX-17-TEX-N-35"></use></g></g></g></svg></mjx-container>) if you want to squeeze that extra performance out of your model.</li>
</ol>
<p>In this project, I have 20000 of samples in total, so I’ll just use basic hold-out validation. 16000 of samples for training dataset, 2000 for validation dataset, and 2000 for testing dataset.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">train_documents <span class="token operator">=</span> positive_doc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">8000</span><span class="token punctuation">]</span> <span class="token operator">+</span> negative_doc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">8000</span><span class="token punctuation">]</span>
valid_documents <span class="token operator">=</span> positive_doc<span class="token punctuation">[</span><span class="token number">8000</span><span class="token punctuation">:</span><span class="token number">9000</span><span class="token punctuation">]</span> <span class="token operator">+</span> negative_doc<span class="token punctuation">[</span><span class="token number">8000</span><span class="token punctuation">:</span><span class="token number">9000</span><span class="token punctuation">]</span>
test_documents <span class="token operator">=</span> positive_doc<span class="token punctuation">[</span><span class="token number">9000</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">+</span> negative_doc<span class="token punctuation">[</span><span class="token number">9000</span><span class="token punctuation">:</span><span class="token punctuation">]</span>

train_pos <span class="token operator">=</span> positive_doc_pos<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">8000</span><span class="token punctuation">]</span> <span class="token operator">+</span> negative_doc_pos<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">8000</span><span class="token punctuation">]</span>
valid_pos <span class="token operator">=</span> positive_doc_pos<span class="token punctuation">[</span><span class="token number">8000</span><span class="token punctuation">:</span><span class="token number">9000</span><span class="token punctuation">]</span> <span class="token operator">+</span> negative_doc_pos<span class="token punctuation">[</span><span class="token number">8000</span><span class="token punctuation">:</span><span class="token number">9000</span><span class="token punctuation">]</span>
test_pos <span class="token operator">=</span> positive_doc_pos<span class="token punctuation">[</span><span class="token number">9000</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">+</span> negative_doc_pos<span class="token punctuation">[</span><span class="token number">9000</span><span class="token punctuation">:</span><span class="token punctuation">]</span>

train_label <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">*</span><span class="token number">8000</span> <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">*</span><span class="token number">8000</span>
valid_label <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">*</span><span class="token number">1000</span> <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">*</span><span class="token number">1000</span>
test_label <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">*</span><span class="token number">1000</span> <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">*</span><span class="token number">1000</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="Convert-the-List-of-Unigrams-into-a-List-of-Vocab-Indices"><a href="#Convert-the-List-of-Unigrams-into-a-List-of-Vocab-Indices" class="headerlink" title="Convert the List of Unigrams into a List of Vocab Indices"></a>Convert the List of Unigrams into a List of Vocab Indices</h2><p>Storing actual one-hot vectors into memory for all words in the entire data set is prohibitive.Instead, we will store word indices in the vocabulary and look-up the weight matrix. This isequivalent of doing a dot product between an one-hot vector and the weight matrix.</p>
<p>First, represent documents in train, dev and test sets as lists of words in the vocabulary:</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">train_idx_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>word2idx<span class="token punctuation">.</span>get<span class="token punctuation">(</span>token<span class="token punctuation">)</span> <span class="token keyword">for</span> token <span class="token keyword">in</span> extract_ngrams<span class="token punctuation">(</span>
    doc<span class="token punctuation">,</span> 
    ngram_range<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
    stop_words<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
    vocab<span class="token operator">=</span>vocab<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">for</span> doc <span class="token keyword">in</span> train_documents<span class="token punctuation">]</span>

valid_idx_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>word2idx<span class="token punctuation">.</span>get<span class="token punctuation">(</span>token<span class="token punctuation">)</span> <span class="token keyword">for</span> token <span class="token keyword">in</span> extract_ngrams<span class="token punctuation">(</span>
    doc<span class="token punctuation">,</span> 
    ngram_range<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
    stop_words<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
    vocab<span class="token operator">=</span>vocab<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">for</span> doc <span class="token keyword">in</span> valid_documents<span class="token punctuation">]</span>

test_idx_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>word2idx<span class="token punctuation">.</span>get<span class="token punctuation">(</span>token<span class="token punctuation">)</span> <span class="token keyword">for</span> token <span class="token keyword">in</span> extract_ngrams<span class="token punctuation">(</span>
    doc<span class="token punctuation">,</span> 
    ngram_range<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
    stop_words<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
    vocab<span class="token operator">=</span>vocab<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">for</span> doc <span class="token keyword">in</span> test_documents<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>Second, represent POS tag in train, dev, and test sets as lists of tags in the POS vocabulary.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">train_pos_idx_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>pos2idx<span class="token punctuation">.</span>get<span class="token punctuation">(</span>pos<span class="token punctuation">)</span> <span class="token keyword">for</span> pos <span class="token keyword">in</span> extract_ngrams<span class="token punctuation">(</span>
    doc<span class="token punctuation">,</span> 
    ngram_range<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
    stop_words<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
    vocab<span class="token operator">=</span>pos_vocab<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">for</span> doc <span class="token keyword">in</span> train_pos<span class="token punctuation">]</span>

valid_pos_idx_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>pos2idx<span class="token punctuation">.</span>get<span class="token punctuation">(</span>pos<span class="token punctuation">)</span> <span class="token keyword">for</span> pos <span class="token keyword">in</span> extract_ngrams<span class="token punctuation">(</span>
    doc<span class="token punctuation">,</span> 
    ngram_range<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
    stop_words<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
    vocab<span class="token operator">=</span>pos_vocab<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">for</span> doc <span class="token keyword">in</span> valid_pos<span class="token punctuation">]</span>

test_pos_idx_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>pos2idx<span class="token punctuation">.</span>get<span class="token punctuation">(</span>pos<span class="token punctuation">)</span> <span class="token keyword">for</span> pos <span class="token keyword">in</span> extract_ngrams<span class="token punctuation">(</span>
    doc<span class="token punctuation">,</span> 
    ngram_range<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
    stop_words<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
    vocab<span class="token operator">=</span>pos_vocab<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">for</span> doc <span class="token keyword">in</span> test_pos<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="Seqeunce-Padding"><a href="#Seqeunce-Padding" class="headerlink" title="Seqeunce Padding"></a>Seqeunce Padding</h2><p>Padding comes from the need to encode sequence data into contiguous batches: in order to make all sequences in a batch fit a given standard length, it is necessary to pad or truncate some sequences. The function <code>pad_sequence()</code> pads sequences to the same length.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">pad_sequence</span><span class="token punctuation">(</span>sequences<span class="token punctuation">,</span> max_len<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> max_len <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        max_ <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token builtin">len</span><span class="token punctuation">(</span>seq<span class="token punctuation">)</span> <span class="token keyword">for</span> seq <span class="token keyword">in</span> sequences<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token punctuation">[</span>seq <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">*</span><span class="token punctuation">(</span>max_len<span class="token operator">-</span><span class="token builtin">len</span><span class="token punctuation">(</span>seq<span class="token punctuation">)</span><span class="token punctuation">)</span> 
    	<span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>seq<span class="token punctuation">)</span> <span class="token operator">&lt;</span> max_len <span class="token keyword">else</span> seq<span class="token punctuation">[</span><span class="token punctuation">:</span>max_len<span class="token punctuation">]</span> 
    	<span class="token keyword">for</span> seq <span class="token keyword">in</span> sequences<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>The function <code>pad_sequence()</code> truncates and pads Python lists to a common length of 128 in our case.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">MAX_LENGTH <span class="token operator">=</span> <span class="token number">128</span>

train_idx_list_padded <span class="token operator">=</span> pad_sequence<span class="token punctuation">(</span>train_idx_list<span class="token punctuation">,</span> MAX_LENGTH<span class="token punctuation">)</span>
valid_idx_list_padded <span class="token operator">=</span> pad_sequence<span class="token punctuation">(</span>valid_idx_list<span class="token punctuation">,</span> MAX_LENGTH<span class="token punctuation">)</span>
test_idx_list_padded <span class="token operator">=</span> pad_sequence<span class="token punctuation">(</span>test_idx_list<span class="token punctuation">,</span> MAX_LENGTH<span class="token punctuation">)</span>

train_pos_idx_list_padded <span class="token operator">=</span> pad_sequence<span class="token punctuation">(</span>train_pos_idx_list<span class="token punctuation">,</span> MAX_LENGTH<span class="token punctuation">)</span>
valid_pos_idx_list_padded <span class="token operator">=</span> pad_sequence<span class="token punctuation">(</span>valid_pos_idx_list<span class="token punctuation">,</span> MAX_LENGTH<span class="token punctuation">)</span>
test_pos_idx_list_padded <span class="token operator">=</span> pad_sequence<span class="token punctuation">(</span>test_pos_idx_list<span class="token punctuation">,</span> MAX_LENGTH<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="Dataset-and-Dataloader"><a href="#Dataset-and-Dataloader" class="headerlink" title="Dataset and Dataloader"></a>Dataset and Dataloader</h1><p>We have to keep in mind that in some cases, even the most state-of-the-art configuration won’t have enough memory space to process the data the way we used to do it. That is the reason why we need to find other ways to do that task efficiently.</p>
<h2 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h2><p>Now, let’s go through the details of how to set the Python class Dataset, which will characterize the key features of the dataset you want to generate.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">ReviewsDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> sequences<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>sequences <span class="token operator">=</span> sequences
        self<span class="token punctuation">.</span>labels <span class="token operator">=</span> labels

    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>labels<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>
        seq <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>self<span class="token punctuation">.</span>sequences<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">)</span>
        label <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>labels<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> seq<span class="token punctuation">,</span> label
    
    <span class="token keyword">def</span> <span class="token function">get_dataloader</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> shuffle<span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> DataLoader<span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span>shuffle<span class="token punctuation">,</span> num_workers<span class="token operator">=</span>num_workers<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>Each call requests a sample index for which the upperbound is specified in the <code>__len__</code> method. When the sample corresponding to a given index is called, the generator executes the <code>__getitem__</code> method to generate it.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">BATCH_SIZE <span class="token operator">=</span> <span class="token number">32</span>
EPOCHS <span class="token operator">=</span> <span class="token number">100</span>

train_dataset <span class="token operator">=</span> ReviewsDataset<span class="token punctuation">(</span>train_idx_list_padded<span class="token punctuation">,</span> train_label<span class="token punctuation">)</span>
valid_dataset <span class="token operator">=</span> ReviewsDataset<span class="token punctuation">(</span>valid_idx_list_padded<span class="token punctuation">,</span> valid_label<span class="token punctuation">)</span>
test_dataset <span class="token operator">=</span> ReviewsDataset<span class="token punctuation">(</span>test_idx_list_padded<span class="token punctuation">,</span> test_label<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="Dataloader"><a href="#Dataloader" class="headerlink" title="Dataloader"></a>Dataloader</h2><p>Now, we have to modify our PyTorch script accordingly so that it accepts the generator that we just created. In order to do so, we use PyTorch’s <code>DataLoader</code> class, which in addition to our <code>Dataset</code> class, also takes in the following important arguments:</p>
<ul>
<li><code>batch_size</code>: denotes the number of samples contained in each generated batch.</li>
<li><code>shuffle</code>: if set to <code>True</code>, we will get a new order of exploration at each pass (or just keep a linear exploration scheme otherwise).</li>
<li><code>num_workers</code>: denotes the number of processes that generate batches in parallel.</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">train_generator <span class="token operator">=</span> train_dataset<span class="token punctuation">.</span>get_dataloader<span class="token punctuation">(</span>
	batch_size<span class="token operator">=</span>BATCH_SIZE<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
valid_generator <span class="token operator">=</span> valid_dataset<span class="token punctuation">.</span>get_dataloader<span class="token punctuation">(</span>
	batch_size<span class="token operator">=</span>BATCH_SIZE<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
test_generator <span class="token operator">=</span> test_dataset<span class="token punctuation">.</span>get_dataloader<span class="token punctuation">(</span>
	batch_size<span class="token operator">=</span>BATCH_SIZE<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="Modeling"><a href="#Modeling" class="headerlink" title="Modeling"></a>Modeling</h1><p>For specifying more complex neural network structure, we have to define our own modules by subclassing <code>nn.Module</code> and defining a <code>forward</code> which receives input tensors and produces output tensors using other modules or other autograd operations on tensors.</p>
<p>This implementation defines the model as a custom <code>Module</code> subclass. I’ll use <code>EmbeddingBag</code> as the baseline. The PyTorch <code>EmbeddingBag</code> operator computes sums or means of “bags” of embeddings. <code>EmbeddingBag</code> is the integration of look-up tables into an embedding. This is quite similar to <code>FastText</code> proposed by FaceBook.</p>
<p>There are three extra functions I created in this <code>TextClassifier</code> class.</p>
<ol>
<li><code>fit</code>: in a nutshell, fitting is equal to training. Then, after it is trained, the model can be used to make predictions.</li>
<li><code>predict</code>: classify incoming data points.</li>
<li><code>plot</code>: diagnose the behavior of a machine learning model. There are three common dynamics that you are likely to observe in learning curves; they are: underfit, overfit, and good fit.</li>
</ol>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">TextClassifier</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token comment">#define all the layers used in model</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> 
                 vocab_size<span class="token punctuation">,</span> 
                 embedding_dim<span class="token punctuation">,</span> 
                 output_dim<span class="token punctuation">,</span> 
                 dropout<span class="token punctuation">)</span><span class="token punctuation">:</span>
        
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>EmbeddingBag<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> embedding_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>drop <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>embedding_dim<span class="token punctuation">,</span> output_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>output <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        self<span class="token punctuation">.</span>epochs <span class="token operator">=</span> <span class="token boolean">None</span>
        self<span class="token punctuation">.</span>train_loss <span class="token operator">=</span> <span class="token boolean">None</span>
        self<span class="token punctuation">.</span>valid_loss <span class="token operator">=</span> <span class="token boolean">None</span>
        
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> text<span class="token punctuation">)</span><span class="token punctuation">:</span>
        embedded <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
        dense_outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>self<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>embedded<span class="token punctuation">)</span><span class="token punctuation">)</span>
        outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>output<span class="token punctuation">(</span>dense_outputs<span class="token punctuation">)</span>
        <span class="token keyword">return</span> outputs
    
    <span class="token keyword">def</span> <span class="token function">count_parameters</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        count <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>p<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> p <span class="token keyword">in</span> self<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> p<span class="token punctuation">.</span>requires_grad<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'The model has </span><span class="token interpolation"><span class="token punctuation">&#123;</span>count<span class="token punctuation">:</span><span class="token format-spec">,</span><span class="token punctuation">&#125;</span></span><span class="token string"> trainable parameters.'</span></span><span class="token punctuation">)</span>
        
    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> train_generator<span class="token punctuation">,</span> valid_generator<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> optimiser<span class="token punctuation">,</span> device<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        train_loss<span class="token punctuation">,</span> valid_loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

        <span class="token comment"># Loop over epochs</span>
        <span class="token keyword">for</span> epoch <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># Training</span>
            model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
            epoch_loss <span class="token operator">=</span> <span class="token number">0</span>
            <span class="token keyword">for</span> local_seqs<span class="token punctuation">,</span> local_labels <span class="token keyword">in</span> train_generator<span class="token punctuation">:</span>
                optimiser<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
                local_seqs<span class="token punctuation">,</span> local_labels <span class="token operator">=</span> local_seqs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> local_labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
                predictions <span class="token operator">=</span> self<span class="token punctuation">(</span>local_seqs<span class="token punctuation">)</span>
                loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>predictions<span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float64<span class="token punctuation">)</span><span class="token punctuation">,</span> local_labels<span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float64<span class="token punctuation">)</span><span class="token punctuation">)</span>
                loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>       
                optimiser<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>      
                epoch_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            train_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>epoch_loss <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_generator<span class="token punctuation">)</span><span class="token punctuation">)</span>

            <span class="token comment"># Validation</span>
            model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
            epoch_loss <span class="token operator">=</span> <span class="token number">0</span>
            <span class="token keyword">with</span> torch<span class="token punctuation">.</span>set_grad_enabled<span class="token punctuation">(</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">for</span> local_seqs<span class="token punctuation">,</span> local_labels <span class="token keyword">in</span> valid_generator<span class="token punctuation">:</span>
                    <span class="token comment"># Transfer to GPU</span>
                    local_seqs<span class="token punctuation">,</span> local_labels <span class="token operator">=</span> local_seqs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> local_labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
                    predictions <span class="token operator">=</span> self<span class="token punctuation">(</span>local_seqs<span class="token punctuation">)</span>
                    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>predictions<span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float64<span class="token punctuation">)</span><span class="token punctuation">,</span> local_labels<span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float64<span class="token punctuation">)</span><span class="token punctuation">)</span>
                    epoch_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
                valid_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>epoch_loss <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>valid_generator<span class="token punctuation">)</span><span class="token punctuation">)</span>
        
        self<span class="token punctuation">.</span>epochs <span class="token operator">=</span> epochs
        self<span class="token punctuation">.</span>train_loss <span class="token operator">=</span> train_loss
        self<span class="token punctuation">.</span>valid_loss <span class="token operator">=</span> valid_loss
        
    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> test_generator<span class="token punctuation">,</span> device<span class="token punctuation">,</span> threshold<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        predictions_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>set_grad_enabled<span class="token punctuation">(</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> local_seqs<span class="token punctuation">,</span> local_labels <span class="token keyword">in</span> test_generator<span class="token punctuation">:</span>
                <span class="token comment"># Transfer to GPU</span>
                local_seqs<span class="token punctuation">,</span> local_labels <span class="token operator">=</span> local_seqs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> local_labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
                predictions <span class="token operator">=</span> self<span class="token punctuation">(</span>local_seqs<span class="token punctuation">)</span>
                predictions_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>predictions<span class="token punctuation">)</span>
                
        test_preds <span class="token operator">=</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>predictions_list<span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">>=</span> threshold<span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">)</span>
        test_preds <span class="token operator">=</span> test_preds<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> test_preds
        
    <span class="token keyword">def</span> <span class="token function">plot</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>epochs<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>train_loss<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"train"</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>epochs<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>valid_loss<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"valid"</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="Training-Process"><a href="#Training-Process" class="headerlink" title="Training Process"></a>Training Process</h2><p>I would like to train the model in four different aspects.</p>
<ol>
<li>Without regularisation</li>
<li>With dropout</li>
<li>With L2 regularisation</li>
<li>With dropout and L2 regularisation</li>
</ol>
<h3 id="Train-without-Regularisation"><a href="#Train-without-Regularisation" class="headerlink" title="Train without Regularisation"></a>Train without Regularisation</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> TextClassifier<span class="token punctuation">(</span>vocab_size<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span><span class="token punctuation">,</span> 
                       embedding_dim<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">,</span> 
                       output_dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> 
                       dropout<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>
optimiser <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
criterion<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_generator<span class="token punctuation">,</span> valid_generator<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> optimiser<span class="token punctuation">,</span> device<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<img src="/Yang-Tech-Blog/2021/04/23/2021-04-23-sentiment-analysis-for-japanese-customer-reviews/model1.png" class="">

<pre class="line-numbers language-python" data-language="python"><code class="language-python">test_preds <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>test_generator<span class="token punctuation">,</span> device<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>metrics<span class="token punctuation">.</span>classification_report<span class="token punctuation">(</span>test_label<span class="token punctuation">,</span> test_preds<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Accuracy: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>metrics<span class="token punctuation">.</span>accuracy_score<span class="token punctuation">(</span>test_label<span class="token punctuation">,</span> test_preds<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec"> .4f</span><span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Precision: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>metrics<span class="token punctuation">.</span>precision_score<span class="token punctuation">(</span>test_label<span class="token punctuation">,</span> test_preds<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec"> .4f</span><span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Recall: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>metrics<span class="token punctuation">.</span>recall_score<span class="token punctuation">(</span>test_label<span class="token punctuation">,</span> test_preds<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec"> .4f</span><span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'F1-Score: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>metrics<span class="token punctuation">.</span>f1_score<span class="token punctuation">(</span>test_label<span class="token punctuation">,</span> test_preds<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec"> .4f</span><span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<pre class="line-numbers language-none"><code class="language-none">              precision    recall  f1-score   support

           0       0.90      0.96      0.93      1000
           1       0.95      0.90      0.92      1000

    accuracy                           0.93      2000
   macro avg       0.93      0.93      0.93      2000
weighted avg       0.93      0.93      0.93      2000

Accuracy:  0.9270
Precision:  0.9533
Recall:  0.8980
F1-Score:  0.9248<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="Train-with-Regularisation-Dropout"><a href="#Train-with-Regularisation-Dropout" class="headerlink" title="Train with Regularisation (Dropout)"></a>Train with Regularisation (Dropout)</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> TextClassifier<span class="token punctuation">(</span>vocab_size<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span><span class="token punctuation">,</span> 
                       embedding_dim<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">,</span> 
                       output_dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> 
                       dropout<span class="token operator">=</span><span class="token number">0.25</span><span class="token punctuation">)</span>
optimiser <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
criterion<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_generator<span class="token punctuation">,</span> valid_generator<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> optimiser<span class="token punctuation">,</span> device<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<img src="/Yang-Tech-Blog/2021/04/23/2021-04-23-sentiment-analysis-for-japanese-customer-reviews/model2.png" class="">

<pre class="line-numbers language-python" data-language="python"><code class="language-python">test_preds <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>test_generator<span class="token punctuation">,</span> device<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>metrics<span class="token punctuation">.</span>classification_report<span class="token punctuation">(</span>test_label<span class="token punctuation">,</span> test_preds<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Accuracy: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>metrics<span class="token punctuation">.</span>accuracy_score<span class="token punctuation">(</span>test_label<span class="token punctuation">,</span> test_preds<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec"> .4f</span><span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Precision: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>metrics<span class="token punctuation">.</span>precision_score<span class="token punctuation">(</span>test_label<span class="token punctuation">,</span> test_preds<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec"> .4f</span><span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Recall: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>metrics<span class="token punctuation">.</span>recall_score<span class="token punctuation">(</span>test_label<span class="token punctuation">,</span> test_preds<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec"> .4f</span><span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'F1-Score: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>metrics<span class="token punctuation">.</span>f1_score<span class="token punctuation">(</span>test_label<span class="token punctuation">,</span> test_preds<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec"> .4f</span><span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<pre class="line-numbers language-none"><code class="language-none">              precision    recall  f1-score   support

           0       0.91      0.96      0.93      1000
           1       0.96      0.91      0.93      1000

    accuracy                           0.93      2000
   macro avg       0.93      0.93      0.93      2000
weighted avg       0.93      0.93      0.93      2000

Accuracy:  0.9320
Precision:  0.9567
Recall:  0.9050
F1-Score:  0.9301<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="Train-with-Regularisation-L2"><a href="#Train-with-Regularisation-L2" class="headerlink" title="Train with Regularisation (L2)"></a>Train with Regularisation (L2)</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> TextClassifier<span class="token punctuation">(</span>vocab_size<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span><span class="token punctuation">,</span> 
                       embedding_dim<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">,</span> 
                       output_dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> 
                       dropout<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>
optimiser <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">1e-4</span><span class="token punctuation">)</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
criterion<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_generator<span class="token punctuation">,</span> valid_generator<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> optimiser<span class="token punctuation">,</span> device<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<img src="/Yang-Tech-Blog/2021/04/23/2021-04-23-sentiment-analysis-for-japanese-customer-reviews/model3.png" class="">

<pre class="line-numbers language-python" data-language="python"><code class="language-python">test_preds <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>test_generator<span class="token punctuation">,</span> device<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>metrics<span class="token punctuation">.</span>classification_report<span class="token punctuation">(</span>test_label<span class="token punctuation">,</span> test_preds<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Accuracy: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>metrics<span class="token punctuation">.</span>accuracy_score<span class="token punctuation">(</span>test_label<span class="token punctuation">,</span> test_preds<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec"> .4f</span><span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Precision: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>metrics<span class="token punctuation">.</span>precision_score<span class="token punctuation">(</span>test_label<span class="token punctuation">,</span> test_preds<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec"> .4f</span><span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Recall: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>metrics<span class="token punctuation">.</span>recall_score<span class="token punctuation">(</span>test_label<span class="token punctuation">,</span> test_preds<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec"> .4f</span><span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'F1-Score: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>metrics<span class="token punctuation">.</span>f1_score<span class="token punctuation">(</span>test_label<span class="token punctuation">,</span> test_preds<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec"> .4f</span><span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<pre class="line-numbers language-none"><code class="language-none">              precision    recall  f1-score   support

           0       0.88      0.96      0.92      1000
           1       0.96      0.87      0.91      1000

    accuracy                           0.92      2000
   macro avg       0.92      0.92      0.92      2000
weighted avg       0.92      0.92      0.92      2000

Accuracy:  0.9160
Precision:  0.9561
Recall:  0.8720
F1-Score:  0.9121<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="Train-with-Regularisation-Dropout-L2"><a href="#Train-with-Regularisation-Dropout-L2" class="headerlink" title="Train with Regularisation (Dropout + L2)"></a>Train with Regularisation (Dropout + L2)</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> TextClassifier<span class="token punctuation">(</span>vocab_size<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span><span class="token punctuation">,</span> 
                       embedding_dim<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">,</span> 
                       output_dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> 
                       dropout<span class="token operator">=</span><span class="token number">0.25</span><span class="token punctuation">)</span>
optimiser <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">1e-4</span><span class="token punctuation">)</span>
criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
criterion<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_generator<span class="token punctuation">,</span> valid_generator<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> optimiser<span class="token punctuation">,</span> device<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<img src="/Yang-Tech-Blog/2021/04/23/2021-04-23-sentiment-analysis-for-japanese-customer-reviews/model4.png" class="">

<pre class="line-numbers language-python" data-language="python"><code class="language-python">test_preds <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>test_generator<span class="token punctuation">,</span> device<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>metrics<span class="token punctuation">.</span>classification_report<span class="token punctuation">(</span>test_label<span class="token punctuation">,</span> test_preds<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Accuracy: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>metrics<span class="token punctuation">.</span>accuracy_score<span class="token punctuation">(</span>test_label<span class="token punctuation">,</span> test_preds<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec"> .4f</span><span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Precision: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>metrics<span class="token punctuation">.</span>precision_score<span class="token punctuation">(</span>test_label<span class="token punctuation">,</span> test_preds<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec"> .4f</span><span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Recall: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>metrics<span class="token punctuation">.</span>recall_score<span class="token punctuation">(</span>test_label<span class="token punctuation">,</span> test_preds<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec"> .4f</span><span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'F1-Score: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>metrics<span class="token punctuation">.</span>f1_score<span class="token punctuation">(</span>test_label<span class="token punctuation">,</span> test_preds<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec"> .4f</span><span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<pre class="line-numbers language-none"><code class="language-none">              precision    recall  f1-score   support

           0       0.91      0.94      0.93      1000
           1       0.94      0.91      0.92      1000

    accuracy                           0.93      2000
   macro avg       0.93      0.93      0.93      2000
weighted avg       0.93      0.93      0.93      2000

Accuracy:  0.9260
Precision:  0.9401
Recall:  0.9100
F1-Score:  0.9248<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="Performance"><a href="#Performance" class="headerlink" title="Performance"></a>Performance</h3><p>Although model with dropout outperms others, it seems to be overfitting. While the model with L2 and the model with both dropout and L2 have a better learning curve during the training process.</p>
<table>
<thead>
<tr>
<th align="center">Model</th>
<th align="center">Accuracy</th>
<th align="center">Precision</th>
<th align="center">Recall</th>
<th align="center">F1-Score</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Without Reg</td>
<td align="center">0.9270</td>
<td align="center">0.9533</td>
<td align="center">0.8980</td>
<td align="center">0.9248</td>
</tr>
<tr>
<td align="center">With Dropout</td>
<td align="center"><strong>0.9320</strong></td>
<td align="center"><strong>0.9567</strong></td>
<td align="center">0.9050</td>
<td align="center"><strong>0.9301</strong></td>
</tr>
<tr>
<td align="center">With L2</td>
<td align="center">0.9160</td>
<td align="center">0.9561</td>
<td align="center">0.8720</td>
<td align="center">0.9121</td>
</tr>
<tr>
<td align="center">With Dropout &amp; L2</td>
<td align="center">0.9260</td>
<td align="center">0.9401</td>
<td align="center"><strong>0.9100</strong></td>
<td align="center">0.9248</td>
</tr>
</tbody></table>
<h2 id="Word-Embedding-and-POS-Embedding"><a href="#Word-Embedding-and-POS-Embedding" class="headerlink" title="Word Embedding and POS Embedding"></a>Word Embedding and POS Embedding</h2><p>Add the POS tags as a features to the embedding vectors. I guess extending word vectors with POS tags is a good practice, because it could deal with polysemy, for example. In Lasguido Nio and Koji Murakami’s paper “Japanese Sentiment Classification Using Bidirectional Long Short-Term Memory Recurrent Neural Network”, they appended the network hidden layer with the Part<br>of Speech tag (POStag) feature and Japanese polarity dictionary information. Their model achieves the state-of-the-art performance in Japanese sentiment classification task. Therefore, I want to give a try implementing their idea on different dataset.</p>
<p>Basically, there’s not much difference in building <code>Dataset</code> and <code>Dataloader</code> subclass.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">ReviewsPOSDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> sequences<span class="token punctuation">,</span> tags<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>sequences <span class="token operator">=</span> sequences
        self<span class="token punctuation">.</span>tags <span class="token operator">=</span> tags
        self<span class="token punctuation">.</span>labels <span class="token operator">=</span> labels

    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>labels<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>
        seq <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>self<span class="token punctuation">.</span>sequences<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">)</span>
        tag <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>self<span class="token punctuation">.</span>tags<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">)</span>
        label <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>labels<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> seq<span class="token punctuation">,</span> tag<span class="token punctuation">,</span> label
    
    <span class="token keyword">def</span> <span class="token function">get_dataloader</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> shuffle<span class="token punctuation">,</span> num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> DataLoader<span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span>shuffle<span class="token punctuation">,</span> num_workers<span class="token operator">=</span>num_workers<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">train_pos_dataset <span class="token operator">=</span> ReviewsPOSDataset<span class="token punctuation">(</span>
	train_idx_list_padded<span class="token punctuation">,</span> train_pos_idx_list_padded<span class="token punctuation">,</span> train_label<span class="token punctuation">)</span>
valid_pos_dataset <span class="token operator">=</span> ReviewsPOSDataset<span class="token punctuation">(</span>
	valid_idx_list_padded<span class="token punctuation">,</span> valid_pos_idx_list_padded<span class="token punctuation">,</span> valid_label<span class="token punctuation">)</span>
test_pos_dataset <span class="token operator">=</span> ReviewsPOSDataset<span class="token punctuation">(</span>
	test_idx_list_padded<span class="token punctuation">,</span> test_pos_idx_list_padded<span class="token punctuation">,</span> test_label<span class="token punctuation">)</span>

train_pos_generator <span class="token operator">=</span> train_pos_dataset<span class="token punctuation">.</span>get_dataloader<span class="token punctuation">(</span>
	batch_size<span class="token operator">=</span>BATCH_SIZE<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
valid_pos_generator <span class="token operator">=</span> valid_pos_dataset<span class="token punctuation">.</span>get_dataloader<span class="token punctuation">(</span>
	batch_size<span class="token operator">=</span>BATCH_SIZE<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
test_pos_generator <span class="token operator">=</span> test_pos_dataset<span class="token punctuation">.</span>get_dataloader<span class="token punctuation">(</span>
	batch_size<span class="token operator">=</span>BATCH_SIZE<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>Next, build the model.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">TextPOSClassifier</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token comment">#define all the layers used in model</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> 
                 vocab_size<span class="token punctuation">,</span> 
                 embedding_dim<span class="token punctuation">,</span> 
                 pos_size<span class="token punctuation">,</span> 
                 pos_embedding_dim<span class="token punctuation">,</span> 
                 output_dim<span class="token punctuation">,</span> 
                 dropout<span class="token punctuation">)</span><span class="token punctuation">:</span>
        
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>device <span class="token operator">=</span> device
        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>EmbeddingBag<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> embedding_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pos_embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>EmbeddingBag<span class="token punctuation">(</span>pos_size<span class="token punctuation">,</span> pos_embedding_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>embedding_dim<span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token punctuation">(</span>embedding_dim<span class="token operator">+</span>pos_embedding_dim<span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>pos_embedding_dim<span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token punctuation">(</span>embedding_dim<span class="token operator">+</span>pos_embedding_dim<span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>drop <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token punctuation">(</span>embedding_dim<span class="token operator">+</span>pos_embedding_dim<span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> output_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>output <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> text<span class="token punctuation">,</span> tag<span class="token punctuation">)</span><span class="token punctuation">:</span>
        text_embedded <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
        pos_embedded <span class="token operator">=</span> self<span class="token punctuation">.</span>pos_embedding<span class="token punctuation">(</span>tag<span class="token punctuation">)</span>
        text_embedded <span class="token operator">=</span> self<span class="token punctuation">.</span>linear1<span class="token punctuation">(</span>text_embedded<span class="token punctuation">)</span>
        pos_embedded <span class="token operator">=</span> self<span class="token punctuation">.</span>linear2<span class="token punctuation">(</span>pos_embedded<span class="token punctuation">)</span>
        embedded <span class="token operator">=</span> torch<span class="token punctuation">.</span>add<span class="token punctuation">(</span>text_embedded<span class="token punctuation">,</span> pos_embedded<span class="token punctuation">)</span>
        dense_outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>self<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>embedded<span class="token punctuation">)</span><span class="token punctuation">)</span>
        outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>output<span class="token punctuation">(</span>dense_outputs<span class="token punctuation">)</span>
        <span class="token keyword">return</span> outputs
    
    <span class="token keyword">def</span> <span class="token function">count_parameters</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        count <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>p<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> p <span class="token keyword">in</span> self<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> p<span class="token punctuation">.</span>requires_grad<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'The model has </span><span class="token interpolation"><span class="token punctuation">&#123;</span>count<span class="token punctuation">:</span><span class="token format-spec">,</span><span class="token punctuation">&#125;</span></span><span class="token string"> trainable parameters.'</span></span><span class="token punctuation">)</span>
        
    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> train_generator<span class="token punctuation">,</span> valid_generator<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> optimiser<span class="token punctuation">,</span> device<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        train_loss<span class="token punctuation">,</span> valid_loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

        <span class="token comment"># Loop over epochs</span>
        <span class="token keyword">for</span> epoch <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># Training</span>
            model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
            epoch_loss <span class="token operator">=</span> <span class="token number">0</span>
            <span class="token keyword">for</span> local_seqs<span class="token punctuation">,</span> local_tags<span class="token punctuation">,</span> local_labels <span class="token keyword">in</span> train_generator<span class="token punctuation">:</span>
                optimiser<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
                local_seqs<span class="token punctuation">,</span> local_labels <span class="token operator">=</span> local_seqs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> local_labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
                local_tags <span class="token operator">=</span> local_tags<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
                predictions <span class="token operator">=</span> self<span class="token punctuation">(</span>local_seqs<span class="token punctuation">,</span> local_tags<span class="token punctuation">)</span>
                loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>predictions<span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float64<span class="token punctuation">)</span><span class="token punctuation">,</span> local_labels<span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float64<span class="token punctuation">)</span><span class="token punctuation">)</span>
                loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>       
                optimiser<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>      
                epoch_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            train_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>epoch_loss <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_generator<span class="token punctuation">)</span><span class="token punctuation">)</span>

            <span class="token comment"># Validation</span>
            model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
            epoch_loss <span class="token operator">=</span> <span class="token number">0</span>
            <span class="token keyword">with</span> torch<span class="token punctuation">.</span>set_grad_enabled<span class="token punctuation">(</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">for</span> local_seqs<span class="token punctuation">,</span> local_tags<span class="token punctuation">,</span> local_labels <span class="token keyword">in</span> valid_generator<span class="token punctuation">:</span>
                    <span class="token comment"># Transfer to GPU</span>
                    local_seqs<span class="token punctuation">,</span> local_labels <span class="token operator">=</span> local_seqs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> local_labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
                    local_tags <span class="token operator">=</span> local_tags<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
                    predictions <span class="token operator">=</span> self<span class="token punctuation">(</span>local_seqs<span class="token punctuation">,</span> local_tags<span class="token punctuation">)</span>
                    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>predictions<span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float64<span class="token punctuation">)</span><span class="token punctuation">,</span> local_labels<span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float64<span class="token punctuation">)</span><span class="token punctuation">)</span>
                    epoch_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
                valid_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>epoch_loss <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>valid_generator<span class="token punctuation">)</span><span class="token punctuation">)</span>
        
        self<span class="token punctuation">.</span>epochs <span class="token operator">=</span> epochs
        self<span class="token punctuation">.</span>train_loss <span class="token operator">=</span> train_loss
        self<span class="token punctuation">.</span>valid_loss <span class="token operator">=</span> valid_loss
        
    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> test_generator<span class="token punctuation">,</span> device<span class="token punctuation">,</span> threshold<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        predictions_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>set_grad_enabled<span class="token punctuation">(</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> local_seqs<span class="token punctuation">,</span> local_tags<span class="token punctuation">,</span> local_labels <span class="token keyword">in</span> test_generator<span class="token punctuation">:</span>
                <span class="token comment"># Transfer to GPU</span>
                local_seqs<span class="token punctuation">,</span> local_labels <span class="token operator">=</span> local_seqs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> local_labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
                local_tags <span class="token operator">=</span> local_tags<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
                predictions <span class="token operator">=</span> self<span class="token punctuation">(</span>local_seqs<span class="token punctuation">,</span> local_tags<span class="token punctuation">)</span>
                predictions_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>predictions<span class="token punctuation">)</span>
                
        test_preds <span class="token operator">=</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>predictions_list<span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">>=</span> threshold<span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">)</span>
        test_preds <span class="token operator">=</span> test_preds<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> test_preds
        
    <span class="token keyword">def</span> <span class="token function">plot</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>epochs<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>train_loss<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"train"</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>epochs<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>valid_loss<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"valid"</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>I will only show the performance table over here, because the training code is exactly the same as the previous.</p>
<table>
<thead>
<tr>
<th align="center">Model</th>
<th align="center">Accuracy</th>
<th align="center">Precision</th>
<th align="center">Recall</th>
<th align="center">F1-Score</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Without Reg</td>
<td align="center">0.9305</td>
<td align="center">0.9415</td>
<td align="center">0.9180</td>
<td align="center">0.9296</td>
</tr>
<tr>
<td align="center">With Dropout</td>
<td align="center">0.9320</td>
<td align="center">0.9435</td>
<td align="center">0.9190</td>
<td align="center">0.9311</td>
</tr>
<tr>
<td align="center">With L2</td>
<td align="center">0.9360</td>
<td align="center">0.9658</td>
<td align="center">0.9040</td>
<td align="center">0.9339</td>
</tr>
<tr>
<td align="center">With Dropout &amp; L2</td>
<td align="center">0.9365</td>
<td align="center">0.9619</td>
<td align="center">0.9090</td>
<td align="center">0.9347</td>
</tr>
</tbody></table>
<p>As you can see in the table, after adding POS embedding to the model, it can perform better.</p>
<h2 id="Grid-Search"><a href="#Grid-Search" class="headerlink" title="Grid Search"></a>Grid Search</h2><p>The traditional way of performing hyperparameter optimization has been grid search, or a parameter sweep, which is simply an exhaustive searching through a manually specified subset of the hyperparameter space of a learning algorithm.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> itertools <span class="token keyword">import</span> product

PARAMS <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token string">"batch_size"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
    <span class="token string">"embedding_dim"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
    <span class="token string">"pos_embedding_dim"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
    <span class="token string">"dropout"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.25</span><span class="token punctuation">]</span>
<span class="token punctuation">&#125;</span>

results <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> batch_size<span class="token punctuation">,</span> embedding_dim<span class="token punctuation">,</span> pos_embedding_dim<span class="token punctuation">,</span> dropout <span class="token keyword">in</span> product<span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">[</span>v <span class="token keyword">for</span> v <span class="token keyword">in</span> PARAMS<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    train_pos_dataset <span class="token operator">=</span> ReviewsPOSDataset<span class="token punctuation">(</span>train_idx_list_padded<span class="token punctuation">,</span> train_pos_idx_list_padded<span class="token punctuation">,</span> train_label<span class="token punctuation">)</span>
    valid_pos_dataset <span class="token operator">=</span> ReviewsPOSDataset<span class="token punctuation">(</span>valid_idx_list_padded<span class="token punctuation">,</span> valid_pos_idx_list_padded<span class="token punctuation">,</span> valid_label<span class="token punctuation">)</span>
    test_pos_dataset <span class="token operator">=</span> ReviewsPOSDataset<span class="token punctuation">(</span>test_idx_list_padded<span class="token punctuation">,</span> test_pos_idx_list_padded<span class="token punctuation">,</span> test_label<span class="token punctuation">)</span>

    train_pos_generator <span class="token operator">=</span> train_pos_dataset<span class="token punctuation">.</span>get_dataloader<span class="token punctuation">(</span>batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    valid_pos_generator <span class="token operator">=</span> valid_pos_dataset<span class="token punctuation">.</span>get_dataloader<span class="token punctuation">(</span>batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    test_pos_generator <span class="token operator">=</span> test_pos_dataset<span class="token punctuation">.</span>get_dataloader<span class="token punctuation">(</span>batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    
    model <span class="token operator">=</span> TextPOSClassifier<span class="token punctuation">(</span>vocab_size<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span><span class="token punctuation">,</span> 
                              embedding_dim<span class="token operator">=</span>embedding_dim<span class="token punctuation">,</span> 
                              pos_size<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>pos_vocab<span class="token punctuation">)</span><span class="token punctuation">,</span> 
                              pos_embedding_dim<span class="token operator">=</span>pos_embedding_dim<span class="token punctuation">,</span> 
                              output_dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> 
                              dropout<span class="token operator">=</span>dropout<span class="token punctuation">)</span>
    optimiser <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">3e-4</span><span class="token punctuation">)</span>
    criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    criterion<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_pos_generator<span class="token punctuation">,</span> valid_pos_generator<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> optimiser<span class="token punctuation">,</span> device<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">40</span><span class="token punctuation">)</span>
    
    test_preds <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>test_pos_generator<span class="token punctuation">,</span> device<span class="token punctuation">)</span>
    accuracy <span class="token operator">=</span> metrics<span class="token punctuation">.</span>accuracy_score<span class="token punctuation">(</span>test_label<span class="token punctuation">,</span> test_preds<span class="token punctuation">)</span>
    precision <span class="token operator">=</span> metrics<span class="token punctuation">.</span>precision_score<span class="token punctuation">(</span>test_label<span class="token punctuation">,</span> test_preds<span class="token punctuation">)</span>
    recall <span class="token operator">=</span> metrics<span class="token punctuation">.</span>recall_score<span class="token punctuation">(</span>test_label<span class="token punctuation">,</span> test_preds<span class="token punctuation">)</span>
    f1 <span class="token operator">=</span> metrics<span class="token punctuation">.</span>f1_score<span class="token punctuation">(</span>test_label<span class="token punctuation">,</span> test_preds<span class="token punctuation">)</span>
    results<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>batch_size<span class="token punctuation">,</span> embedding_dim<span class="token punctuation">,</span> pos_embedding_dim<span class="token punctuation">,</span> accuracy<span class="token punctuation">,</span> precision<span class="token punctuation">,</span> recall<span class="token punctuation">,</span> f1<span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<table>
<thead>
<tr>
<th align="center">index</th>
<th align="center">batch_size</th>
<th align="center">embedding_dim</th>
<th align="center">pos_embedding_dim</th>
<th align="center">accuracy</th>
<th align="center">precision</th>
<th align="center">recall</th>
<th align="center">f1</th>
</tr>
</thead>
<tbody><tr>
<td align="center">0</td>
<td align="center">16</td>
<td align="center">100</td>
<td align="center">100</td>
<td align="center">0.9310</td>
<td align="center">0.926733</td>
<td align="center">0.936</td>
<td align="center">0.931343</td>
</tr>
<tr>
<td align="center">1</td>
<td align="center">16</td>
<td align="center">100</td>
<td align="center">100</td>
<td align="center">0.9395</td>
<td align="center">0.965079</td>
<td align="center">0.912</td>
<td align="center">0.937789</td>
</tr>
<tr>
<td align="center">2</td>
<td align="center">16</td>
<td align="center">100</td>
<td align="center">300</td>
<td align="center">0.9380</td>
<td align="center">0.959119</td>
<td align="center">0.915</td>
<td align="center">0.936540</td>
</tr>
<tr>
<td align="center">3</td>
<td align="center">16</td>
<td align="center">100</td>
<td align="center">300</td>
<td align="center">0.9300</td>
<td align="center">0.968410</td>
<td align="center">0.889</td>
<td align="center">0.927007</td>
</tr>
<tr>
<td align="center">4</td>
<td align="center">16</td>
<td align="center">300</td>
<td align="center">100</td>
<td align="center">0.9370</td>
<td align="center">0.944106</td>
<td align="center">0.929</td>
<td align="center">0.936492</td>
</tr>
<tr>
<td align="center">5</td>
<td align="center">16</td>
<td align="center">300</td>
<td align="center">100</td>
<td align="center">0.9360</td>
<td align="center">0.957023</td>
<td align="center">0.913</td>
<td align="center">0.934493</td>
</tr>
<tr>
<td align="center">6</td>
<td align="center">16</td>
<td align="center">300</td>
<td align="center">300</td>
<td align="center">0.9310</td>
<td align="center">0.969499</td>
<td align="center">0.890</td>
<td align="center">0.928050</td>
</tr>
<tr>
<td align="center">7</td>
<td align="center">16</td>
<td align="center">300</td>
<td align="center">300</td>
<td align="center">0.9320</td>
<td align="center">0.929423</td>
<td align="center">0.935</td>
<td align="center">0.932203</td>
</tr>
<tr>
<td align="center">8</td>
<td align="center">32</td>
<td align="center">100</td>
<td align="center">100</td>
<td align="center">0.9350</td>
<td align="center">0.953125</td>
<td align="center">0.915</td>
<td align="center">0.933673</td>
</tr>
<tr>
<td align="center">9</td>
<td align="center">32</td>
<td align="center">100</td>
<td align="center">100</td>
<td align="center">0.9335</td>
<td align="center">0.962647</td>
<td align="center">0.902</td>
<td align="center">0.931337</td>
</tr>
<tr>
<td align="center">10</td>
<td align="center">32</td>
<td align="center">100</td>
<td align="center">300</td>
<td align="center">0.9360</td>
<td align="center">0.963830</td>
<td align="center">0.906</td>
<td align="center">0.934021</td>
</tr>
<tr>
<td align="center">11</td>
<td align="center">32</td>
<td align="center">100</td>
<td align="center">300</td>
<td align="center">0.9325</td>
<td align="center">0.940877</td>
<td align="center">0.923</td>
<td align="center">0.931853</td>
</tr>
<tr>
<td align="center">12</td>
<td align="center">32</td>
<td align="center">300</td>
<td align="center">100</td>
<td align="center">0.9295</td>
<td align="center">0.928215</td>
<td align="center">0.931</td>
<td align="center">0.929606</td>
</tr>
<tr>
<td align="center">13</td>
<td align="center">32</td>
<td align="center">300</td>
<td align="center">100</td>
<td align="center">0.9275</td>
<td align="center">0.918707</td>
<td align="center">0.938</td>
<td align="center">0.928253</td>
</tr>
<tr>
<td align="center">14</td>
<td align="center">32</td>
<td align="center">300</td>
<td align="center">300</td>
<td align="center">0.9320</td>
<td align="center">0.943532</td>
<td align="center">0.919</td>
<td align="center">0.931104</td>
</tr>
<tr>
<td align="center">15</td>
<td align="center">32</td>
<td align="center">300</td>
<td align="center">300</td>
<td align="center">0.9125</td>
<td align="center">0.888053</td>
<td align="center">0.944</td>
<td align="center">0.915172</td>
</tr>
</tbody></table>
<h2 id="Concatenate-with-Word-Embedding-and-POS-Embedding"><a href="#Concatenate-with-Word-Embedding-and-POS-Embedding" class="headerlink" title="Concatenate with Word Embedding and POS Embedding"></a>Concatenate with Word Embedding and POS Embedding</h2><p>In the last section, I built the model with adding up word embedding vectors and POS embedding vector. I was wondering if concatenating these two vectors would work as well.</p>
<p>Basically, we need to change two part of the code only.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">TextPOSConcatClassifier</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token comment">#define all the layers used in model</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> 
                 vocab_size<span class="token punctuation">,</span> 
                 embedding_dim<span class="token punctuation">,</span> 
                 pos_size<span class="token punctuation">,</span> 
                 pos_embedding_dim<span class="token punctuation">,</span> 
                 output_dim<span class="token punctuation">,</span> 
                 dropout<span class="token punctuation">)</span><span class="token punctuation">:</span>
        
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>device <span class="token operator">=</span> device
        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>EmbeddingBag<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> embedding_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>pos_embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>EmbeddingBag<span class="token punctuation">(</span>pos_size<span class="token punctuation">,</span> pos_embedding_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>drop <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>embedding_dim<span class="token operator">+</span>pos_embedding_dim<span class="token punctuation">,</span> output_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>output <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> text<span class="token punctuation">,</span> tag<span class="token punctuation">)</span><span class="token punctuation">:</span>
        text_embedded <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
        pos_embedded <span class="token operator">=</span> self<span class="token punctuation">.</span>pos_embedding<span class="token punctuation">(</span>tag<span class="token punctuation">)</span>
        embedded <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>text_embedded<span class="token punctuation">,</span> pos_embedded<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        dense_outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>self<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>embedded<span class="token punctuation">)</span><span class="token punctuation">)</span>
        outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>output<span class="token punctuation">(</span>dense_outputs<span class="token punctuation">)</span>
        <span class="token keyword">return</span> outputs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="Train-without-Regularisation-1"><a href="#Train-without-Regularisation-1" class="headerlink" title="Train without Regularisation"></a>Train without Regularisation</h3><img src="/Yang-Tech-Blog/2021/04/23/2021-04-23-sentiment-analysis-for-japanese-customer-reviews/model5.png" class="">

<pre class="line-numbers language-none"><code class="language-none">              precision    recall  f1-score   support

           0       0.92      0.94      0.93      1000
           1       0.94      0.92      0.93      1000

    accuracy                           0.93      2000
   macro avg       0.93      0.93      0.93      2000
weighted avg       0.93      0.93      0.93      2000

Accuracy:  0.9310
Precision:  0.9407
Recall:  0.9200
F1-Score:  0.9302<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="Train-with-Regularisation-Dropout-1"><a href="#Train-with-Regularisation-Dropout-1" class="headerlink" title="Train with Regularisation (Dropout)"></a>Train with Regularisation (Dropout)</h3><img src="/Yang-Tech-Blog/2021/04/23/2021-04-23-sentiment-analysis-for-japanese-customer-reviews/model6.png" class="">

<pre class="line-numbers language-none"><code class="language-none">              precision    recall  f1-score   support

           0       0.91      0.95      0.93      1000
           1       0.95      0.91      0.93      1000

    accuracy                           0.93      2000
   macro avg       0.93      0.93      0.93      2000
weighted avg       0.93      0.93      0.93      2000

Accuracy:  0.9295
Precision:  0.9507
Recall:  0.9060
F1-Score:  0.9278<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="Train-with-Regularisation-L2-1"><a href="#Train-with-Regularisation-L2-1" class="headerlink" title="Train with Regularisation (L2)"></a>Train with Regularisation (L2)</h3><img src="/Yang-Tech-Blog/2021/04/23/2021-04-23-sentiment-analysis-for-japanese-customer-reviews/model7.png" class="">

<pre class="line-numbers language-none"><code class="language-none">              precision    recall  f1-score   support

           0       0.88      0.92      0.90      1000
           1       0.91      0.88      0.90      1000

    accuracy                           0.90      2000
   macro avg       0.90      0.90      0.90      2000
weighted avg       0.90      0.90      0.90      2000

Accuracy:  0.8975
Precision:  0.9128
Recall:  0.8790
F1-Score:  0.8956<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="Train-with-Regularisation-Dropout-L2-1"><a href="#Train-with-Regularisation-Dropout-L2-1" class="headerlink" title="Train with Regularisation (Dropout + L2)"></a>Train with Regularisation (Dropout + L2)</h3><img src="/Yang-Tech-Blog/2021/04/23/2021-04-23-sentiment-analysis-for-japanese-customer-reviews/model8.png" class="">

<pre class="line-numbers language-none"><code class="language-none">              precision    recall  f1-score   support

           0       0.89      0.92      0.90      1000
           1       0.92      0.88      0.90      1000

    accuracy                           0.90      2000
   macro avg       0.90      0.90      0.90      2000
weighted avg       0.90      0.90      0.90      2000

Accuracy:  0.9020
Precision:  0.9196
Recall:  0.8810
F1-Score:  0.8999<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="Performance-1"><a href="#Performance-1" class="headerlink" title="Performance"></a>Performance</h3><table>
<thead>
<tr>
<th align="center">Model</th>
<th align="center">Accuracy</th>
<th align="center">Precision</th>
<th align="center">Recall</th>
<th align="center">F1-Score</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Without Reg</td>
<td align="center">0.9310</td>
<td align="center">0.9407</td>
<td align="center">0.9200</td>
<td align="center">0.9302</td>
</tr>
<tr>
<td align="center">With Dropout</td>
<td align="center">0.9295</td>
<td align="center">0.9507</td>
<td align="center">0.9060</td>
<td align="center">0.9278</td>
</tr>
<tr>
<td align="center">With L2</td>
<td align="center">0.8975</td>
<td align="center">0.9128</td>
<td align="center">0.8790</td>
<td align="center">0.8956</td>
</tr>
<tr>
<td align="center">With Dropout &amp; L2</td>
<td align="center">0.9020</td>
<td align="center">0.9196</td>
<td align="center">0.8810</td>
<td align="center">0.8999</td>
</tr>
</tbody></table>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>In this work, I presented preliminary works on different sentiment classifiers for Japanese language using neural network. The idea mostly come from the paper “Japanese Sentiment Classification Using Bidirectional Long Short-Term Memory Recurrent Neural Network”, adding part-of-speech tagging feature that can be easily obtained resulted in more robust performance. There are still lots things can be done on this topic. Future works will have a look at adding sentiment feature using sentiment dictionary or polarity dictionary, and add attention mechanism model to the original architecture.</p>
<h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><ol>
<li><a target="_blank" rel="noopener" href="https://www.52nlp.cn/%E6%97%A5%E6%96%87%E5%88%86%E8%AF%8D%E5%99%A8-mecab-%E6%96%87%E6%A1%A3">https://www.52nlp.cn/%E6%97%A5%E6%96%87%E5%88%86%E8%AF%8D%E5%99%A8-mecab-%E6%96%87%E6%A1%A3</a></li>
<li><a target="_blank" rel="noopener" href="https://spacy.io/usage/models">https://spacy.io/usage/models</a></li>
<li><a target="_blank" rel="noopener" href="https://anlp.jp/proceedings/annual_meeting/2018/pdf_dir/P12-2.pdf">https://anlp.jp/proceedings/annual_meeting/2018/pdf_dir/P12-2.pdf</a></li>
<li><a target="_blank" rel="noopener" href="https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel">https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel</a></li>
<li><a target="_blank" rel="noopener" href="http://www.robfahey.co.uk/blog/japanese-text-analysis-in-python/">http://www.robfahey.co.uk/blog/japanese-text-analysis-in-python/</a></li>
</ol>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        Author:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Yang-Tech-Blog/about" rel="external nofollow noreferrer">Yang Wang</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        Link:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://penguinwang96825.github.io/Yang-Tech-Blog/Yang-Tech-Blog/2021/04/23/2021-04-23-sentiment-analysis-for-japanese-customer-reviews/">https://penguinwang96825.github.io/Yang-Tech-Blog/Yang-Tech-Blog/2021/04/23/2021-04-23-sentiment-analysis-for-japanese-customer-reviews/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        Reprint policy:
                    </i>
                </span>
                <span class="reprint-info">
                    All articles in this blog are used except for special statements
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    reprint polocy. If reproduced, please indicate source
                    <a href="/Yang-Tech-Blog/about" target="_blank">Yang Wang</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>Copied successfully, please follow the reprint policy of this article</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">more</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Yang-Tech-Blog/tags/Python/">
                                    <span class="chip bg-color">Python</span>
                                </a>
                            
                                <a href="/Yang-Tech-Blog/tags/PyTorch/">
                                    <span class="chip bg-color">PyTorch</span>
                                </a>
                            
                                <a href="/Yang-Tech-Blog/tags/Sentiment-Analysis/">
                                    <span class="chip bg-color">Sentiment Analysis</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Yang-Tech-Blog/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>WeChat swipe to share！</p>"></div>
    <script src="/Yang-Tech-Blog/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    
        <div class="disqus-card card" data-aos="fade-up">
    <div id="disqus_thread" class="card-content">
        <noscript>Please enable JavaScript to view the
            <a target="_blank" rel="noopener" href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
    </div>
</div>

<script type="text/javascript">
    disqus_config = function () {
        this.page.url = 'https://penguinwang96825.github.io/Yang-Tech-Blog/2021/04/23/2021-04-23-sentiment-analysis-for-japanese-customer-reviews/';
        this.page.identifier = '/Yang-Tech-Blog/2021/04/23/2021-04-23-sentiment-analysis-for-japanese-customer-reviews/';
        this.page.title = 'Sentiment Analysis for Japanese Customer Reviews';
    };
    let disqus_shortname = 'penguinwang';

    (function () { // DON'T EDIT BELOW THIS LINE
        let d = document, s = d.createElement('script');
        // 如：s.src = 'https://blinkfox.disqus.com/embed.js';
        s.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;Previous</div>
            <div class="card">
                <a href="/Yang-Tech-Blog/2021/04/27/2021-04-27-mecab-and-cabocha-for-japanese/">
                    <div class="card-image">
                        
                        <img src="https://github.com/penguinwang96825/penguinwang96825.github.io/blob/master/2021/04/27/2021-04-27-mecab-and-cabocha-for-japanese/wallhaven-j3xm5w.png?raw=true" class="responsive-img" alt="MeCab and CaboCha for Japanese">
                        
                        <span class="card-title">MeCab and CaboCha for Japanese</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            In Python, there are several choices of modules for morphological analysis. There are several types of kuromoji such as Janome, Juman, MeCab, and Esanpy, but this time we will use MeCab, which is said to be relatively fast and accurate.
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2021-04-27
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Yang-Tech-Blog/categories/NLP/" class="post-category">
                                    NLP
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Yang-Tech-Blog/tags/Python/">
                        <span class="chip bg-color">Python</span>
                    </a>
                    
                    <a href="/Yang-Tech-Blog/tags/Japanese/">
                        <span class="chip bg-color">Japanese</span>
                    </a>
                    
                    <a href="/Yang-Tech-Blog/tags/Text-Processing/">
                        <span class="chip bg-color">Text Processing</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                Next&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Yang-Tech-Blog/2021/04/18/2021-04-18-softmax-and-cross-entropy/">
                    <div class="card-image">
                        
                        <img src="https://github.com/penguinwang96825/penguinwang96825.github.io/blob/master/2021/04/18/2021-04-18-softmax-and-cross-entropy/wallhaven-n6xk36.jpg?raw=true" class="responsive-img" alt="Softmax and Cross-Entropy">
                        
                        <span class="card-title">Softmax and Cross-Entropy</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            I'm trying to implement neural network from scratch in Python recently. Considering to solve multi-class classification problem using neural network, I try to create a simple neural network. The most important thing in neural network is backpropagation. Backpropagation is an algorithm for supervised learning of artificial neural networks using gradient descent. I want to find the derivation of cross-entropy loss function with softmax activation function, so this article will record the formula I calculated. As for the rest, I will discuss it in the future.
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2021-04-18
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Yang-Tech-Blog/categories/NLP/" class="post-category">
                                    NLP
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Yang-Tech-Blog/tags/Python/">
                        <span class="chip bg-color">Python</span>
                    </a>
                    
                    <a href="/Yang-Tech-Blog/tags/Neural-Network/">
                        <span class="chip bg-color">Neural Network</span>
                    </a>
                    
                    <a href="/Yang-Tech-Blog/tags/Calculus/">
                        <span class="chip bg-color">Calculus</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Yang-Tech-Blog/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/Yang-Tech-Blog/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Yang-Tech-Blog/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Yang-Tech-Blog/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;TOC</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Yang-Tech-Blog/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h1, h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\(', '\)']]}
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

    <!-- footer -->
    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Yang-Tech-Blog/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='true'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.3'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Yang-Tech-Blog/libs/aplayer/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

    
    <div class="container row center-align" style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2018-2022</span>
            
            <span id="year">2018</span>
            <a href="/Yang-Tech-Blog/about" target="_blank">Yang Wang</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;Total site word count:&nbsp;<span
                class="white-color">115.9k</span>&nbsp;words
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;Total number of visits:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;times
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;Total number of visitors:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;people
            </span>
            
            <br>
            
            <span id="sitetime">Loading runtime...</span>
            <script>
                function siteTime() {
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2018";
                    var startMonth = "12";
                    var startDate = "3";
                    var startHour = "0";
                    var startMinute = "0";
                    var startSecond = "0";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "This site has been safely operated " + diffDays + " days " + diffHours +
                            " hours " + diffMinutes + " minutes " + diffSeconds + " seconds";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "This site has been safely operated " + diffYears + " years " + diffDays +
                            " days " + diffHours + " hours " + diffMinutes + " minutes " + diffSeconds + " seconds";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/penguinwang96825" class="tooltipped" target="_blank" data-tooltip="Visit my GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:penguinwang@smail.nchu.edu.tw" class="tooltipped" target="_blank" data-tooltip="Contact me by mail" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>













</div>
    </div>
</footer>

<div class="progress-bar"></div>

    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;Search</span>
            <input type="search" id="searchInput" name="s" placeholder="Please enter a search keyword"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Yang-Tech-Blog/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Yang-Tech-Blog/libs/materialize/materialize.min.js"></script>
    <script src="/Yang-Tech-Blog/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Yang-Tech-Blog/libs/aos/aos.js"></script>
    <script src="/Yang-Tech-Blog/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Yang-Tech-Blog/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Yang-Tech-Blog/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Yang-Tech-Blog/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Yang-Tech-Blog/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

	
    

    

    
    <script type="text/javascript" src="/Yang-Tech-Blog/libs/background/ribbon-dynamic.js" async="async"></script>
    

    
    <script src="/Yang-Tech-Blog/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

<script>
    pseudocode.renderElement(document.getElementById("pseudocode"));
</script>

</html>
