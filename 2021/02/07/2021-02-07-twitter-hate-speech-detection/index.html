<!DOCTYPE HTML>
<html lang="en">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Twitter Hate Speech Detection, Yang&#39;s Blog">
    <meta name="description" content="CS Student / NLP Enthusiast / Tireless Coder">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Twitter Hate Speech Detection | Yang&#39;s Blog</title>
    <link rel="icon" type="image/png" href="/Hexo-Blog/favicon.png">

    <link rel="stylesheet" type="text/css" href="/Hexo-Blog/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/Hexo-Blog/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/Hexo-Blog/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/Hexo-Blog/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/Hexo-Blog/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/Hexo-Blog/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/Hexo-Blog/css/my.css">
    
    <script src="/Hexo-Blog/libs/jquery/jquery.min.js"></script>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"></head>




<body>
    
        <!--  加载动画，强制加载0.5s  -->
        <style type="text/css">
    #loading-container{
    position: fixed;
    top: 0;
    left: 0;
    min-height: 100vh;
    width: 100vw;
    z-index: 9999;
    display: flex;
    flex-direction: column;
    justify-content: center;
    align-items: center;
    background: #FFF;
    text-align: center;
    /* loader页面消失采用渐隐的方式*/
    -webkit-transition: opacity 1s ease;
    -moz-transition: opacity 1s ease;
    -o-transition: opacity 1s ease;
    transition: opacity 1s ease;
}
.loading-image{
    width: 120px;
    height: 50px;
    transform: translate(-50%);
}

.loading-image div:nth-child(2) {
    -webkit-animation: pacman-balls 1s linear 0s infinite;
    animation: pacman-balls 1s linear 0s infinite
}

.loading-image div:nth-child(3) {
    -webkit-animation: pacman-balls 1s linear .33s infinite;
    animation: pacman-balls 1s linear .33s infinite
}

.loading-image div:nth-child(4) {
    -webkit-animation: pacman-balls 1s linear .66s infinite;
    animation: pacman-balls 1s linear .66s infinite
}

.loading-image div:nth-child(5) {
    -webkit-animation: pacman-balls 1s linear .99s infinite;
    animation: pacman-balls 1s linear .99s infinite
}

.loading-image div:first-of-type {
    width: 0;
    height: 0;
    border: 25px solid #49b1f5;
    border-right-color: transparent;
    border-radius: 25px;
    -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
    animation: rotate_pacman_half_up .5s 0s infinite;
}
.loading-image div:nth-child(2) {
    width: 0;
    height: 0;
    border: 25px solid #49b1f5;
    border-right-color: transparent;
    border-radius: 25px;
    -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
    animation: rotate_pacman_half_down .5s 0s infinite;
    margin-top: -50px;
}
@-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

@keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

@-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

@keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

@-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

@keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


.loading-image div:nth-child(3),
.loading-image div:nth-child(4),
.loading-image div:nth-child(5),
.loading-image div:nth-child(6){
    background-color: #49b1f5;
    width: 15px;
    height: 15px;
    border-radius: 100%;
    margin: 2px;
    width: 10px;
    height: 10px;
    position: absolute;
    transform: translateY(-6.25px);
    top: 25px;
    left: 100px;
}
.loading-text{
    margin-bottom: 20vh;
    text-align: center;
    color: #2c3e50;
    font-size: 2rem;
    box-sizing: border-box;
    padding: 0 10px;
    text-shadow: 0 2px 10px rgba(0,0,0,0.2);
}
@media only screen and (max-width: 500px) {
    .loading-text{
        font-size: 1.5rem;
    }
}
.fadeout {
    opacity: 0;
    filter: alpha(opacity=0);
}
/* logo出现动画 */
@-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
@keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
</style>
<div id="loading-container">
    <p class="loading-text">Shhh ~ stealing pages from the server ... </p>
    <div class="loading-image">
        <div></div>
        <div></div>
        <div></div>
        <div></div>
        <div></div>
        <div></div>
    </div>
</div>
<script>
    (function () {
        const loaded = function () {
            setTimeout(function () {
                const loader = document.getElementById("loading-container");
                loader.className = "fadeout";
                setTimeout(function () {
                    loader.style.display = "none";
                }, 500);
            }, 500);
        };
        loaded();
    })();
</script>
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Hexo-Blog/" class="waves-effect waves-light">
                    
                    <img src="/Hexo-Blog/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Yang&#39;s Blog</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Hexo-Blog/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>Index</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Hexo-Blog/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>Tags</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Hexo-Blog/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>Categories</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Hexo-Blog/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>Archives</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Hexo-Blog/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>About</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Hexo-Blog/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>Contact</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Hexo-Blog/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>Friends</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="Search" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Hexo-Blog/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Yang&#39;s Blog</div>
        <div class="logo-desc">
            
            CS Student / NLP Enthusiast / Tireless Coder
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Hexo-Blog/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			Index
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Hexo-Blog/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			Tags
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Hexo-Blog/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			Categories
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Hexo-Blog/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			Archives
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Hexo-Blog/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			About
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Hexo-Blog/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			Contact
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Hexo-Blog/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			Friends
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/penguinwang96825" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/penguinwang96825" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    
<script src="/Hexo-Blog/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('Please enter the password to access this article!')).toString(CryptoJS.enc.Hex)) {
                alert('Wrong password, will return to the home page!');
                location.href = '/Hexo-Blog/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('https://github.com/penguinwang96825/penguinwang96825.github.io/blob/master/2021/02/07/2021-02-07-twitter-hate-speech-detection/alexander-shatov.jpg?raw=true')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Twitter Hate Speech Detection</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/Hexo-Blog/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Hexo-Blog/tags/Python/">
                                <span class="chip bg-color">Python</span>
                            </a>
                        
                            <a href="/Hexo-Blog/tags/PyTorch/">
                                <span class="chip bg-color">PyTorch</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Hexo-Blog/categories/NLP/" class="post-category">
                                NLP
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>Publish Date:&nbsp;&nbsp;
                    2021-02-07
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>Word Count:&nbsp;&nbsp;
                    4.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>Read Times:&nbsp;&nbsp;
                    26 Min
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>Read Count:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/Hexo-Blog/libs/prism/prism.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <link rel="stylesheet" type="text&#x2F;css" href="https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css"><p>The objective of this task is to detect hate speech in tweets. For the sake of simplicity, let’s say a tweet contains hate speech if it has a racist or sexist sentiment associated with it. So, the task is to classify racist or sexist tweets from other tweets.</p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Hate  speech  is  an  unfortunately  common  occurrence  on  the  Internet.  Often social media sites like Facebook and Twitter face the problem of identifying and censoring  problematic  posts  while weighing the right to freedom of speech. The  importance  of  detecting  and  moderating hate  speech  is  evident  from  the  strong  connection between hate speech and actual hate crimes. Early identification of users promoting  hate  speech  could  enable  outreach  programs that attempt to prevent an escalation from speech to action. Sites such as Twitter and Facebook have been seeking  to  actively  combat  hate  speech. In spite of these reasons, NLP research on hate speech has been very limited, primarily due to the lack of a general definition of hate speech, an analysis of its demographic influences, and an investigation of the most effective features.</p>
<p>Formally, given a training sample of tweets and labels, where label ‘1’ denotes the tweet is racist/sexist and label ‘0’ denotes the tweet is not racist/sexist, our objective is to predict the labels on the test dataset.</p>
<h1 id="Import-Libraries"><a href="#Import-Libraries" class="headerlink" title="Import Libraries"></a>Import Libraries</h1><p>Let’s import the packages we need.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> os
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'CUDA_LAUNCH_BLOCKING'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"1"</span>

<span class="token keyword">import</span> re
<span class="token keyword">import</span> string
<span class="token keyword">import</span> swifter
<span class="token keyword">import</span> nltk
<span class="token keyword">import</span> random
<span class="token keyword">import</span> tez
<span class="token keyword">import</span> transformers
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> seaborn <span class="token keyword">as</span> sns
<span class="token keyword">from</span> wordcloud <span class="token keyword">import</span> WordCloud<span class="token punctuation">,</span> STOPWORDS
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AdamW<span class="token punctuation">,</span> get_linear_schedule_with_warmup
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> metrics<span class="token punctuation">,</span> model_selection<span class="token punctuation">,</span> preprocessing
<span class="token keyword">from</span> tez<span class="token punctuation">.</span>callbacks <span class="token keyword">import</span> EarlyStopping
<span class="token keyword">from</span> tez<span class="token punctuation">.</span>callbacks <span class="token keyword">import</span> CallbackRunner
<span class="token keyword">from</span> tez <span class="token keyword">import</span> enums
<span class="token keyword">from</span> tez<span class="token punctuation">.</span>utils <span class="token keyword">import</span> AverageMeter
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> collections <span class="token keyword">import</span> defaultdict
<span class="token keyword">from</span> collections <span class="token keyword">import</span> Counter
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>Set the random seed, it’s useful for reproducing the issues.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">seed_everything</span><span class="token punctuation">(</span>seed<span class="token operator">=</span><span class="token number">914</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>
    os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'PYTHONHASHSEED'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">str</span><span class="token punctuation">(</span>seed<span class="token punctuation">)</span>
    np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>
    torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>
    torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>
    torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>deterministic <span class="token operator">=</span> <span class="token boolean">True</span>

seed_everything<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>Some util functions refered from <a target="_blank" rel="noopener" href="https://www.kaggle.com/bminixhofer/a-validation-framework-impact-of-the-random-seed">here</a>.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">threshold_search</span><span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_proba<span class="token punctuation">)</span><span class="token punctuation">:</span>
    best_threshold <span class="token operator">=</span> <span class="token number">0</span>
    best_score <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> threshold <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span><span class="token punctuation">[</span>i <span class="token operator">*</span> <span class="token number">0.01</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> disable<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        score <span class="token operator">=</span> metrics<span class="token punctuation">.</span>f1_score<span class="token punctuation">(</span>y_true<span class="token operator">=</span>y_true<span class="token punctuation">,</span> y_pred<span class="token operator">=</span>y_proba <span class="token operator">></span> threshold<span class="token punctuation">)</span>
        <span class="token keyword">if</span> score <span class="token operator">></span> best_score<span class="token punctuation">:</span>
            best_threshold <span class="token operator">=</span> threshold
            best_score <span class="token operator">=</span> score
    search_result <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'threshold'</span><span class="token punctuation">:</span> best_threshold<span class="token punctuation">,</span> <span class="token string">'f1'</span><span class="token punctuation">:</span> best_score<span class="token punctuation">&#125;</span>
    <span class="token keyword">return</span> search_result<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h1 id="Configurations"><a href="#Configurations" class="headerlink" title="Configurations"></a>Configurations</h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">DictObj</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dictionary<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">import</span> pprint
        self<span class="token punctuation">.</span><span class="token builtin">map</span> <span class="token operator">=</span> dictionary
        pprint<span class="token punctuation">.</span>pprint<span class="token punctuation">(</span>dictionary<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">__setattr__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> name<span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> name <span class="token operator">==</span> <span class="token string">'map'</span><span class="token punctuation">:</span>
            <span class="token comment"># print("init set attr", name ,"value:", value)</span>
            <span class="token builtin">object</span><span class="token punctuation">.</span>__setattr__<span class="token punctuation">(</span>self<span class="token punctuation">,</span> name<span class="token punctuation">,</span> value<span class="token punctuation">)</span>
            <span class="token keyword">return</span>
        <span class="token comment"># print('set attr called ', name, value)</span>
        self<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> value

    <span class="token keyword">def</span> <span class="token function">__getattr__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> name<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># print('get attr called ', name)</span>
        <span class="token keyword">return</span>  self<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">[</span>name<span class="token punctuation">]</span>

PARAM <span class="token operator">=</span> DictObj<span class="token punctuation">(</span><span class="token punctuation">&#123;</span>
    <span class="token string">'NUM_CLASSES'</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span> 
    <span class="token string">'MAX_LENGTH'</span><span class="token punctuation">:</span> <span class="token number">256</span><span class="token punctuation">,</span> 
    <span class="token string">'TRAIN_BATCH_SIZE'</span><span class="token punctuation">:</span> <span class="token number">8</span><span class="token punctuation">,</span> 
    <span class="token string">'VALID_BATCH_SIZE'</span><span class="token punctuation">:</span> <span class="token number">16</span><span class="token punctuation">,</span> 
    <span class="token string">'EPOCH'</span><span class="token punctuation">:</span> <span class="token number">5</span><span class="token punctuation">,</span> 
    <span class="token string">'DEVICE'</span><span class="token punctuation">:</span> <span class="token string">"cuda"</span><span class="token punctuation">,</span> 
    <span class="token string">'N_JOB'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> 
    <span class="token string">'FP16'</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">,</span> 
    <span class="token string">'ES_PATIENCE'</span><span class="token punctuation">:</span> <span class="token number">10</span><span class="token punctuation">,</span> 
    <span class="token string">'TF_LOG'</span><span class="token punctuation">:</span> <span class="token string">"./logs/"</span><span class="token punctuation">,</span> 
    <span class="token string">'MODEL_SAVE_PATH'</span><span class="token punctuation">:</span> <span class="token string">"./models/bert.bin"</span>
<span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h1 id="EDA"><a href="#EDA" class="headerlink" title="EDA"></a>EDA</h1><p>Load the data.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">dfx <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"./data/train.csv"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>Visualise the wordcloud. You can download the font from <a href="https://penguinwang96825.github.io/Hexo-Blog/download/CabinSketch-Bold.ttf">here</a>.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">more_stopwords <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token string">'oh'</span><span class="token punctuation">,</span> <span class="token string">'will'</span><span class="token punctuation">,</span> <span class="token string">'hey'</span><span class="token punctuation">,</span> <span class="token string">'yet'</span><span class="token punctuation">,</span> <span class="token string">'ye'</span><span class="token punctuation">,</span> <span class="token string">'really'</span><span class="token punctuation">,</span> 
    <span class="token string">'make'</span><span class="token punctuation">,</span> <span class="token string">'amp'</span><span class="token punctuation">,</span> <span class="token string">'via'</span><span class="token punctuation">,</span> <span class="token string">'ð'</span><span class="token punctuation">,</span> <span class="token string">'¼'</span><span class="token punctuation">,</span> <span class="token string">'â'</span><span class="token punctuation">&#125;</span>
STOPWORDS <span class="token operator">=</span> STOPWORDS<span class="token punctuation">.</span>union<span class="token punctuation">(</span>more_stopwords<span class="token punctuation">)</span>
corpus <span class="token operator">=</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>dfx<span class="token punctuation">[</span><span class="token string">'tweet'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
no_urls_no_tags <span class="token operator">=</span> <span class="token string">" "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span>word <span class="token keyword">for</span> word <span class="token keyword">in</span> corpus<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>
                            <span class="token keyword">if</span> <span class="token string">'http'</span> <span class="token keyword">not</span> <span class="token keyword">in</span> word
                                <span class="token keyword">and</span> <span class="token keyword">not</span> word<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">'@'</span><span class="token punctuation">)</span>
                                <span class="token keyword">and</span> <span class="token keyword">not</span> word<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">'#'</span><span class="token punctuation">)</span>
                                <span class="token keyword">and</span> word <span class="token operator">!=</span> <span class="token string">'RT'</span>
                            <span class="token punctuation">]</span><span class="token punctuation">)</span>
wordcloud <span class="token operator">=</span> WordCloud<span class="token punctuation">(</span>
    font_path<span class="token operator">=</span><span class="token string">r"CabinSketch-Bold.ttf"</span><span class="token punctuation">,</span> 
    stopwords<span class="token operator">=</span>STOPWORDS<span class="token punctuation">,</span>
    background_color<span class="token operator">=</span><span class="token string">'black'</span><span class="token punctuation">,</span>
    width<span class="token operator">=</span><span class="token number">2500</span><span class="token punctuation">,</span>
    height<span class="token operator">=</span><span class="token number">1400</span>
<span class="token punctuation">)</span><span class="token punctuation">.</span>generate<span class="token punctuation">(</span>no_urls_no_tags<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>wordcloud<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">'off'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<img src="/Hexo-Blog/2021/02/07/2021-02-07-twitter-hate-speech-detection/wordcloud.png" class="">

<p>Clean the data.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">nltk<span class="token punctuation">.</span>download<span class="token punctuation">(</span><span class="token string">'words'</span><span class="token punctuation">)</span>
words <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span>nltk<span class="token punctuation">.</span>corpus<span class="token punctuation">.</span>words<span class="token punctuation">.</span>words<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">clean_tweets</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    text <span class="token operator">=</span> strip_links<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
    text <span class="token operator">=</span> strip_all_entities<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
    text <span class="token operator">=</span> strip_non_english_words<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
    <span class="token keyword">return</span> text

<span class="token keyword">def</span> <span class="token function">strip_links</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    link_regex <span class="token operator">=</span> re<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span><span class="token string">'((https?):((//)|(\\\\))+([\w\d:#@%/;$()~_?\+-=\\\.&amp;](#!)?)*)'</span><span class="token punctuation">,</span> re<span class="token punctuation">.</span>DOTALL<span class="token punctuation">)</span>
    links <span class="token operator">=</span> re<span class="token punctuation">.</span>findall<span class="token punctuation">(</span>link_regex<span class="token punctuation">,</span> text<span class="token punctuation">)</span>
    <span class="token keyword">for</span> link <span class="token keyword">in</span> links<span class="token punctuation">:</span>
        text <span class="token operator">=</span> text<span class="token punctuation">.</span>replace<span class="token punctuation">(</span>link<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'[LINK]'</span><span class="token punctuation">)</span>    
    <span class="token keyword">return</span> text

<span class="token keyword">def</span> <span class="token function">strip_all_entities</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    entity_prefixes <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'@'</span><span class="token punctuation">,</span> <span class="token string">'#'</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> separator <span class="token keyword">in</span> string<span class="token punctuation">.</span>punctuation<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"["</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"]"</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> separator <span class="token keyword">not</span> <span class="token keyword">in</span> entity_prefixes<span class="token punctuation">:</span>
            text <span class="token operator">=</span> text<span class="token punctuation">.</span>replace<span class="token punctuation">(</span>separator<span class="token punctuation">,</span><span class="token string">' '</span><span class="token punctuation">)</span>
    words <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> word <span class="token keyword">in</span> text<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        word <span class="token operator">=</span> word<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> word<span class="token punctuation">:</span>
            <span class="token keyword">if</span> word<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">not</span> <span class="token keyword">in</span> entity_prefixes<span class="token punctuation">:</span>
                words<span class="token punctuation">.</span>append<span class="token punctuation">(</span>word<span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>words<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">strip_non_english_words</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> text<span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token string">'ascii'</span><span class="token punctuation">,</span> errors<span class="token operator">=</span><span class="token string">'ignore'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">"ascii"</span><span class="token punctuation">,</span> errors<span class="token operator">=</span><span class="token string">"ignore"</span><span class="token punctuation">)</span>

dfx<span class="token punctuation">[</span><span class="token string">"review"</span><span class="token punctuation">]</span> <span class="token operator">=</span> dfx<span class="token punctuation">[</span><span class="token string">"tweet"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>swifter<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>clean_tweets<span class="token punctuation">)</span>
dfx<span class="token punctuation">[</span><span class="token string">"length"</span><span class="token punctuation">]</span> <span class="token operator">=</span> dfx<span class="token punctuation">[</span><span class="token string">"review"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>swifter<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">)</span>
dfx <span class="token operator">=</span> dfx<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>dfx<span class="token punctuation">[</span>dfx<span class="token punctuation">.</span>length <span class="token operator">&lt;</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">.</span>index<span class="token punctuation">)</span>
dfx <span class="token operator">=</span> dfx<span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span>drop<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>Split the data.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">df_train<span class="token punctuation">,</span> df_valid <span class="token operator">=</span> model_selection<span class="token punctuation">.</span>train_test_split<span class="token punctuation">(</span>
    dfx<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">,</span> stratify<span class="token operator">=</span>dfx<span class="token punctuation">.</span>label<span class="token punctuation">.</span>values
<span class="token punctuation">)</span>

df_train <span class="token operator">=</span> df_train<span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span>drop<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
df_valid <span class="token operator">=</span> df_valid<span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span>drop<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>Calculate weight for imbalanced dataset.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">class_sample_count <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token builtin">len</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>df_train<span class="token punctuation">.</span>label<span class="token operator">==</span>t<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> t <span class="token keyword">in</span> np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>df_train<span class="token punctuation">.</span>label<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
weight <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span> <span class="token operator">/</span> class_sample_count<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<img src="/Hexo-Blog/2021/02/07/2021-02-07-twitter-hate-speech-detection/imb.png" class="">

<h1 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h1><p>Let’s create a <code>Dataset()</code> class for our twitter hate speech dataset.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">TwitterDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> review<span class="token punctuation">,</span> target<span class="token punctuation">,</span> max_len<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>review <span class="token operator">=</span> review
        self<span class="token punctuation">.</span>target <span class="token operator">=</span> target
        self<span class="token punctuation">.</span>tokenizer <span class="token operator">=</span> transformers<span class="token punctuation">.</span>BertTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
            <span class="token string">"bert-base-uncased"</span><span class="token punctuation">,</span> do_lower_case<span class="token operator">=</span><span class="token boolean">True</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>max_len <span class="token operator">=</span> max_len

    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>review<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">)</span><span class="token punctuation">:</span>
        review <span class="token operator">=</span> <span class="token builtin">str</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>review<span class="token punctuation">[</span>item<span class="token punctuation">]</span><span class="token punctuation">)</span>
        review <span class="token operator">=</span> <span class="token string">" "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>review<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        inputs <span class="token operator">=</span> self<span class="token punctuation">.</span>tokenizer<span class="token punctuation">.</span>encode_plus<span class="token punctuation">(</span>
            review<span class="token punctuation">,</span>
            <span class="token boolean">None</span><span class="token punctuation">,</span>
            add_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
            max_length<span class="token operator">=</span>self<span class="token punctuation">.</span>max_len<span class="token punctuation">,</span>
            padding<span class="token operator">=</span><span class="token string">"max_length"</span><span class="token punctuation">,</span>
            truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> 
            return_tensors<span class="token operator">=</span><span class="token string">'pt'</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>

        input_ids <span class="token operator">=</span> inputs<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>
        attention_mask <span class="token operator">=</span> inputs<span class="token punctuation">[</span><span class="token string">"attention_mask"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> <span class="token punctuation">&#123;</span>
            <span class="token string">"ids"</span><span class="token punctuation">:</span> input_ids<span class="token punctuation">,</span>
            <span class="token string">"mask"</span><span class="token punctuation">:</span> attention_mask<span class="token punctuation">,</span>
            <span class="token string">"targets"</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>self<span class="token punctuation">.</span>target<span class="token punctuation">[</span>item<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span>
        <span class="token punctuation">&#125;</span>

train_dataset <span class="token operator">=</span> TwitterDataset<span class="token punctuation">(</span>df_train<span class="token punctuation">.</span>review<span class="token punctuation">.</span>values<span class="token punctuation">,</span> df_train<span class="token punctuation">.</span>label<span class="token punctuation">.</span>values<span class="token punctuation">,</span> max_len<span class="token operator">=</span>PARAM<span class="token punctuation">.</span>MAX_LENGTH<span class="token punctuation">)</span>
valid_dataset <span class="token operator">=</span> TwitterDataset<span class="token punctuation">(</span>df_valid<span class="token punctuation">.</span>review<span class="token punctuation">.</span>values<span class="token punctuation">,</span> df_valid<span class="token punctuation">.</span>label<span class="token punctuation">.</span>values<span class="token punctuation">,</span> max_len<span class="token operator">=</span>PARAM<span class="token punctuation">.</span>MAX_LENGTH<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>We have 24575 training data and 6144 validation data.</p>
<h1 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h1><p>I will use Tez, a simple pytorch trainer, to build our neural network. Tez is a simple, to-the-point, library to make your pytorch training easy.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">TwitterClassifier</span><span class="token punctuation">(</span>tez<span class="token punctuation">.</span>Model<span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_train_steps<span class="token punctuation">,</span> num_classes<span class="token punctuation">,</span> weight<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span><span class="token string">"lamb"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>tokenizer <span class="token operator">=</span> transformers<span class="token punctuation">.</span>BertTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
            <span class="token string">"bert-base-uncased"</span><span class="token punctuation">,</span> do_lower_case<span class="token operator">=</span><span class="token boolean">True</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bert <span class="token operator">=</span> transformers<span class="token punctuation">.</span>BertModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
            <span class="token string">"bert-base-uncased"</span><span class="token punctuation">,</span> 
            return_dict<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bert_drop <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.3</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>out <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>bert<span class="token punctuation">.</span>config<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>num_train_steps <span class="token operator">=</span> num_train_steps
        self<span class="token punctuation">.</span>step_scheduler_after <span class="token operator">=</span> <span class="token string">"batch"</span>
        self<span class="token punctuation">.</span>optimizer <span class="token operator">=</span> optimizer
        self<span class="token punctuation">.</span>history <span class="token operator">=</span> defaultdict<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">)</span>
        
        <span class="token keyword">if</span> weight <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>weight <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>weight<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">fetch_optimizer</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        param_optimizer <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        no_decay <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"bias"</span><span class="token punctuation">,</span> <span class="token string">"LayerNorm.bias"</span><span class="token punctuation">]</span>
        optimizer_parameters <span class="token operator">=</span> <span class="token punctuation">[</span>
            <span class="token punctuation">&#123;</span>
                <span class="token string">"params"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>
                    p <span class="token keyword">for</span> n<span class="token punctuation">,</span> p <span class="token keyword">in</span> param_optimizer <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">any</span><span class="token punctuation">(</span>nd <span class="token keyword">in</span> n <span class="token keyword">for</span> nd <span class="token keyword">in</span> no_decay<span class="token punctuation">)</span>
                <span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token string">"weight_decay"</span><span class="token punctuation">:</span> <span class="token number">0.001</span><span class="token punctuation">,</span>
            <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
            <span class="token punctuation">&#123;</span>
                <span class="token string">"params"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>
                    p <span class="token keyword">for</span> n<span class="token punctuation">,</span> p <span class="token keyword">in</span> param_optimizer <span class="token keyword">if</span> <span class="token builtin">any</span><span class="token punctuation">(</span>nd <span class="token keyword">in</span> n <span class="token keyword">for</span> nd <span class="token keyword">in</span> no_decay<span class="token punctuation">)</span>
                <span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token string">"weight_decay"</span><span class="token punctuation">:</span> <span class="token number">0.0</span><span class="token punctuation">,</span>
            <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
        <span class="token punctuation">]</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>optimizer <span class="token operator">==</span> <span class="token string">"adam"</span><span class="token punctuation">:</span>
            opt <span class="token operator">=</span> AdamW<span class="token punctuation">(</span>optimizer_parameters<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">3e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span>
        <span class="token keyword">elif</span> self<span class="token punctuation">.</span>optimizer <span class="token operator">==</span> <span class="token string">"lamb"</span><span class="token punctuation">:</span>
            opt <span class="token operator">=</span> Lamb<span class="token punctuation">(</span>optimizer_parameters<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">3e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">.01</span><span class="token punctuation">,</span> betas<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">.9</span><span class="token punctuation">,</span> <span class="token number">.999</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> opt

    <span class="token keyword">def</span> <span class="token function">fetch_scheduler</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        sch <span class="token operator">=</span> get_linear_schedule_with_warmup<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>optimizer<span class="token punctuation">,</span> num_warmup_steps<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> num_training_steps<span class="token operator">=</span>self<span class="token punctuation">.</span>num_train_steps
        <span class="token punctuation">)</span>
        <span class="token keyword">return</span> sch

    <span class="token keyword">def</span> <span class="token function">train_one_epoch</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>model_state <span class="token operator">=</span> enums<span class="token punctuation">.</span>ModelState<span class="token punctuation">.</span>TRAIN
        losses <span class="token operator">=</span> AverageMeter<span class="token punctuation">(</span><span class="token punctuation">)</span>
        tk0 <span class="token operator">=</span> tqdm<span class="token punctuation">(</span>data_loader<span class="token punctuation">,</span> total<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> b_idx<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>tk0<span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>train_state <span class="token operator">=</span> enums<span class="token punctuation">.</span>TrainingState<span class="token punctuation">.</span>TRAIN_STEP_START
            loss<span class="token punctuation">,</span> metrics <span class="token operator">=</span> self<span class="token punctuation">.</span>train_one_step<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>train_state <span class="token operator">=</span> enums<span class="token punctuation">.</span>TrainingState<span class="token punctuation">.</span>TRAIN_STEP_END
            losses<span class="token punctuation">.</span>update<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> data_loader<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span>
            <span class="token keyword">if</span> b_idx <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                metrics_meter <span class="token operator">=</span> <span class="token punctuation">&#123;</span>k<span class="token punctuation">:</span> AverageMeter<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> k <span class="token keyword">in</span> metrics<span class="token punctuation">&#125;</span>
            monitor <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
            <span class="token keyword">for</span> m_m <span class="token keyword">in</span> metrics_meter<span class="token punctuation">:</span>
                metrics_meter<span class="token punctuation">[</span>m_m<span class="token punctuation">]</span><span class="token punctuation">.</span>update<span class="token punctuation">(</span>metrics<span class="token punctuation">[</span>m_m<span class="token punctuation">]</span><span class="token punctuation">,</span> data_loader<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span>
                monitor<span class="token punctuation">[</span>m_m<span class="token punctuation">]</span> <span class="token operator">=</span> metrics_meter<span class="token punctuation">[</span>m_m<span class="token punctuation">]</span><span class="token punctuation">.</span>avg
            self<span class="token punctuation">.</span>current_train_step <span class="token operator">+=</span> <span class="token number">1</span>
            tk0<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span>loss<span class="token operator">=</span>losses<span class="token punctuation">.</span>avg<span class="token punctuation">,</span> stage<span class="token operator">=</span><span class="token string">"train"</span><span class="token punctuation">,</span> <span class="token operator">**</span>monitor<span class="token punctuation">)</span>
        tk0<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>update_metrics<span class="token punctuation">(</span>losses<span class="token operator">=</span>losses<span class="token punctuation">,</span> monitor<span class="token operator">=</span>monitor<span class="token punctuation">)</span>
        <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> monitor<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string-interpolation"><span class="token string">f"train_</span><span class="token interpolation"><span class="token punctuation">&#123;</span>k<span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>v<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">"train_loss"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>losses<span class="token punctuation">.</span>avg<span class="token punctuation">)</span>
        <span class="token keyword">return</span> losses<span class="token punctuation">.</span>avg

    <span class="token keyword">def</span> <span class="token function">validate_one_epoch</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>model_state <span class="token operator">=</span> enums<span class="token punctuation">.</span>ModelState<span class="token punctuation">.</span>VALID
        losses <span class="token operator">=</span> AverageMeter<span class="token punctuation">(</span><span class="token punctuation">)</span>
        tk0 <span class="token operator">=</span> tqdm<span class="token punctuation">(</span>data_loader<span class="token punctuation">,</span> total<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> b_idx<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>tk0<span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>train_state <span class="token operator">=</span> enums<span class="token punctuation">.</span>TrainingState<span class="token punctuation">.</span>VALID_STEP_START
            <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                loss<span class="token punctuation">,</span> metrics <span class="token operator">=</span> self<span class="token punctuation">.</span>validate_one_step<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>train_state <span class="token operator">=</span> enums<span class="token punctuation">.</span>TrainingState<span class="token punctuation">.</span>VALID_STEP_END
            losses<span class="token punctuation">.</span>update<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> data_loader<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span>
            <span class="token keyword">if</span> b_idx <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                metrics_meter <span class="token operator">=</span> <span class="token punctuation">&#123;</span>k<span class="token punctuation">:</span> AverageMeter<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> k <span class="token keyword">in</span> metrics<span class="token punctuation">&#125;</span>
            monitor <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
            <span class="token keyword">for</span> m_m <span class="token keyword">in</span> metrics_meter<span class="token punctuation">:</span>
                metrics_meter<span class="token punctuation">[</span>m_m<span class="token punctuation">]</span><span class="token punctuation">.</span>update<span class="token punctuation">(</span>metrics<span class="token punctuation">[</span>m_m<span class="token punctuation">]</span><span class="token punctuation">,</span> data_loader<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span>
                monitor<span class="token punctuation">[</span>m_m<span class="token punctuation">]</span> <span class="token operator">=</span> metrics_meter<span class="token punctuation">[</span>m_m<span class="token punctuation">]</span><span class="token punctuation">.</span>avg
            tk0<span class="token punctuation">.</span>set_postfix<span class="token punctuation">(</span>loss<span class="token operator">=</span>losses<span class="token punctuation">.</span>avg<span class="token punctuation">,</span> stage<span class="token operator">=</span><span class="token string">"valid"</span><span class="token punctuation">,</span> <span class="token operator">**</span>monitor<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>current_valid_step <span class="token operator">+=</span> <span class="token number">1</span>
        tk0<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>update_metrics<span class="token punctuation">(</span>losses<span class="token operator">=</span>losses<span class="token punctuation">,</span> monitor<span class="token operator">=</span>monitor<span class="token punctuation">)</span>
        <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> monitor<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string-interpolation"><span class="token string">f"valid_</span><span class="token interpolation"><span class="token punctuation">&#123;</span>k<span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>v<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">"valid_loss"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>losses<span class="token punctuation">.</span>avg<span class="token punctuation">)</span>
        <span class="token keyword">return</span> losses<span class="token punctuation">.</span>avg
    
    <span class="token keyword">def</span> <span class="token function">loss</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> targets <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> <span class="token boolean">None</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>weight <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>weight <span class="token operator">=</span> self<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>to<span class="token punctuation">(</span>self<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
        <span class="token keyword">return</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span>self<span class="token punctuation">.</span>weight<span class="token punctuation">)</span><span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">monitor_metrics</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> targets <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
        outputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
        targets <span class="token operator">=</span> targets<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
        accuracy <span class="token operator">=</span> metrics<span class="token punctuation">.</span>accuracy_score<span class="token punctuation">(</span>targets<span class="token punctuation">,</span> outputs<span class="token punctuation">)</span>
        f1_score <span class="token operator">=</span> metrics<span class="token punctuation">.</span>f1_score<span class="token punctuation">(</span>targets<span class="token punctuation">,</span> outputs<span class="token punctuation">,</span> average<span class="token operator">=</span><span class="token string">'weighted'</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token punctuation">&#123;</span><span class="token string">"accuracy"</span><span class="token punctuation">:</span> accuracy<span class="token punctuation">,</span> <span class="token string">"f1"</span><span class="token punctuation">:</span> f1_score<span class="token punctuation">&#125;</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> ids<span class="token punctuation">,</span> mask<span class="token punctuation">,</span> targets<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        last_hidden_states <span class="token operator">=</span> self<span class="token punctuation">.</span>bert<span class="token punctuation">(</span>ids<span class="token punctuation">,</span> attention_mask<span class="token operator">=</span>mask<span class="token punctuation">)</span>
        b_o <span class="token operator">=</span> self<span class="token punctuation">.</span>bert_drop<span class="token punctuation">(</span>last_hidden_states<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        output <span class="token operator">=</span> self<span class="token punctuation">.</span>out<span class="token punctuation">(</span>b_o<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> self<span class="token punctuation">.</span>loss<span class="token punctuation">(</span>output<span class="token punctuation">,</span> targets<span class="token punctuation">)</span>
        acc <span class="token operator">=</span> self<span class="token punctuation">.</span>monitor_metrics<span class="token punctuation">(</span>output<span class="token punctuation">,</span> targets<span class="token punctuation">)</span>
        <span class="token keyword">return</span> output<span class="token punctuation">,</span> loss<span class="token punctuation">,</span> acc

    <span class="token keyword">def</span> <span class="token function">score</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> test_dataset<span class="token punctuation">,</span> n_jobs<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        
        <span class="token keyword">def</span> <span class="token function">softmax</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        
        prediction <span class="token operator">=</span> self<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>test_dataset<span class="token punctuation">,</span> n_jobs<span class="token operator">=</span>n_jobs<span class="token punctuation">)</span>
        prediction <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>prediction<span class="token punctuation">)</span>
        prediction <span class="token operator">=</span> softmax<span class="token punctuation">(</span>np<span class="token punctuation">.</span>vstack<span class="token punctuation">(</span>prediction<span class="token punctuation">)</span><span class="token punctuation">)</span>
        prediction <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>prediction<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        groud_truth <span class="token operator">=</span> test_dataset<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"target"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>int64<span class="token punctuation">)</span>
        <span class="token keyword">return</span> metrics<span class="token punctuation">.</span>accuracy_score<span class="token punctuation">(</span>prediction<span class="token punctuation">,</span> groud_truth<span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">plot_history</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">from</span> matplotlib<span class="token punctuation">.</span>ticker <span class="token keyword">import</span> MaxNLocator
        
        train_loss<span class="token punctuation">,</span> valid_loss <span class="token operator">=</span> self<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">"train_loss"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">"valid_loss"</span><span class="token punctuation">]</span>
        train_accuracy<span class="token punctuation">,</span> valid_accuracy <span class="token operator">=</span> self<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">"train_accuracy"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">"valid_accuracy"</span><span class="token punctuation">]</span>

        plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">"figure.figsize"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">6</span>
        ax1 <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        ax1<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_loss<span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> train_loss<span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">"tab:blue"</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"train"</span><span class="token punctuation">)</span>
        ax1<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>valid_loss<span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> valid_loss<span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">"tab:orange"</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"valid"</span><span class="token punctuation">)</span>
        ax1<span class="token punctuation">.</span>xaxis<span class="token punctuation">.</span>set_major_locator<span class="token punctuation">(</span>MaxNLocator<span class="token punctuation">(</span>integer<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        ax1<span class="token punctuation">.</span>title<span class="token punctuation">.</span>set_text<span class="token punctuation">(</span><span class="token string">'Loss'</span><span class="token punctuation">)</span>
        ax1<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token punctuation">)</span>
        ax2 <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
        ax2<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_accuracy<span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> train_accuracy<span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">"tab:blue"</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"train"</span><span class="token punctuation">)</span>
        ax2<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>valid_accuracy<span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> valid_accuracy<span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">"tab:orange"</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"valid"</span><span class="token punctuation">)</span>
        ax2<span class="token punctuation">.</span>xaxis<span class="token punctuation">.</span>set_major_locator<span class="token punctuation">(</span>MaxNLocator<span class="token punctuation">(</span>integer<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        ax2<span class="token punctuation">.</span>title<span class="token punctuation">.</span>set_text<span class="token punctuation">(</span><span class="token string">'Accuracy'</span><span class="token punctuation">)</span>
        ax2<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>Training large deep neural networks on massive datasets is computationally very<br>challenging.  In Yang You’s <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1904.00962.pdf">paper</a>, they first study a principled layerwise adaptation strategy to accelerate training of deep neural networks using large mini-batches. Using this strategy, they develop a new layerwise adaptive large batch optimization technique called <code>LAMB</code>. The <code>LAMB</code> implementation is available <a target="_blank" rel="noopener" href="https://github.com/tensorflow/addons/blob/master/tensorflow_addons/optimizers/lamb.py">online</a>.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Lamb</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Optimizer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">r"""Implements Lamb algorithm.
    It has been proposed in `Large Batch Optimization for Deep Learning: Training BERT in 76 minutes`_.
    Arguments:
        params (iterable): iterable of parameters to optimize or dicts defining
            parameter groups
        lr (float, optional): learning rate (default: 1e-3)
        betas (Tuple[float, float], optional): coefficients used for computing
            running averages of gradient and its square (default: (0.9, 0.999))
        eps (float, optional): term added to the denominator to improve
            numerical stability (default: 1e-8)
        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)
        adam (bool, optional): always use trust ratio = 1, which turns this into
            Adam. Useful for comparison purposes.
    .. _Large Batch Optimization for Deep Learning: Training BERT in 76 minutes:
        https://arxiv.org/abs/1904.00962
    """</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> params<span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">,</span> betas<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.9</span><span class="token punctuation">,</span> <span class="token number">0.999</span><span class="token punctuation">)</span><span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">,</span>
                 weight_decay<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> adam<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token number">0.0</span> <span class="token operator">&lt;=</span> lr<span class="token punctuation">:</span>
            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">"Invalid learning rate: &#123;&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>lr<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token number">0.0</span> <span class="token operator">&lt;=</span> eps<span class="token punctuation">:</span>
            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">"Invalid epsilon value: &#123;&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>eps<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token number">0.0</span> <span class="token operator">&lt;=</span> betas<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> <span class="token number">1.0</span><span class="token punctuation">:</span>
            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">"Invalid beta parameter at index 0: &#123;&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>betas<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token number">0.0</span> <span class="token operator">&lt;=</span> betas<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> <span class="token number">1.0</span><span class="token punctuation">:</span>
            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">"Invalid beta parameter at index 1: &#123;&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>betas<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        defaults <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>lr<span class="token operator">=</span>lr<span class="token punctuation">,</span> betas<span class="token operator">=</span>betas<span class="token punctuation">,</span> eps<span class="token operator">=</span>eps<span class="token punctuation">,</span>
                        weight_decay<span class="token operator">=</span>weight_decay<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>adam <span class="token operator">=</span> adam
        <span class="token builtin">super</span><span class="token punctuation">(</span>Lamb<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>params<span class="token punctuation">,</span> defaults<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> closure<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Performs a single optimization step.
        Arguments:
            closure (callable, optional): A closure that reevaluates the model
                and returns the loss.
        """</span>
        loss <span class="token operator">=</span> <span class="token boolean">None</span>
        <span class="token keyword">if</span> closure <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            loss <span class="token operator">=</span> closure<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">for</span> group <span class="token keyword">in</span> self<span class="token punctuation">.</span>param_groups<span class="token punctuation">:</span>
            <span class="token keyword">for</span> p <span class="token keyword">in</span> group<span class="token punctuation">[</span><span class="token string">'params'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
                <span class="token keyword">if</span> p<span class="token punctuation">.</span>grad <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                    <span class="token keyword">continue</span>
                grad <span class="token operator">=</span> p<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data
                <span class="token keyword">if</span> grad<span class="token punctuation">.</span>is_sparse<span class="token punctuation">:</span>
                    <span class="token keyword">raise</span> RuntimeError<span class="token punctuation">(</span><span class="token string">'Lamb does not support sparse gradients, consider SparseAdam instad.'</span><span class="token punctuation">)</span>

                state <span class="token operator">=</span> self<span class="token punctuation">.</span>state<span class="token punctuation">[</span>p<span class="token punctuation">]</span>

                <span class="token comment"># State initialization</span>
                <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>state<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                    state<span class="token punctuation">[</span><span class="token string">'step'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
                    <span class="token comment"># Exponential moving average of gradient values</span>
                    state<span class="token punctuation">[</span><span class="token string">'exp_avg'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>p<span class="token punctuation">.</span>data<span class="token punctuation">)</span>
                    <span class="token comment"># Exponential moving average of squared gradient values</span>
                    state<span class="token punctuation">[</span><span class="token string">'exp_avg_sq'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>p<span class="token punctuation">.</span>data<span class="token punctuation">)</span>

                exp_avg<span class="token punctuation">,</span> exp_avg_sq <span class="token operator">=</span> state<span class="token punctuation">[</span><span class="token string">'exp_avg'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> state<span class="token punctuation">[</span><span class="token string">'exp_avg_sq'</span><span class="token punctuation">]</span>
                beta1<span class="token punctuation">,</span> beta2 <span class="token operator">=</span> group<span class="token punctuation">[</span><span class="token string">'betas'</span><span class="token punctuation">]</span>

                state<span class="token punctuation">[</span><span class="token string">'step'</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>

                <span class="token comment"># Decay the first and second moment running average coefficient</span>
                <span class="token comment"># m_t</span>
                exp_avg<span class="token punctuation">.</span>mul_<span class="token punctuation">(</span>beta1<span class="token punctuation">)</span><span class="token punctuation">.</span>add_<span class="token punctuation">(</span>grad<span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">1</span> <span class="token operator">-</span> beta1<span class="token punctuation">)</span>
                <span class="token comment"># v_t</span>
                exp_avg_sq<span class="token punctuation">.</span>mul_<span class="token punctuation">(</span>beta2<span class="token punctuation">)</span><span class="token punctuation">.</span>addcmul_<span class="token punctuation">(</span>grad<span class="token punctuation">,</span> grad<span class="token punctuation">,</span> value<span class="token operator">=</span><span class="token number">1</span> <span class="token operator">-</span> beta2<span class="token punctuation">)</span>

                <span class="token comment"># Paper v3 does not use debiasing.</span>
                <span class="token comment"># bias_correction1 = 1 - beta1 ** state['step']</span>
                <span class="token comment"># bias_correction2 = 1 - beta2 ** state['step']</span>
                <span class="token comment"># Apply bias to lr to avoid broadcast.</span>
                step_size <span class="token operator">=</span> group<span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span> <span class="token comment"># * math.sqrt(bias_correction2) / bias_correction1</span>

                weight_norm <span class="token operator">=</span> p<span class="token punctuation">.</span>data<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>clamp<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>

                adam_step <span class="token operator">=</span> exp_avg <span class="token operator">/</span> exp_avg_sq<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>add<span class="token punctuation">(</span>group<span class="token punctuation">[</span><span class="token string">'eps'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
                <span class="token keyword">if</span> group<span class="token punctuation">[</span><span class="token string">'weight_decay'</span><span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>
                    adam_step<span class="token punctuation">.</span>add_<span class="token punctuation">(</span>p<span class="token punctuation">.</span>data<span class="token punctuation">,</span> alpha<span class="token operator">=</span>group<span class="token punctuation">[</span><span class="token string">'weight_decay'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

                adam_norm <span class="token operator">=</span> adam_step<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token punctuation">)</span>
                <span class="token keyword">if</span> weight_norm <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">or</span> adam_norm <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                    trust_ratio <span class="token operator">=</span> <span class="token number">1</span>
                <span class="token keyword">else</span><span class="token punctuation">:</span>
                    trust_ratio <span class="token operator">=</span> weight_norm <span class="token operator">/</span> adam_norm
                state<span class="token punctuation">[</span><span class="token string">'weight_norm'</span><span class="token punctuation">]</span> <span class="token operator">=</span> weight_norm
                state<span class="token punctuation">[</span><span class="token string">'adam_norm'</span><span class="token punctuation">]</span> <span class="token operator">=</span> adam_norm
                state<span class="token punctuation">[</span><span class="token string">'trust_ratio'</span><span class="token punctuation">]</span> <span class="token operator">=</span> trust_ratio
                <span class="token keyword">if</span> self<span class="token punctuation">.</span>adam<span class="token punctuation">:</span>
                    trust_ratio <span class="token operator">=</span> <span class="token number">1</span>

                p<span class="token punctuation">.</span>data<span class="token punctuation">.</span>add_<span class="token punctuation">(</span>adam_step<span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token operator">-</span>step_size <span class="token operator">*</span> trust_ratio<span class="token punctuation">)</span>

        <span class="token keyword">return</span> loss<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="Start-Training"><a href="#Start-Training" class="headerlink" title="Start Training!"></a>Start Training!</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">n_train_steps <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>df_train<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">32</span> <span class="token operator">*</span> <span class="token number">10</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> TwitterClassifier<span class="token punctuation">(</span>num_train_steps<span class="token operator">=</span>n_train_steps<span class="token punctuation">,</span> num_classes<span class="token operator">=</span>PARAM<span class="token punctuation">.</span>NUM_CLASSES<span class="token punctuation">,</span> weight<span class="token operator">=</span>weight<span class="token punctuation">)</span>

tb_logger <span class="token operator">=</span> tez<span class="token punctuation">.</span>callbacks<span class="token punctuation">.</span>TensorBoardLogger<span class="token punctuation">(</span>log_dir<span class="token operator">=</span>PARAM<span class="token punctuation">.</span>TF_LOG<span class="token punctuation">)</span>
es <span class="token operator">=</span> tez<span class="token punctuation">.</span>callbacks<span class="token punctuation">.</span>EarlyStopping<span class="token punctuation">(</span>monitor<span class="token operator">=</span><span class="token string">"valid_loss"</span><span class="token punctuation">,</span> 
                                 model_path<span class="token operator">=</span>PARAM<span class="token punctuation">.</span>MODEL_SAVE_PATH<span class="token punctuation">,</span> 
                                 patience<span class="token operator">=</span>PARAM<span class="token punctuation">.</span>ES_PATIENCE<span class="token punctuation">)</span>
model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>
    train_dataset<span class="token punctuation">,</span>
    valid_dataset<span class="token operator">=</span>valid_dataset<span class="token punctuation">,</span>
    train_bs<span class="token operator">=</span>PARAM<span class="token punctuation">.</span>TRAIN_BATCH_SIZE<span class="token punctuation">,</span> 
    valid_bs<span class="token operator">=</span>PARAM<span class="token punctuation">.</span>VALID_BATCH_SIZE<span class="token punctuation">,</span> 
    device<span class="token operator">=</span>PARAM<span class="token punctuation">.</span>DEVICE<span class="token punctuation">,</span>
    epochs<span class="token operator">=</span>PARAM<span class="token punctuation">.</span>EPOCH<span class="token punctuation">,</span>
    callbacks<span class="token operator">=</span><span class="token punctuation">[</span>tb_logger<span class="token punctuation">,</span> es<span class="token punctuation">]</span><span class="token punctuation">,</span>
    n_jobs<span class="token operator">=</span>PARAM<span class="token punctuation">.</span>N_JOB<span class="token punctuation">,</span> 
    fp16<span class="token operator">=</span>PARAM<span class="token punctuation">.</span>FP16<span class="token punctuation">,</span>
<span class="token punctuation">)</span>
model<span class="token punctuation">.</span>save<span class="token punctuation">(</span>PARAM<span class="token punctuation">.</span>MODEL_SAVE_PATH<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<img src="/Hexo-Blog/2021/02/07/2021-02-07-twitter-hate-speech-detection/history.png" class="">

<h2 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">TwitterInferenceClassifier</span><span class="token punctuation">(</span>tez<span class="token punctuation">.</span>Model<span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>tokenizer <span class="token operator">=</span> transformers<span class="token punctuation">.</span>BertTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
            <span class="token string">"bert-base-uncased"</span><span class="token punctuation">,</span> do_lower_case<span class="token operator">=</span><span class="token boolean">True</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bert <span class="token operator">=</span> transformers<span class="token punctuation">.</span>BertModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
            <span class="token string">"bert-base-uncased"</span><span class="token punctuation">,</span> 
            return_dict<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bert_drop <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.3</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>out <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>bert<span class="token punctuation">.</span>config<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> ids<span class="token punctuation">,</span> mask<span class="token punctuation">,</span> targets<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        last_hidden_states <span class="token operator">=</span> self<span class="token punctuation">.</span>bert<span class="token punctuation">(</span>ids<span class="token punctuation">,</span> attention_mask<span class="token operator">=</span>mask<span class="token punctuation">)</span>
        b_o <span class="token operator">=</span> self<span class="token punctuation">.</span>bert_drop<span class="token punctuation">(</span>last_hidden_states<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        output <span class="token operator">=</span> self<span class="token punctuation">.</span>out<span class="token punctuation">(</span>b_o<span class="token punctuation">)</span>
        <span class="token keyword">return</span> output<span class="token punctuation">,</span> _<span class="token punctuation">,</span> _
    
    <span class="token keyword">def</span> <span class="token function">load</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> model_path<span class="token punctuation">,</span> device<span class="token operator">=</span><span class="token string">"cuda"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>device <span class="token operator">=</span> device
        <span class="token keyword">if</span> <span class="token builtin">next</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>device <span class="token operator">!=</span> self<span class="token punctuation">.</span>device<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>to<span class="token punctuation">(</span>self<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
        model_dict <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>model_path<span class="token punctuation">,</span> map_location<span class="token operator">=</span>torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>model_dict<span class="token punctuation">[</span><span class="token string">"state_dict"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>


model_reload <span class="token operator">=</span> TwitterInferenceClassifier<span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>PARAM<span class="token punctuation">.</span>DEVICE<span class="token punctuation">)</span>
model_reload<span class="token punctuation">.</span>load<span class="token punctuation">(</span>PARAM<span class="token punctuation">.</span>MODEL_SAVE_PATH<span class="token punctuation">,</span> device<span class="token operator">=</span>PARAM<span class="token punctuation">.</span>DEVICE<span class="token punctuation">)</span>

test_df<span class="token punctuation">[</span><span class="token string">"review"</span><span class="token punctuation">]</span> <span class="token operator">=</span> test_df<span class="token punctuation">[</span><span class="token string">"tweet"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>swifter<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>clean_tweets<span class="token punctuation">)</span>
test_df<span class="token punctuation">[</span><span class="token string">"length"</span><span class="token punctuation">]</span> <span class="token operator">=</span> test_df<span class="token punctuation">[</span><span class="token string">"review"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>swifter<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">)</span>
test_df<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
test_dataset <span class="token operator">=</span> TwitterDataset<span class="token punctuation">(</span>test_df<span class="token punctuation">.</span>review<span class="token punctuation">.</span>values<span class="token punctuation">,</span> test_df<span class="token punctuation">.</span>label<span class="token punctuation">.</span>values<span class="token punctuation">,</span> max_len<span class="token operator">=</span>PARAM<span class="token punctuation">.</span>MAX_LENGTH<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">softmax</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

prediction <span class="token operator">=</span> model_reload<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>test_dataset<span class="token punctuation">,</span> n_jobs<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span>
prediction <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>prediction<span class="token punctuation">)</span>
prediction <span class="token operator">=</span> softmax<span class="token punctuation">(</span>np<span class="token punctuation">.</span>vstack<span class="token punctuation">(</span>prediction<span class="token punctuation">)</span><span class="token punctuation">)</span>
prediction <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>prediction<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

submit <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"./data/sample_submission.csv"</span><span class="token punctuation">)</span>
submit<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span> <span class="token operator">=</span> prediction
submit<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">"./data/submit.csv"</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>This solution to the detection of hate speech and offensive language on Twitter through deep learning using BERT achieves reasonable accuracy (90.8%) as well as f1-score (92.1%) on validation dataset. However, it got low f1-score (29.5%) on test dataset. As we can see, the high accuracy rate was just an illusion.</p>
<p>Supervised learning relies on the fact that training and test data follow the same distribution. If that were not the case, then one could perfectly get a model that performs well in training data but does not on test data. And it would not be because of overfitting of the training data.</p>
<p>First, let’s try to reduce the complexity of the model.</p>
<h1 id="Naive-Bayes-Classifier"><a href="#Naive-Bayes-Classifier" class="headerlink" title="Naive Bayes Classifier"></a>Naive Bayes Classifier</h1><p>We’ll take a look at one natural language processing technique for text classification called Naive Bayes.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> os
<span class="token keyword">import</span> re
<span class="token keyword">import</span> string
<span class="token keyword">import</span> math

target_names <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'non-toxic'</span><span class="token punctuation">,</span> <span class="token string">'toxic'</span><span class="token punctuation">]</span>

<span class="token keyword">class</span> <span class="token class-name">HateSpeechDetector</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token keyword">def</span> <span class="token function">clean</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">)</span><span class="token punctuation">:</span>
        translator <span class="token operator">=</span> <span class="token builtin">str</span><span class="token punctuation">.</span>maketrans<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">,</span> string<span class="token punctuation">.</span>punctuation<span class="token punctuation">)</span>
        <span class="token keyword">return</span> s<span class="token punctuation">.</span>translate<span class="token punctuation">(</span>translator<span class="token punctuation">)</span>
 
    <span class="token keyword">def</span> <span class="token function">tokenize</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> text<span class="token punctuation">)</span><span class="token punctuation">:</span>
        text <span class="token operator">=</span> self<span class="token punctuation">.</span>clean<span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> re<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"\W+"</span><span class="token punctuation">,</span> text<span class="token punctuation">)</span>
 
    <span class="token keyword">def</span> <span class="token function">get_word_counts</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> words<span class="token punctuation">)</span><span class="token punctuation">:</span>
        word_counts <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
        <span class="token keyword">for</span> word <span class="token keyword">in</span> words<span class="token punctuation">:</span>
            word_counts<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token operator">=</span> word_counts<span class="token punctuation">.</span>get<span class="token punctuation">(</span>word<span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1.0</span>
        <span class="token keyword">return</span> word_counts
    
    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>num_reviews <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
        self<span class="token punctuation">.</span>log_class_priors <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
        self<span class="token punctuation">.</span>word_counts <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
        self<span class="token punctuation">.</span>vocab <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

        n <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>num_reviews<span class="token punctuation">[</span><span class="token string">'toxic'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token keyword">for</span> label <span class="token keyword">in</span> Y <span class="token keyword">if</span> label <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>num_reviews<span class="token punctuation">[</span><span class="token string">'non-toxic'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token keyword">for</span> label <span class="token keyword">in</span> Y <span class="token keyword">if</span> label <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>log_class_priors<span class="token punctuation">[</span><span class="token string">'toxic'</span><span class="token punctuation">]</span> <span class="token operator">=</span> math<span class="token punctuation">.</span>log<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_reviews<span class="token punctuation">[</span><span class="token string">'toxic'</span><span class="token punctuation">]</span> <span class="token operator">/</span> n<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>log_class_priors<span class="token punctuation">[</span><span class="token string">'non-toxic'</span><span class="token punctuation">]</span> <span class="token operator">=</span> math<span class="token punctuation">.</span>log<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_reviews<span class="token punctuation">[</span><span class="token string">'non-toxic'</span><span class="token punctuation">]</span> <span class="token operator">/</span> n<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>word_counts<span class="token punctuation">[</span><span class="token string">'toxic'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
        self<span class="token punctuation">.</span>word_counts<span class="token punctuation">[</span><span class="token string">'non-toxic'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>

        <span class="token keyword">for</span> x<span class="token punctuation">,</span> y <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span><span class="token punctuation">:</span>
            c <span class="token operator">=</span> <span class="token string">'toxic'</span> <span class="token keyword">if</span> y <span class="token operator">==</span> <span class="token number">1</span> <span class="token keyword">else</span> <span class="token string">'non-toxic'</span>
            counts <span class="token operator">=</span> self<span class="token punctuation">.</span>get_word_counts<span class="token punctuation">(</span>self<span class="token punctuation">.</span>tokenize<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> word<span class="token punctuation">,</span> count <span class="token keyword">in</span> counts<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">if</span> word <span class="token keyword">not</span> <span class="token keyword">in</span> self<span class="token punctuation">.</span>vocab<span class="token punctuation">:</span>
                    self<span class="token punctuation">.</span>vocab<span class="token punctuation">.</span>add<span class="token punctuation">(</span>word<span class="token punctuation">)</span>
                <span class="token keyword">if</span> word <span class="token keyword">not</span> <span class="token keyword">in</span> self<span class="token punctuation">.</span>word_counts<span class="token punctuation">[</span>c<span class="token punctuation">]</span><span class="token punctuation">:</span>
                    self<span class="token punctuation">.</span>word_counts<span class="token punctuation">[</span>c<span class="token punctuation">]</span><span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0.0</span>

                self<span class="token punctuation">.</span>word_counts<span class="token punctuation">[</span>c<span class="token punctuation">]</span><span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token operator">+=</span> count
                
    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>
        result <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> x <span class="token keyword">in</span> X<span class="token punctuation">:</span>
            counts <span class="token operator">=</span> self<span class="token punctuation">.</span>get_word_counts<span class="token punctuation">(</span>self<span class="token punctuation">.</span>tokenize<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
            toxic_score <span class="token operator">=</span> <span class="token number">0</span>
            non_toxic_score <span class="token operator">=</span> <span class="token number">0</span>
            <span class="token keyword">for</span> word<span class="token punctuation">,</span> _ <span class="token keyword">in</span> counts<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">if</span> word <span class="token keyword">not</span> <span class="token keyword">in</span> self<span class="token punctuation">.</span>vocab<span class="token punctuation">:</span> <span class="token keyword">continue</span>

                <span class="token comment"># Add Laplace smoothing</span>
                log_w_given_toxic <span class="token operator">=</span> math<span class="token punctuation">.</span>log<span class="token punctuation">(</span>
                    <span class="token punctuation">(</span>self<span class="token punctuation">.</span>word_counts<span class="token punctuation">[</span><span class="token string">'toxic'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span>word<span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_reviews<span class="token punctuation">[</span><span class="token string">'toxic'</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>vocab<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                log_w_given_non_toxic <span class="token operator">=</span> math<span class="token punctuation">.</span>log<span class="token punctuation">(</span>
                    <span class="token punctuation">(</span>self<span class="token punctuation">.</span>word_counts<span class="token punctuation">[</span><span class="token string">'non-toxic'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span>word<span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_reviews<span class="token punctuation">[</span><span class="token string">'non-toxic'</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>vocab<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

                toxic_score <span class="token operator">+=</span> log_w_given_toxic
                non_toxic_score <span class="token operator">+=</span> log_w_given_non_toxic

            toxic_score <span class="token operator">+=</span> self<span class="token punctuation">.</span>log_class_priors<span class="token punctuation">[</span><span class="token string">'toxic'</span><span class="token punctuation">]</span>
            non_toxic_score <span class="token operator">+=</span> self<span class="token punctuation">.</span>log_class_priors<span class="token punctuation">[</span><span class="token string">'non-toxic'</span><span class="token punctuation">]</span>

            <span class="token keyword">if</span> toxic_score <span class="token operator">></span> non_toxic_score<span class="token punctuation">:</span>
                result<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                result<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
                
        <span class="token keyword">return</span> result<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>Train Naive Bayes Classifier for training dataset.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">HSD <span class="token operator">=</span> HateSpeechDetector<span class="token punctuation">(</span><span class="token punctuation">)</span>
HSD<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>df_train<span class="token punctuation">[</span><span class="token string">"tweet"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> df_train<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
pred <span class="token operator">=</span> HSD<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>df_valid<span class="token punctuation">[</span><span class="token string">"tweet"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>metrics<span class="token punctuation">.</span>classification_report<span class="token punctuation">(</span>df_valid<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>metrics<span class="token punctuation">.</span>accuracy_score<span class="token punctuation">(</span>df_valid<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>metrics<span class="token punctuation">.</span>f1_score<span class="token punctuation">(</span>df_valid<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>metrics<span class="token punctuation">.</span>confusion_matrix<span class="token punctuation">(</span>df_valid<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<pre class="line-numbers language-console" data-language="console"><code class="language-console">              precision    recall  f1-score   support

           0       0.93      1.00      0.96      5701
           1       1.00      0.05      0.09       443

    accuracy                           0.93      6144
   macro avg       0.97      0.52      0.53      6144
weighted avg       0.94      0.93      0.90      6144

0.9314778645833334
0.09462365591397849
[[5701    0]
 [ 421   22]]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>The result got worse. Naive Bayes got lower f1-score (14.7%) on test dataset. Next, I want to try under resampling strategies. We shall know that this is a highly imbalanced datasets (22803 for “0” and 1772 for “1”), so I’m going to adopted resampling technique for dealing with highly imbalanced datasets. It consists of removing samples from the majority class (under-sampling) or adding more examples from the minority class (over-sampling).</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Class count</span>
count_class_0<span class="token punctuation">,</span> count_class_1 <span class="token operator">=</span> df_train<span class="token punctuation">.</span>label<span class="token punctuation">.</span>value_counts<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># Divide by class</span>
df_class_0 <span class="token operator">=</span> df_train<span class="token punctuation">[</span>df_train<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">]</span>
df_class_1 <span class="token operator">=</span> df_train<span class="token punctuation">[</span>df_train<span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">]</span>

df_class_0_under <span class="token operator">=</span> df_class_0<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>count_class_1<span class="token punctuation">)</span>
df_train_under <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>df_class_0_under<span class="token punctuation">,</span> df_class_1<span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Random under-sampling:'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>df_train_under<span class="token punctuation">.</span>label<span class="token punctuation">.</span>value_counts<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">"figure.figsize"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">6</span>
df_train_under<span class="token punctuation">.</span>label<span class="token punctuation">.</span>value_counts<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>plot<span class="token punctuation">(</span>kind<span class="token operator">=</span><span class="token string">'bar'</span><span class="token punctuation">,</span> title<span class="token operator">=</span><span class="token string">'Count (target)'</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<img src="/Hexo-Blog/2021/02/07/2021-02-07-twitter-hate-speech-detection/under-sampling.png" class="">

<p>Re-train the Bayes model.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">HSD <span class="token operator">=</span> HateSpeechDetector<span class="token punctuation">(</span><span class="token punctuation">)</span>
HSD<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>df_train_under<span class="token punctuation">[</span><span class="token string">"tweet"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> df_train_under<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
pred <span class="token operator">=</span> HSD<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>df_valid<span class="token punctuation">[</span><span class="token string">"tweet"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>metrics<span class="token punctuation">.</span>classification_report<span class="token punctuation">(</span>df_valid<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>metrics<span class="token punctuation">.</span>accuracy_score<span class="token punctuation">(</span>df_valid<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>metrics<span class="token punctuation">.</span>f1_score<span class="token punctuation">(</span>df_valid<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>metrics<span class="token punctuation">.</span>confusion_matrix<span class="token punctuation">(</span>df_valid<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<pre class="line-numbers language-console" data-language="console"><code class="language-console">              precision    recall  f1-score   support

           0       0.99      0.85      0.92      5701
           1       0.32      0.87      0.47       443

    accuracy                           0.86      6144
   macro avg       0.65      0.86      0.69      6144
weighted avg       0.94      0.86      0.88      6144

0.8562825520833334
0.46710923355461675
[[4874  827]
 [  56  387]]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>This time, we got a higher f1-score (46.9%) on test datasets, and it’s even better than the f1-score (29.52%) of BERT.</p>
<p>Therefore, I try to utilise under sampling on BERT again to see if we can increase the f1-score!</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">train_dataset <span class="token operator">=</span> TwitterDataset<span class="token punctuation">(</span>df_train_under<span class="token punctuation">.</span>review<span class="token punctuation">.</span>values<span class="token punctuation">,</span> df_train_under<span class="token punctuation">.</span>label<span class="token punctuation">.</span>values<span class="token punctuation">,</span> max_len<span class="token operator">=</span>PARAM<span class="token punctuation">.</span>MAX_LENGTH<span class="token punctuation">)</span>
valid_dataset <span class="token operator">=</span> TwitterDataset<span class="token punctuation">(</span>df_valid<span class="token punctuation">.</span>review<span class="token punctuation">.</span>values<span class="token punctuation">,</span> df_valid<span class="token punctuation">.</span>label<span class="token punctuation">.</span>values<span class="token punctuation">,</span> max_len<span class="token operator">=</span>PARAM<span class="token punctuation">.</span>MAX_LENGTH<span class="token punctuation">)</span>

n_train_steps <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>df_train<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">32</span> <span class="token operator">*</span> <span class="token number">10</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> TwitterClassifier<span class="token punctuation">(</span>num_train_steps<span class="token operator">=</span>n_train_steps<span class="token punctuation">,</span> num_classes<span class="token operator">=</span>PARAM<span class="token punctuation">.</span>NUM_CLASSES<span class="token punctuation">,</span> weight<span class="token operator">=</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

tb_logger <span class="token operator">=</span> tez<span class="token punctuation">.</span>callbacks<span class="token punctuation">.</span>TensorBoardLogger<span class="token punctuation">(</span>log_dir<span class="token operator">=</span>PARAM<span class="token punctuation">.</span>TF_LOG<span class="token punctuation">)</span>
es <span class="token operator">=</span> tez<span class="token punctuation">.</span>callbacks<span class="token punctuation">.</span>EarlyStopping<span class="token punctuation">(</span>monitor<span class="token operator">=</span><span class="token string">"valid_loss"</span><span class="token punctuation">,</span> 
                                 model_path<span class="token operator">=</span><span class="token string">"./models/bert_under.bin"</span><span class="token punctuation">,</span> 
                                 patience<span class="token operator">=</span>PARAM<span class="token punctuation">.</span>ES_PATIENCE<span class="token punctuation">)</span>
model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>
    train_dataset<span class="token punctuation">,</span>
    valid_dataset<span class="token operator">=</span>valid_dataset<span class="token punctuation">,</span>
    train_bs<span class="token operator">=</span>PARAM<span class="token punctuation">.</span>TRAIN_BATCH_SIZE<span class="token punctuation">,</span> 
    valid_bs<span class="token operator">=</span>PARAM<span class="token punctuation">.</span>VALID_BATCH_SIZE<span class="token punctuation">,</span> 
    device<span class="token operator">=</span>PARAM<span class="token punctuation">.</span>DEVICE<span class="token punctuation">,</span>
    epochs<span class="token operator">=</span>PARAM<span class="token punctuation">.</span>EPOCH<span class="token punctuation">,</span>
    callbacks<span class="token operator">=</span><span class="token punctuation">[</span>tb_logger<span class="token punctuation">,</span> es<span class="token punctuation">]</span><span class="token punctuation">,</span>
    n_jobs<span class="token operator">=</span>PARAM<span class="token punctuation">.</span>N_JOB<span class="token punctuation">,</span> 
    fp16<span class="token operator">=</span>PARAM<span class="token punctuation">.</span>FP16<span class="token punctuation">,</span>
<span class="token punctuation">)</span>
model<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">"./models/bert_under.bin"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<img src="/Hexo-Blog/2021/02/07/2021-02-07-twitter-hate-speech-detection/history2.png" class="">

<p>Unfortunately, BERT with under sampling technique get the lowest f1-score (13.1%)…</p>
<h1 id="Data-Augmentation"><a href="#Data-Augmentation" class="headerlink" title="Data Augmentation"></a>Data Augmentation</h1><p>Data augmentation in data analysis are techniques used to increase the amount of data by adding slightly modified copies of already existing data or newly created synthetic data from existing data. It acts as a regularizer and helps reduce overfitting when training a machine learning model.</p>
<p>In this post, I will primarily address data augmentation with regard to the Text Classification and some of these techniques listed below.</p>
<ul>
<li>Backtranslation</li>
<li>Synonym Word Replacement<ul>
<li>Pre-trained Word Embedding based: Word2Vec, , GloVe, FastText, …</li>
<li>Contexual Word Embedding based: ELMo, BERT, DistilBERT, …</li>
<li>Lexical based: Wordnet, …</li>
</ul>
</li>
<li>Generative Models: BERT, XLNet, RoBERTa, BART, T%</li>
<li>Random Operation:<ul>
<li>Random Insertion</li>
<li>Random Swapping</li>
<li>Random Deletion</li>
</ul>
</li>
</ul>
<h2 id="Naive-Bayes-with-Wordnet-Augmentation"><a href="#Naive-Bayes-with-Wordnet-Augmentation" class="headerlink" title="Naive Bayes with Wordnet Augmentation"></a>Naive Bayes with Wordnet Augmentation</h2><p>I use WordNet, a large linguistic database, to identify relevant synonyms.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> nlpaug<span class="token punctuation">.</span>augmenter<span class="token punctuation">.</span>char <span class="token keyword">as</span> nac
<span class="token keyword">import</span> nlpaug<span class="token punctuation">.</span>augmenter<span class="token punctuation">.</span>word <span class="token keyword">as</span> naw
<span class="token keyword">import</span> nlpaug<span class="token punctuation">.</span>augmenter<span class="token punctuation">.</span>sentence <span class="token keyword">as</span> nas
<span class="token keyword">import</span> nlpaug<span class="token punctuation">.</span>flow <span class="token keyword">as</span> nafc
<span class="token keyword">from</span> nlpaug<span class="token punctuation">.</span>util <span class="token keyword">import</span> Action<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><code>nlpaug</code> helps you with augmenting nlp for your machine learning projects.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">augment_text</span><span class="token punctuation">(</span>df<span class="token punctuation">,</span> samples<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    aug <span class="token operator">=</span> naw<span class="token punctuation">.</span>SynonymAug<span class="token punctuation">(</span>aug_src<span class="token operator">=</span><span class="token string">'wordnet'</span><span class="token punctuation">)</span>
    aug_text <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    
    <span class="token comment"># Selecting the minority class samples</span>
    df_n <span class="token operator">=</span> df<span class="token punctuation">[</span>df<span class="token punctuation">.</span>label<span class="token operator">==</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span>drop<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token comment">## Data augmentation loop</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>df_n<span class="token punctuation">)</span><span class="token punctuation">,</span> samples<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        text <span class="token operator">=</span> df_n<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'tweet'</span><span class="token punctuation">]</span>
        augmented_text <span class="token operator">=</span> aug<span class="token punctuation">.</span>augment<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
        aug_text<span class="token punctuation">.</span>append<span class="token punctuation">(</span>augmented_text<span class="token punctuation">)</span>
    
    <span class="token keyword">return</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">&#123;</span>
        <span class="token string">'tweet'</span><span class="token punctuation">:</span> aug_text<span class="token punctuation">,</span> 
        <span class="token string">'label'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>Concatenate with the original dataframe.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">df_train_1_aug <span class="token operator">=</span> augment_text<span class="token punctuation">(</span>df_train<span class="token punctuation">,</span> samples<span class="token operator">=</span><span class="token number">20000</span><span class="token punctuation">)</span>
df_train_all_aug <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>df_train<span class="token punctuation">,</span> df_train_1_aug<span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
df_train_all_aug <span class="token operator">=</span> df_train_all_aug<span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span>drop<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
df_train_all_aug<span class="token punctuation">[</span><span class="token string">"review"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df_train_all_aug<span class="token punctuation">[</span><span class="token string">"tweet"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>swifter<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>clean_tweets<span class="token punctuation">)</span>
df_train_all_aug<span class="token punctuation">[</span><span class="token string">"length"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df_train_all_aug<span class="token punctuation">[</span><span class="token string">"review"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>swifter<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<img src="/Hexo-Blog/2021/02/07/2021-02-07-twitter-hate-speech-detection/train-aug.png" class="">

<p>Traing Naive Bayes with text augmentation.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">HSD <span class="token operator">=</span> HateSpeechDetector<span class="token punctuation">(</span><span class="token punctuation">)</span>
HSD<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>df_train_all_aug<span class="token punctuation">[</span><span class="token string">"tweet"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> df_train_all_aug<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
pred <span class="token operator">=</span> HSD<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>df_valid<span class="token punctuation">[</span><span class="token string">"tweet"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>metrics<span class="token punctuation">.</span>classification_report<span class="token punctuation">(</span>df_valid<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>metrics<span class="token punctuation">.</span>accuracy_score<span class="token punctuation">(</span>df_valid<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>metrics<span class="token punctuation">.</span>f1_score<span class="token punctuation">(</span>df_valid<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>metrics<span class="token punctuation">.</span>confusion_matrix<span class="token punctuation">(</span>df_valid<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<pre class="line-numbers language-console" data-language="console"><code class="language-console">              precision    recall  f1-score   support

           0       0.98      0.94      0.96      5701
           1       0.50      0.80      0.61       443

    accuracy                           0.93      6144
   macro avg       0.74      0.87      0.79      6144
weighted avg       0.95      0.93      0.93      6144

0.9269205729166666
0.6112554112554112
[[5342  359]
 [  90  353]]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>It got a f1-score of 63.1% on test dataset! Seems pretty well! In this case, I was wondering, what if I do the same text augmentation operation on validation data? Will it increase the accuracy and f1-score? Let’s see!</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">df_valid_1_aug <span class="token operator">=</span> augment_text<span class="token punctuation">(</span>df_valid<span class="token punctuation">,</span> samples<span class="token operator">=</span><span class="token number">5000</span><span class="token punctuation">)</span>
df_valid_all_aug <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>df_valid<span class="token punctuation">,</span> df_valid_1_aug<span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
df_valid_all_aug <span class="token operator">=</span> df_valid_all_aug<span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span>drop<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
df_valid_all_aug<span class="token punctuation">[</span><span class="token string">"review"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df_valid_all_aug<span class="token punctuation">[</span><span class="token string">"tweet"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>swifter<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>clean_tweets<span class="token punctuation">)</span>
df_valid_all_aug<span class="token punctuation">[</span><span class="token string">"length"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df_valid_all_aug<span class="token punctuation">[</span><span class="token string">"review"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>swifter<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<img src="/Hexo-Blog/2021/02/07/2021-02-07-twitter-hate-speech-detection/valid-aug.png" class="">

<pre class="line-numbers language-python" data-language="python"><code class="language-python">HSD <span class="token operator">=</span> HateSpeechDetector<span class="token punctuation">(</span><span class="token punctuation">)</span>
HSD<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>df_train_all_aug<span class="token punctuation">[</span><span class="token string">"tweet"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> df_train_all_aug<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
pred <span class="token operator">=</span> HSD<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>df_valid_all_aug<span class="token punctuation">[</span><span class="token string">"tweet"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>metrics<span class="token punctuation">.</span>classification_report<span class="token punctuation">(</span>df_valid_all_aug<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>metrics<span class="token punctuation">.</span>accuracy_score<span class="token punctuation">(</span>df_valid_all_aug<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>metrics<span class="token punctuation">.</span>f1_score<span class="token punctuation">(</span>df_valid_all_aug<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>metrics<span class="token punctuation">.</span>confusion_matrix<span class="token punctuation">(</span>df_valid_all_aug<span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<pre class="line-numbers language-console" data-language="console"><code class="language-console">              precision    recall  f1-score   support

           0       0.93      0.94      0.94      5701
           1       0.93      0.93      0.93      5443

    accuracy                           0.93     11144
   macro avg       0.93      0.93      0.93     11144
weighted avg       0.93      0.93      0.93     11144

0.9339554917444365
0.9322782480677219
[[5342  359]
 [ 377 5066]]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>It got a f1-score of 63.6% on test dataset! It’s slightly higher than only operating augmentation on training dataset.</p>
<h2 id="Naive-Bayes-with-BERT-Augmentation"><a href="#Naive-Bayes-with-BERT-Augmentation" class="headerlink" title="Naive Bayes with BERT Augmentation"></a>Naive Bayes with BERT Augmentation</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">augment_text_using_bert</span><span class="token punctuation">(</span>df<span class="token punctuation">,</span> samples<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    aug <span class="token operator">=</span> naw<span class="token punctuation">.</span>ContextualWordEmbsAug<span class="token punctuation">(</span>model_path<span class="token operator">=</span><span class="token string">'bert-base-uncased'</span><span class="token punctuation">,</span> action<span class="token operator">=</span><span class="token string">"substitute"</span><span class="token punctuation">)</span>
    aug_text <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    
    <span class="token comment"># Selecting the minority class samples</span>
    df_n <span class="token operator">=</span> df<span class="token punctuation">[</span>df<span class="token punctuation">.</span>label<span class="token operator">==</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reset_index<span class="token punctuation">(</span>drop<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token comment">## Data augmentation loop</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>df_n<span class="token punctuation">)</span><span class="token punctuation">,</span> samples<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        text <span class="token operator">=</span> df_n<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'tweet'</span><span class="token punctuation">]</span>
        augmented_text <span class="token operator">=</span> aug<span class="token punctuation">.</span>augment<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
        aug_text<span class="token punctuation">.</span>append<span class="token punctuation">(</span>augmented_text<span class="token punctuation">)</span>
    
    <span class="token keyword">return</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">&#123;</span>
        <span class="token string">'tweet'</span><span class="token punctuation">:</span> aug_text<span class="token punctuation">,</span> 
        <span class="token string">'label'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">&#125;</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>Basically, the code is the same as the previous. I listed the result (on test dataset) in one table.</p>
<div style="display: flex; justify-content: center;">
    <table class="styled-table">
        <thead>
            <tr>
                <th>Model</th>
                <th>Augmentation</th>
                <th>F1-score</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>Naive Bayes</td>
                <td>Wordnet (Train)</td>
                <td>🥈 0.6307</td>
            </tr>
            <tr>
                <td>Naive Bayes</td>
                <td>Wordnet (Train+Valid)</td>
                <td>🥇 0.6356</td>
            </tr>
            <tr>
                <td>Naive Bayes</td>
                <td>BERT (Train)</td>
                <td>0.5136</td>
            </tr>
            <tr>
                <td>Naive Bayes</td>
                <td>BERT (Train+Valid)</td>
                <td>🥉 0.5200</td>
            </tr>
        </tbody>
    </table>
</div>

<p>Next, I investigate the wordnet augmentation on training datatset for BERT model. This results in a lower f1-score of 35.2% on test dataset. </p>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>In this report, I proposed several solutions to the detection of hate speech and offensive language on Twitter through machine learning (Naive Bayes) and deep learning (BERT). Most of the time, BERT performed worse than Naive Bayes. In the future, if I have spare time, I may try ensemble methods to see whether it can increase the f1-score significantly! See you next time!</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol>
<li><a target="_blank" rel="noopener" href="https://github.com/abhishekkrthakur/tez">https://github.com/abhishekkrthakur/tez</a></li>
<li><a target="_blank" rel="noopener" href="https://www.kaggle.com/renatobmlr/pytorch-imbalanced-classes">https://www.kaggle.com/renatobmlr/pytorch-imbalanced-classes</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/makcedward/nlpaug/blob/master/example/textual_augmenter.ipynb">https://github.com/makcedward/nlpaug/blob/master/example/textual_augmenter.ipynb</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1904.00962.pdf">https://arxiv.org/pdf/1904.00962.pdf</a></li>
<li><a target="_blank" rel="noopener" href="https://pythonmachinelearning.pro/text-classification-tutorial-with-naive-bayes/">https://pythonmachinelearning.pro/text-classification-tutorial-with-naive-bayes/</a></li>
<li><a target="_blank" rel="noopener" href="https://www.kaggle.com/getting-started/14998">https://www.kaggle.com/getting-started/14998</a></li>
<li><a target="_blank" rel="noopener" href="https://neptune.ai/blog/data-augmentation-nlp">https://neptune.ai/blog/data-augmentation-nlp</a></li>
<li><a target="_blank" rel="noopener" href="https://saurabhk30.medium.com/5-data-augmentation-techniques-for-text-classification-d14f6d8bd6aa">https://saurabhk30.medium.com/5-data-augmentation-techniques-for-text-classification-d14f6d8bd6aa</a></li>
</ol>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        Author:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Hexo-Blog/about" rel="external nofollow noreferrer">Yang Wang</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        Link:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://penguinwang96825.github.io/Hexo-Blog/Hexo-Blog/2021/02/07/2021-02-07-twitter-hate-speech-detection/">https://penguinwang96825.github.io/Hexo-Blog/Hexo-Blog/2021/02/07/2021-02-07-twitter-hate-speech-detection/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        Reprint policy:
                    </i>
                </span>
                <span class="reprint-info">
                    All articles in this blog are used except for special statements
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    reprint polocy. If reproduced, please indicate source
                    <a href="/Hexo-Blog/about" target="_blank">Yang Wang</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>Copied successfully, please follow the reprint policy of this article</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">more</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Hexo-Blog/tags/Python/">
                                    <span class="chip bg-color">Python</span>
                                </a>
                            
                                <a href="/Hexo-Blog/tags/PyTorch/">
                                    <span class="chip bg-color">PyTorch</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Hexo-Blog/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>WeChat swipe to share！</p>"></div>
    <script src="/Hexo-Blog/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    
        <div class="disqus-card card" data-aos="fade-up">
    <div id="disqus_thread" class="card-content">
        <noscript>Please enable JavaScript to view the
            <a target="_blank" rel="noopener" href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
    </div>
</div>

<script type="text/javascript">
    disqus_config = function () {
        this.page.url = 'https://penguinwang96825.github.io/Hexo-Blog/2021/02/07/2021-02-07-twitter-hate-speech-detection/';
        this.page.identifier = '/Hexo-Blog/2021/02/07/2021-02-07-twitter-hate-speech-detection/';
        this.page.title = 'Twitter Hate Speech Detection';
    };
    let disqus_shortname = 'penguinwang';

    (function () { // DON'T EDIT BELOW THIS LINE
        let d = document, s = d.createElement('script');
        // 如：s.src = 'https://blinkfox.disqus.com/embed.js';
        s.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;Previous</div>
            <div class="card">
                <a href="/Hexo-Blog/2021/03/02/2021-03-02-train-word-embedding-vectos-on-custom-corpus/">
                    <div class="card-image">
                        
                        <img src="https://github.com/penguinwang96825/penguinwang96825.github.io/blob/master/2021/03/02/2021-03-02-train-word-embedding-vectos-on-custom-corpus/jon-tyson.jpg?raw=true" class="responsive-img" alt="Train Word Embedding Vectors on Custom Corpus">
                        
                        <span class="card-title">Train Word Embedding Vectors on Custom Corpus</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            When I was doing my dissertation project, I found out that the performance of model wasn't quite well. I believe it's because the domain of pre-trained GoogleNews-vectors-negative300 is different from the the dataset of mine. Hence, I decide to pre-train a word2vec model by myself.
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2021-03-02
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Hexo-Blog/categories/NLP/" class="post-category">
                                    NLP
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Hexo-Blog/tags/WSL/">
                        <span class="chip bg-color">WSL</span>
                    </a>
                    
                    <a href="/Hexo-Blog/tags/Ubuntu/">
                        <span class="chip bg-color">Ubuntu</span>
                    </a>
                    
                    <a href="/Hexo-Blog/tags/NLP/">
                        <span class="chip bg-color">NLP</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                Next&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Hexo-Blog/2021/02/06/2021-02-06-prevent-colab-from-disconnecting/">
                    <div class="card-image">
                        
                        <img src="https://github.com/penguinwang96825/penguinwang96825.github.io/blob/master/2021/02/06/2021-02-06-prevent-colab-from-disconnecting/kai-wenzel.jpg?raw=true" class="responsive-img" alt="Prevent Colab from Disconnecting">
                        
                        <span class="card-title">Prevent Colab from Disconnecting</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            Google Colab notebooks have an idle timeout of 90 minutes and absolute timeout of 12 hours. This means, if user does not interact with his Google Colab notebook for more than 90 minutes, its instance is automatically terminated. Also, maximum lifetime of a Colab instance is 12 hours.
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2021-02-06
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Hexo-Blog/categories/Installation/" class="post-category">
                                    Installation
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Hexo-Blog/tags/Colab/">
                        <span class="chip bg-color">Colab</span>
                    </a>
                    
                    <a href="/Hexo-Blog/tags/JavaScript/">
                        <span class="chip bg-color">JavaScript</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + 'From: Yang&#39;s Blog<br />'
            + 'Author: Yang Wang<br />'
            + 'Link: <a href="' + url + '">' + url + '</a><br />'
            + 'The copyright of this article belongs to the author, please indicate the source of any form of reproduction.';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>


<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Hexo-Blog/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/Hexo-Blog/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Hexo-Blog/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Hexo-Blog/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;TOC</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Hexo-Blog/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h1, h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

    <!-- footer -->
    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Hexo-Blog/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.3'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Hexo-Blog/libs/aplayer/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

    
    <div class="container row center-align" style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2018-2021</span>
            
            <span id="year">2018</span>
            <a href="/Hexo-Blog/about" target="_blank">Yang Wang</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;Total site word count:&nbsp;<span
                class="white-color">106.8k</span>&nbsp;words
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;Total number of visits:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;times
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;Total number of visitors:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;people
            </span>
            
            <br>
            
            <span id="sitetime">Loading runtime...</span>
            <script>
                function siteTime() {
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2018";
                    var startMonth = "12";
                    var startDate = "3";
                    var startHour = "0";
                    var startMinute = "0";
                    var startSecond = "0";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "This site has been safely operated " + diffDays + " days " + diffHours +
                            " hours " + diffMinutes + " minutes " + diffSeconds + " seconds";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "This site has been safely operated " + diffYears + " years " + diffDays +
                            " days " + diffHours + " hours " + diffMinutes + " minutes " + diffSeconds + " seconds";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/penguinwang96825" class="tooltipped" target="_blank" data-tooltip="Visit my GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:penguinwang@smail.nchu.edu.tw" class="tooltipped" target="_blank" data-tooltip="Contact me by mail" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>













</div>
    </div>
</footer>

<div class="progress-bar"></div>

    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;Search</span>
            <input type="search" id="searchInput" name="s" placeholder="Please enter a search keyword"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Hexo-Blog/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Hexo-Blog/libs/materialize/materialize.min.js"></script>
    <script src="/Hexo-Blog/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Hexo-Blog/libs/aos/aos.js"></script>
    <script src="/Hexo-Blog/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Hexo-Blog/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Hexo-Blog/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Hexo-Blog/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Hexo-Blog/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

	
    

    

    
    <script type="text/javascript" src="/Hexo-Blog/libs/background/ribbon-dynamic.js" async="async"></script>
    

    
    <script src="/Hexo-Blog/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
