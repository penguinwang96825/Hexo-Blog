<!DOCTYPE HTML>
<html lang="en">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Train Word Embedding Vectors on Custom Corpus, Yang&#39;s Blog">
    <meta name="description" content="CS Major / NLP Researcher / Tireless Coder">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Train Word Embedding Vectors on Custom Corpus | Yang&#39;s Blog</title>
    <link rel="icon" type="image/png" href="/Yang-Tech-Blog/favicon.png">

    <link rel="stylesheet" type="text/css" href="/Yang-Tech-Blog/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/Yang-Tech-Blog/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/Yang-Tech-Blog/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/Yang-Tech-Blog/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/Yang-Tech-Blog/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/Yang-Tech-Blog/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/Yang-Tech-Blog/css/my.css">
    
    <script src="/Yang-Tech-Blog/libs/jquery/jquery.min.js"></script>

    <script src='http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default'>
    </script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [['$','$'], ['\\(','\\)']],
                displayMath: [['$$','$$'], ['\\[','\\]']],
                processEscapes: true,
                processEnvironments: true,
            }
        });
    </script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css">
    <script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js">
    </script>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.1"></head>




<body>
    
        <!--  加载动画，强制加载0.5s  -->
        <style type="text/css">
    #loading-container{
    position: fixed;
    top: 0;
    left: 0;
    min-height: 100vh;
    width: 100vw;
    z-index: 9999;
    display: flex;
    flex-direction: column;
    justify-content: center;
    align-items: center;
    background: #FFF;
    text-align: center;
    /* loader页面消失采用渐隐的方式*/
    -webkit-transition: opacity 1s ease;
    -moz-transition: opacity 1s ease;
    -o-transition: opacity 1s ease;
    transition: opacity 1s ease;
}
.loading-image{
    width: 120px;
    height: 50px;
    transform: translate(-50%);
}

.loading-image div:nth-child(2) {
    -webkit-animation: pacman-balls 1s linear 0s infinite;
    animation: pacman-balls 1s linear 0s infinite
}

.loading-image div:nth-child(3) {
    -webkit-animation: pacman-balls 1s linear .33s infinite;
    animation: pacman-balls 1s linear .33s infinite
}

.loading-image div:nth-child(4) {
    -webkit-animation: pacman-balls 1s linear .66s infinite;
    animation: pacman-balls 1s linear .66s infinite
}

.loading-image div:nth-child(5) {
    -webkit-animation: pacman-balls 1s linear .99s infinite;
    animation: pacman-balls 1s linear .99s infinite
}

.loading-image div:first-of-type {
    width: 0;
    height: 0;
    border: 25px solid #49b1f5;
    border-right-color: transparent;
    border-radius: 25px;
    -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
    animation: rotate_pacman_half_up .5s 0s infinite;
}
.loading-image div:nth-child(2) {
    width: 0;
    height: 0;
    border: 25px solid #49b1f5;
    border-right-color: transparent;
    border-radius: 25px;
    -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
    animation: rotate_pacman_half_down .5s 0s infinite;
    margin-top: -50px;
}
@-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

@keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

@-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

@keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

@-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

@keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


.loading-image div:nth-child(3),
.loading-image div:nth-child(4),
.loading-image div:nth-child(5),
.loading-image div:nth-child(6){
    background-color: #49b1f5;
    width: 15px;
    height: 15px;
    border-radius: 100%;
    margin: 2px;
    width: 10px;
    height: 10px;
    position: absolute;
    transform: translateY(-6.25px);
    top: 25px;
    left: 100px;
}
.loading-text{
    margin-bottom: 20vh;
    text-align: center;
    color: #2c3e50;
    font-size: 2rem;
    box-sizing: border-box;
    padding: 0 10px;
    text-shadow: 0 2px 10px rgba(0,0,0,0.2);
}
@media only screen and (max-width: 500px) {
    .loading-text{
        font-size: 1.5rem;
    }
}
.fadeout {
    opacity: 0;
    filter: alpha(opacity=0);
}
/* logo出现动画 */
@-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
@keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
</style>
<div id="loading-container">
    <p class="loading-text">Stealing pages from the server... </p>
    <div class="loading-image">
        <div></div>
        <div></div>
        <div></div>
        <div></div>
        <div></div>
        <div></div>
    </div>
</div>
<script>
    (function () {
        const loaded = function () {
            setTimeout(function () {
                const loader = document.getElementById("loading-container");
                loader.className = "fadeout";
                setTimeout(function () {
                    loader.style.display = "none";
                }, 500);
            }, 500);
        };
        loaded();
    })();
</script>
    
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Yang-Tech-Blog/" class="waves-effect waves-light">
                    
                    <img src="/Yang-Tech-Blog/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Yang&#39;s Blog</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Yang-Tech-Blog/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>Index</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Yang-Tech-Blog/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>Tags</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Yang-Tech-Blog/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>Categories</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Yang-Tech-Blog/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>Archives</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Yang-Tech-Blog/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>About</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Yang-Tech-Blog/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>Contact</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="" class="waves-effect waves-light">

      
      <i class="fas fa-list" style="zoom: 0.6;"></i>
      
      <span>Medias</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="/Yang-Tech-Blog/papers">
          
          <i class="fas fa-book" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Papers</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="Search" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Yang-Tech-Blog/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Yang&#39;s Blog</div>
        <div class="logo-desc">
            
            CS Major / NLP Researcher / Tireless Coder
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Yang-Tech-Blog/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			Index
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Yang-Tech-Blog/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			Tags
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Yang-Tech-Blog/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			Categories
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Yang-Tech-Blog/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			Archives
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Yang-Tech-Blog/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			About
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Yang-Tech-Blog/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			Contact
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-list"></i>
			
			Medias
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>

                  <a href="/Yang-Tech-Blog/papers " style="margin-left:75px">
				  
				   <i class="fa fas fa-book" style="position: absolute;left:50px" ></i>
			      
		          <span>Papers</span>
                  </a>
                </li>
              
            </ul>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/penguinwang96825" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/penguinwang96825" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    
<script src="/Yang-Tech-Blog/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('Please enter the password to access this article!')).toString(CryptoJS.enc.Hex)) {
                alert('Wrong password, will return to the home page!');
                location.href = '/Yang-Tech-Blog/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('https://github.com/penguinwang96825/penguinwang96825.github.io/blob/master/2021/03/02/2021-03-02-train-word-embedding-vectos-on-custom-corpus/jon-tyson.jpg?raw=true')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Train Word Embedding Vectors on Custom Corpus</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/Yang-Tech-Blog/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Yang-Tech-Blog/tags/NLP/">
                                <span class="chip bg-color">NLP</span>
                            </a>
                        
                            <a href="/Yang-Tech-Blog/tags/WSL/">
                                <span class="chip bg-color">WSL</span>
                            </a>
                        
                            <a href="/Yang-Tech-Blog/tags/Ubuntu/">
                                <span class="chip bg-color">Ubuntu</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/Yang-Tech-Blog/categories/NLP/" class="post-category">
                                NLP
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>Publish Date:&nbsp;&nbsp;
                    2021-03-02
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>Word Count:&nbsp;&nbsp;
                    3.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>Read Times:&nbsp;&nbsp;
                    21 Min
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>Read Count:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/Yang-Tech-Blog/libs/prism/prism.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <link rel="stylesheet" type="text&#x2F;css" href="https://cdn.jsdelivr.net/npm/hexo-tag-hint@0.3.1/dist/hexo-tag-hint.min.css"><p>When I was doing my dissertation project, I found out that the performance of model wasn’t quite well. I believe it’s because the domain of pre-trained GoogleNews-vectors-negative300 is different from the the dataset of mine. Hence, I decide to pre-train a word2vec model by myself. In this article, I’ll use a library called “Koan” released by Bloomberg LP. They build CBOW model using C++, which is more efficiently compared to <a target="_blank" rel="noopener" href="https://github.com/tmikolov/word2vec/">word2vec</a> and <a target="_blank" rel="noopener" href="https://github.com/RaRe-Technologies/gensim/">gensim</a> libraries. If you are a Windows user, and you don’t have a Linux system in your computer, please read this <a href="/Yang-Tech-Blog/2021/01/22/2021-01-22-train-word2vec-on-wsl/" title="[article]">[article]</a> I wrote before to set up your WSL.</p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>The reason we care about language is that, because of language, we are able to turn invisible ideas into visible actions. However, language is ambiguous at all levels: lexical, phrasal, semantic. To address this, we need to build a language model, which can convert text into vectors. The most common techniques are Bag of Words (One-Hot Encoding, TF-IDF), Distributional Word Embedding (Word2Vec, GloVe, FastText), and Contextualised Word Embedding (ELMo, BERT). In this article, I’m gonna implement Word2Vec to generate pre-trained vectors.</p>
<h1 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h1><p>Word2Vec is a statistical-based method to obtain word vectors, and it is proposed by Tomas Mikolov et al. [4] of Google in 2013. Word2Vec is available in two flavors, the CBoW model and the Skip-Gram model, which is based on neural networks which can map words to low dimensional space. CBoW model predicts the current word by context, and Skip-Gram model predicts context by current word.</p>
<h2 id="Text-Pre-processing"><a href="#Text-Pre-processing" class="headerlink" title="Text Pre-processing"></a>Text Pre-processing</h2><p>First, you need to read in your csv file containing texts.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">r"./20061020_20131126_bloomberg_news.csv"</span><span class="token punctuation">)</span>
df<span class="token punctuation">[</span><span class="token string">"title"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">"title"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">)</span>
df<span class="token punctuation">[</span><span class="token string">"paragraph"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">"paragraph"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">)</span>
df<span class="token punctuation">.</span>sample<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">title</th>
<th align="center">timestamp</th>
<th align="center">paragraph</th>
</tr>
</thead>
<tbody><tr>
<td align="center">6493</td>
<td align="center">Coronavirus: Malaysia’s Economy Shows Doing th…</td>
<td align="center">2020&#x2F;8&#x2F;23</td>
<td align="center">Strict lockdowns, accommodative central banks,…</td>
</tr>
<tr>
<td align="center">1833</td>
<td align="center">Lower Rates: Trump and the Markets Picked Thei…</td>
<td align="center">2019&#x2F;8&#x2F;7</td>
<td align="center">Collapsing bond yields aren’t exactly a sign …</td>
</tr>
<tr>
<td align="center">4376</td>
<td align="center">Crypto Brokerage Tagomi Gets $12 Million in Se…</td>
<td align="center">2019&#x2F;3&#x2F;4</td>
<td align="center">Tagomi Holdings Inc., a digital asset brokerag…</td>
</tr>
</tbody></table>
<p>Second, put them into a list.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">documents <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
documents<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">"title"</span><span class="token punctuation">,</span> <span class="token string">"paragraph"</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>Third, do some text cleaning work.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">regex</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    text <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r"([^a-zA-Z0-9\.\?\,\!\%\']+)"</span><span class="token punctuation">,</span> <span class="token string">" "</span><span class="token punctuation">,</span> text<span class="token punctuation">)</span>
    text <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r"(?&lt;=\d),(?=\d)+"</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">,</span> text<span class="token punctuation">)</span>
    text <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r"\,"</span><span class="token punctuation">,</span> <span class="token string">" , "</span><span class="token punctuation">,</span> text<span class="token punctuation">)</span>
    text <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r"\?"</span><span class="token punctuation">,</span> <span class="token string">" ? "</span><span class="token punctuation">,</span> text<span class="token punctuation">)</span>
    text <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r"\!"</span><span class="token punctuation">,</span> <span class="token string">" ! "</span><span class="token punctuation">,</span> text<span class="token punctuation">)</span>
    text <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r"\."</span><span class="token punctuation">,</span> <span class="token string">" . "</span><span class="token punctuation">,</span> text<span class="token punctuation">)</span>
    text <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r"  "</span><span class="token punctuation">,</span> <span class="token string">" "</span><span class="token punctuation">,</span> text<span class="token punctuation">)</span>
    text <span class="token operator">=</span> text<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> text

docs <span class="token operator">=</span> <span class="token punctuation">[</span>regex<span class="token punctuation">(</span>doc<span class="token punctuation">)</span> <span class="token keyword">for</span> doc <span class="token keyword">in</span> documents<span class="token punctuation">]</span>
docs_cased <span class="token operator">=</span> <span class="token punctuation">[</span>regex<span class="token punctuation">(</span>doc<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> doc <span class="token keyword">in</span> documents<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="Tokenisation"><a href="#Tokenisation" class="headerlink" title="Tokenisation"></a>Tokenisation</h2><p>You’ll need to prepare your corpus as a single text file with all words separated by one or more spaces or tabs.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">progressbar</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">,</span> prefix<span class="token operator">=</span><span class="token string">""</span><span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stdout<span class="token punctuation">)</span><span class="token punctuation">:</span>
    count <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">show</span><span class="token punctuation">(</span>t<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>size<span class="token operator">*</span>t<span class="token operator">/</span>count<span class="token punctuation">)</span>
        <span class="token comment"># file.write("%s[%s%s] %i/%i\r" % (prefix, "#"*x, "."*(size-x), int(100*t/count), 100))</span>
        <span class="token builtin">file</span><span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"&#123;&#125;[&#123;&#125;&#123;&#125;] &#123;&#125;%\r"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>prefix<span class="token punctuation">,</span> <span class="token string">"█"</span><span class="token operator">*</span>x<span class="token punctuation">,</span> <span class="token string">"."</span><span class="token operator">*</span><span class="token punctuation">(</span>size<span class="token operator">-</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token operator">*</span>t<span class="token operator">/</span>count<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token builtin">file</span><span class="token punctuation">.</span>flush<span class="token punctuation">(</span><span class="token punctuation">)</span>
    show<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> item <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">yield</span> item
        show<span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token builtin">file</span><span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">)</span>
    <span class="token builtin">file</span><span class="token punctuation">.</span>flush<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">Tokenizer</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> 
                 char_level<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> 
                 num_tokens<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> 
                 pad_token<span class="token operator">=</span><span class="token string">'&lt;PAD>'</span><span class="token punctuation">,</span> 
                 oov_token<span class="token operator">=</span><span class="token string">'&lt;UNK>'</span><span class="token punctuation">,</span> 
                 token_to_index<span class="token operator">=</span><span class="token boolean">None</span>
                <span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>char_level <span class="token operator">=</span> char_level
        self<span class="token punctuation">.</span>separator <span class="token operator">=</span> <span class="token string">''</span> <span class="token keyword">if</span> self<span class="token punctuation">.</span>char_level <span class="token keyword">else</span> <span class="token string">' '</span>
        <span class="token comment"># &lt;PAD> + &lt;UNK> tokens</span>
        <span class="token keyword">if</span> num_tokens<span class="token punctuation">:</span> num_tokens <span class="token operator">-=</span> <span class="token number">2</span>
        self<span class="token punctuation">.</span>num_tokens <span class="token operator">=</span> num_tokens
        self<span class="token punctuation">.</span>oov_token <span class="token operator">=</span> oov_token
        <span class="token keyword">if</span> <span class="token keyword">not</span> token_to_index<span class="token punctuation">:</span>
            token_to_index <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">'&lt;PAD>'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'&lt;UNK>'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">&#125;</span>
        self<span class="token punctuation">.</span>token_to_index <span class="token operator">=</span> token_to_index
        self<span class="token punctuation">.</span>index_to_token <span class="token operator">=</span> <span class="token punctuation">&#123;</span>v<span class="token punctuation">:</span> k <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> self<span class="token punctuation">.</span>token_to_index<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span>

    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>token_to_index<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">__str__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token string-interpolation"><span class="token string">f"&lt;Tokenizer(num_tokens=</span><span class="token interpolation"><span class="token punctuation">&#123;</span><span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">&#125;</span></span><span class="token string">)>"</span></span>

    <span class="token keyword">def</span> <span class="token function">fit_on_texts</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> texts<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>char_level<span class="token punctuation">:</span>
            all_tokens <span class="token operator">=</span> <span class="token punctuation">[</span>token <span class="token keyword">for</span> text <span class="token keyword">in</span> texts <span class="token keyword">for</span> token <span class="token keyword">in</span> text<span class="token punctuation">]</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> self<span class="token punctuation">.</span>char_level<span class="token punctuation">:</span>
            all_tokens <span class="token operator">=</span> <span class="token punctuation">[</span>token <span class="token keyword">for</span> text <span class="token keyword">in</span> texts <span class="token keyword">for</span> token <span class="token keyword">in</span> text<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        counts <span class="token operator">=</span> Counter<span class="token punctuation">(</span>all_tokens<span class="token punctuation">)</span><span class="token punctuation">.</span>most_common<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_tokens<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>min_token_freq <span class="token operator">=</span> counts<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> token<span class="token punctuation">,</span> count <span class="token keyword">in</span> progressbar<span class="token punctuation">(</span>counts<span class="token punctuation">,</span> prefix<span class="token operator">=</span><span class="token string">"VOCAB"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            index <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>token_to_index<span class="token punctuation">[</span>token<span class="token punctuation">]</span> <span class="token operator">=</span> index
            self<span class="token punctuation">.</span>index_to_token<span class="token punctuation">[</span>index<span class="token punctuation">]</span> <span class="token operator">=</span> token
        <span class="token keyword">return</span> self

    <span class="token keyword">def</span> <span class="token function">texts_to_sequences</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> texts<span class="token punctuation">)</span><span class="token punctuation">:</span>
        sequences <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> text <span class="token keyword">in</span> progressbar<span class="token punctuation">(</span>texts<span class="token punctuation">,</span> prefix<span class="token operator">=</span><span class="token string">"TEXT2SEQ"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token keyword">not</span> self<span class="token punctuation">.</span>char_level<span class="token punctuation">:</span>
                text <span class="token operator">=</span> text<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>
            sequence <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            <span class="token keyword">for</span> token <span class="token keyword">in</span> text<span class="token punctuation">:</span>
                sequence<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>token_to_index<span class="token punctuation">.</span>get<span class="token punctuation">(</span>
                    token<span class="token punctuation">,</span> self<span class="token punctuation">.</span>token_to_index<span class="token punctuation">[</span>self<span class="token punctuation">.</span>oov_token<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            sequences<span class="token punctuation">.</span>append<span class="token punctuation">(</span>sequence<span class="token punctuation">)</span>
        <span class="token keyword">return</span> sequences

    <span class="token keyword">def</span> <span class="token function">sequences_to_texts</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> sequences<span class="token punctuation">)</span><span class="token punctuation">:</span>
        texts <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> sequence <span class="token keyword">in</span> progressbar<span class="token punctuation">(</span>sequences<span class="token punctuation">,</span> prefix<span class="token operator">=</span><span class="token string">"SEQ2TEXT"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            text <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            <span class="token keyword">for</span> index <span class="token keyword">in</span> sequence<span class="token punctuation">:</span>
                text<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>index_to_token<span class="token punctuation">.</span>get<span class="token punctuation">(</span>index<span class="token punctuation">,</span> self<span class="token punctuation">.</span>oov_token<span class="token punctuation">)</span><span class="token punctuation">)</span>
            texts<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>separator<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span>token <span class="token keyword">for</span> token <span class="token keyword">in</span> text<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> texts

    <span class="token keyword">def</span> <span class="token function">save</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> fp<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>fp<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fp<span class="token punctuation">:</span>
            contents <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
                <span class="token string">'char_level'</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>char_level<span class="token punctuation">,</span>
                <span class="token string">'oov_token'</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>oov_token<span class="token punctuation">,</span>
                <span class="token string">'token_to_index'</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>token_to_index
            <span class="token punctuation">&#125;</span>
            json<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>contents<span class="token punctuation">,</span> fp<span class="token punctuation">,</span> indent<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> sort_keys<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

    <span class="token decorator annotation punctuation">@classmethod</span>
    <span class="token keyword">def</span> <span class="token function">load</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> fp<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>fp<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> fp<span class="token punctuation">:</span>
            kwargs <span class="token operator">=</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span>fp<span class="token operator">=</span>fp<span class="token punctuation">)</span>
        <span class="token keyword">return</span> cls<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">tokeniser <span class="token operator">=</span> Tokenizer<span class="token punctuation">(</span>char_level<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> num_tokens<span class="token operator">=</span><span class="token number">1000000</span><span class="token punctuation">)</span>
tokeniser<span class="token punctuation">.</span>fit_on_texts<span class="token punctuation">(</span>docs_cased<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
sequences <span class="token operator">=</span> tokeniser<span class="token punctuation">.</span>texts_to_sequences<span class="token punctuation">(</span>docs_cased<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
texts <span class="token operator">=</span> tokeniser<span class="token punctuation">.</span>sequences_to_texts<span class="token punctuation">(</span>sequences<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>sequences<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"="</span><span class="token operator">*</span><span class="token number">50</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>texts<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<pre class="line-numbers language-console" data-language="console"><code class="language-console">[[21789, 358380, 4, 37272, 4, 61540, 358381, 5009, 1964, 5, 2902, 37914], [21789, 4, 37272, 4, 61540, 9, 1133, 34, 1299, 3, 122, 577, 10, 123, 6313, 1253, 294, 8, 547, 11, 25, 304, 2], [7233, 80031, 1117, 546, 47, 9039, 6, 39, 2225, 7, 29623], [328, 19, 1338, 16712, 6, 126, 179, 2, 305, 241, 14, 11689, 606, 2848, 3368, 4, 3, 1166, 1794, 19, 552, 4, 32651, 34, 259, 4, 2902, 577, 10, 2514, 1352, 8, 252, 2, 9, 596, 13, 18410, 4, 850, 606, 3, 7233, 80031, 2], [304, 6076, 3389, 19, 6, 4488, 90, 1037, 488]]
&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;
[&#39;ethereum xet , xrp , litecoin xlc cryptocurrency alternative to bitcoin btc&#39;, &#39;ethereum , xrp , litecoin and others are giving the world ? s most famous digital currency a run for its money .&#39;, &#39;crypto opportunists create 500 more coins in new phase of mania&#39;, &#39;risk is running rampant in financial markets . stocks trade at dot come era valuations , the ipo pipeline is full , spacs are back , bitcoin ? s headed toward a record . and right on cue , here come the crypto opportunists .&#39;, &#39;money stuff exxon is in trouble over climate change&#39;]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>After tokenised our corpus, save it to a <code>news.tokens</code> file.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'./news.tokens'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    <span class="token keyword">for</span> item <span class="token keyword">in</span> texts<span class="token punctuation">:</span>
        f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"%s\n"</span> <span class="token operator">%</span> item<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<h2 id="Training-Process"><a href="#Training-Process" class="headerlink" title="Training Process"></a>Training Process</h2><p>Word2vec is a two-layer neural net that processes text by “vectorizing” words. Its input is a text corpus and its output is a set of vectors: feature vectors that represent words in that corpus.</p>
<h3 id="CBOW"><a href="#CBOW" class="headerlink" title="CBOW"></a>CBOW</h3><p>Move your <code>news.tokens</code> file to WSL folder. In my case, it is at <code>C:\Users\yangwang\AppData\Local\Packages\CanonicalGroupLimited.Ubuntu18.04onWindows_79rhkp1fndgsc\LocalState\rootfs\home\yang\</code>.</p>
<p>Next, open your mobaxterm and execute the following code.</p>
<img src="/Yang-Tech-Blog/2021/03/02/2021-03-02-train-word-embedding-vectos-on-custom-corpus/mobaxterm.jpg" class="">

<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> ./build/koan -V <span class="token number">1000000</span> <span class="token punctuation">\</span>
             --epochs <span class="token number">10</span> <span class="token punctuation">\</span>
             --dim <span class="token number">300</span> <span class="token punctuation">\</span>
             --negatives <span class="token number">5</span> <span class="token punctuation">\</span>
             --context-size <span class="token number">5</span> <span class="token punctuation">\</span>
             -l <span class="token number">0.075</span> <span class="token punctuation">\</span>
             --threads <span class="token number">16</span> <span class="token punctuation">\</span>
             --cbow <span class="token boolean">true</span> <span class="token punctuation">\</span>
             --min-count <span class="token number">2</span> <span class="token punctuation">\</span>
             --file ./news.tokens<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>Learned embeddings will be saved to <code>embeddings_$&#123;CURRENT_TIMESTAMP&#125;.txt</code> in the present working directory.</p>
<h3 id="Skip-Gram"><a href="#Skip-Gram" class="headerlink" title="Skip-Gram"></a>Skip-Gram</h3><p>Similarly, you can get the pre-trained vectors by Skip-Gram, just set <code>cbow</code> to <code>false</code>.</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span>  ./build/koan -V <span class="token number">1000000</span> <span class="token punctuation">\</span>
             --epochs <span class="token number">10</span> <span class="token punctuation">\</span>
             --dim <span class="token number">300</span> <span class="token punctuation">\</span>
             --negatives <span class="token number">5</span> <span class="token punctuation">\</span>
             --context-size <span class="token number">5</span> <span class="token punctuation">\</span>
             -l <span class="token number">0.075</span> <span class="token punctuation">\</span>
             --threads <span class="token number">16</span> <span class="token punctuation">\</span>
             --cbow <span class="token boolean">false</span> <span class="token punctuation">\</span>
             --min-count <span class="token number">2</span> <span class="token punctuation">\</span>
             --file ./news.tokens<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="Convert-GloVe-Format-to-Word2Vec-Format"><a href="#Convert-GloVe-Format-to-Word2Vec-Format" class="headerlink" title="Convert GloVe Format to Word2Vec Format"></a>Convert GloVe Format to Word2Vec Format</h2><p>Move your pre-trained vectors back to your Windows folder, and change your file name to <code>news-cbow-negative300.txt</code> (or <code>news-skipgram-negative300.txt</code>, depend on how you trained it). We then convert GloVe vectors format into the word2vec format.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> gensim<span class="token punctuation">.</span>models <span class="token keyword">import</span> KeyedVectors
<span class="token keyword">from</span> gensim<span class="token punctuation">.</span>scripts<span class="token punctuation">.</span>glove2word2vec <span class="token keyword">import</span> glove2word2vec

_ <span class="token operator">=</span> glove2word2vec<span class="token punctuation">(</span><span class="token string">"./news-cbow-negative300.txt"</span><span class="token punctuation">,</span> <span class="token string">"./news-word2vec-cbow-negative300.txt"</span><span class="token punctuation">)</span>
wv_from_text <span class="token operator">=</span> KeyedVectors<span class="token punctuation">.</span>load_word2vec_format<span class="token punctuation">(</span><span class="token string">"./news-word2vec-cbow-negative300.txt"</span><span class="token punctuation">,</span> binary<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><strong>Notes</strong></p>
<p>GloVe format (a real example can be found on the <a target="_blank" rel="noopener" href="https://nlp.stanford.edu/projects/glove/">Stanford site</a>)</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">word1 <span class="token number">0.123</span> <span class="token number">0.134</span> <span class="token number">0.532</span> <span class="token number">0.152</span>
word2 <span class="token number">0.934</span> <span class="token number">0.412</span> <span class="token number">0.532</span> <span class="token number">0.159</span>
word3 <span class="token number">0.334</span> <span class="token number">0.241</span> <span class="token number">0.324</span> <span class="token number">0.188</span>
<span class="token punctuation">..</span>.
word9 <span class="token number">0.334</span> <span class="token number">0.241</span> <span class="token number">0.324</span> <span class="token number">0.188</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>Word2Vec format (a real example can be found in the <a target="_blank" rel="noopener" href="https://code.google.com/archive/p/word2vec/">old w2v repository</a>).</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token number">9</span> <span class="token number">4</span>
word1 <span class="token number">0.123</span> <span class="token number">0.134</span> <span class="token number">0.532</span> <span class="token number">0.152</span>
word2 <span class="token number">0.934</span> <span class="token number">0.412</span> <span class="token number">0.532</span> <span class="token number">0.159</span>
word3 <span class="token number">0.334</span> <span class="token number">0.241</span> <span class="token number">0.324</span> <span class="token number">0.188</span>
<span class="token punctuation">..</span>.
word9 <span class="token number">0.334</span> <span class="token number">0.241</span> <span class="token number">0.324</span> <span class="token number">0.188</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>Voilà! You have successfully got a pre-trained word embedding!</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">wv_from_text<span class="token punctuation">.</span>similar_by_word<span class="token punctuation">(</span><span class="token string">"bitcoin"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<hr>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'cryptocurrency'</span>, <span class="token number">0.7397603392601013</span><span class="token punctuation">)</span>,
 <span class="token punctuation">(</span><span class="token string">'cryptocurrencies'</span>, <span class="token number">0.7099655866622925</span><span class="token punctuation">)</span>,
 <span class="token punctuation">(</span><span class="token string">'crypto'</span>, <span class="token number">0.6509920358657837</span><span class="token punctuation">)</span>,
 <span class="token punctuation">(</span><span class="token string">'xrp'</span>, <span class="token number">0.5511361360549927</span><span class="token punctuation">)</span>,
 <span class="token punctuation">(</span><span class="token string">'ethereum'</span>, <span class="token number">0.547865629196167</span><span class="token punctuation">)</span>,
 <span class="token punctuation">(</span><span class="token string">'monero'</span>, <span class="token number">0.5345401167869568</span><span class="token punctuation">)</span>,
 <span class="token punctuation">(</span><span class="token string">"bitcoin's"</span>, <span class="token number">0.5305401086807251</span><span class="token punctuation">)</span>,
 <span class="token punctuation">(</span><span class="token string">'bitcoins'</span>, <span class="token number">0.5253546237945557</span><span class="token punctuation">)</span>,
 <span class="token punctuation">(</span><span class="token string">'gold'</span>, <span class="token number">0.5229815244674683</span><span class="token punctuation">)</span>,
 <span class="token punctuation">(</span><span class="token string">'blockchain'</span>, <span class="token number">0.508536159992218</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h1 id="Train-GloVe-on-WSL"><a href="#Train-GloVe-on-WSL" class="headerlink" title="Train GloVe on WSL"></a>Train GloVe on WSL</h1><p>GloVe (Global Vectors for Word Representation) is an alternate method to create word embeddings. It is based on matrix factorization techniques on the word-context matrix.</p>
<h2 id="Download-GloVe"><a href="#Download-GloVe" class="headerlink" title="Download GloVe"></a>Download GloVe</h2><p>Download <a target="_blank" rel="noopener" href="https://github.com/stanfordnlp/GloVe">GloVe</a> library from Standford’s GitHub</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">git</span> clone https://github.com/stanfordnlp/glove
<span class="token builtin class-name">cd</span> glove <span class="token operator">&amp;&amp;</span> <span class="token function">make</span>
./demo.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<h2 id="Training-Process-1"><a href="#Training-Process-1" class="headerlink" title="Training Process"></a>Training Process</h2><p>This is how you run the model:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">git</span> clone http://github.com/stanfordnlp/glove
<span class="token builtin class-name">cd</span> glove <span class="token operator">&amp;&amp;</span> <span class="token function">make</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>To train it on your own corpus, you just have to make changes to one file, that is <code>demo.sh</code>.</p>
<p>Remove the script from <code>if</code> to <code>fi</code> after <code>make</code>. Replace the <code>CORPUS</code> name with your file name, in our case, <code>news.tokens</code> There is another if loop at the end of file <code>demo.sh</code>.</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token keyword">if</span> <span class="token punctuation">[</span> <span class="token string">"<span class="token variable">$CORPUS</span>"</span> <span class="token operator">=</span> <span class="token string">'text8'</span> <span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token keyword">then</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>Replace <code>text8</code> with <code>news.tokens</code>.</p>
<p>Run the <code>demo.sh</code> once the changes are made.</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ ./demo.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>Don’t forget to keep your corpus file directly inside the Glove folder. Make sure your corpus file is in the correct format.You’ll need to prepare your corpus as a single text file with all words separated by one or more spaces or tabs. If your corpus has multiple documents, the documents (only) should be separated by new line characters.</p>
<p>Sometimes, you have trouble with running <code>./demo.sh</code>. When you use <code>./demo.sh</code>, you’ll get <code>sudo: demo.sh: command not found</code>.</p>
<p>Here’s a summary of how to troubleshoot the <strong>Permission Denied error</strong> in our case.</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">ls</span> -l demo.sh <span class="token comment"># Check file permissions of demo.sh</span>
---------- <span class="token number">1</span> yang yang <span class="token number">0</span> <span class="token number">2039</span>-10-21 <span class="token number">14</span>:47 foo.sh 
    ^^^ 
 ^^^ <span class="token operator">|</span> ^^^   ^^^^ ^^^^
  <span class="token operator">|</span>  <span class="token operator">|</span>  <span class="token operator">|</span>      <span class="token operator">|</span>    <span class="token operator">|</span> 
Owner<span class="token operator">|</span> World   <span class="token operator">|</span>    <span class="token operator">|</span>
     <span class="token operator">|</span>         <span class="token operator">|</span>  Name of
   Group       <span class="token operator">|</span>   Group
            Name of 
             Owner<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>Owner has no read and write access <code>rw</code> and the <code>-</code> indicates that the executable permission is missing. The <code>chmod</code> command fixes that. (Group and other only have read permission set on the file, they cannot write to it or execute it).</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">chmod</span> +x demo.sh
<span class="token function">chmod</span> +r demo.sh
<span class="token function">chmod</span> +w demo.sh
<span class="token function">ls</span> -l demo.sh<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<p><code>demo.sh</code> is now executable as far as Linux is concerned.</p>
<img src="/Yang-Tech-Blog/2021/03/02/2021-03-02-train-word-embedding-vectos-on-custom-corpus/train-glove.jpg" class="">

<h2 id="Convert-GloVe-Format-to-Word2Vec-Format-1"><a href="#Convert-GloVe-Format-to-Word2Vec-Format-1" class="headerlink" title="Convert GloVe Format to Word2Vec Format"></a>Convert GloVe Format to Word2Vec Format</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">_ <span class="token operator">=</span> glove2word2vec<span class="token punctuation">(</span><span class="token string">"./news-glove-vectors300.txt"</span><span class="token punctuation">,</span> <span class="token string">"./news-glove-w2vformat-vectors300.txt"</span><span class="token punctuation">)</span>
wv_glove <span class="token operator">=</span> KeyedVectors<span class="token punctuation">.</span>load_word2vec_format<span class="token punctuation">(</span><span class="token string">"./news-glove-w2vformat-vectors300.txt"</span><span class="token punctuation">,</span> binary<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>Test it on ‘bitcoin’ token.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">wv_glove<span class="token punctuation">.</span>similar_by_word<span class="token punctuation">(</span><span class="token string">"bitcoin"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<hr>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'cryptocurrency'</span>, <span class="token number">0.7422985434532166</span><span class="token punctuation">)</span>,
 <span class="token punctuation">(</span><span class="token string">'cryptocurrencies'</span>, <span class="token number">0.6949392557144165</span><span class="token punctuation">)</span>,
 <span class="token punctuation">(</span><span class="token string">'crypto'</span>, <span class="token number">0.6679537296295166</span><span class="token punctuation">)</span>,
 <span class="token punctuation">(</span><span class="token string">'blockchain'</span>, <span class="token number">0.5640972852706909</span><span class="token punctuation">)</span>,
 <span class="token punctuation">(</span><span class="token string">'bitcoins'</span>, <span class="token number">0.4695727825164795</span><span class="token punctuation">)</span>,
 <span class="token punctuation">(</span><span class="token string">'ethereum'</span>, <span class="token number">0.4689256548881531</span><span class="token punctuation">)</span>,
 <span class="token punctuation">(</span><span class="token string">'ether'</span>, <span class="token number">0.4526808261871338</span><span class="token punctuation">)</span>,
 <span class="token punctuation">(</span><span class="token string">'virtual'</span>, <span class="token number">0.43389463424682617</span><span class="token punctuation">)</span>,
 <span class="token punctuation">(</span><span class="token string">'tokens'</span>, <span class="token number">0.42009514570236206</span><span class="token punctuation">)</span>,
 <span class="token punctuation">(</span><span class="token string">'coins'</span>, <span class="token number">0.418658971786499</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h1 id="Train-FastText-on-WSL"><a href="#Train-FastText-on-WSL" class="headerlink" title="Train FastText on WSL"></a>Train FastText on WSL</h1><p>FastText is a library for efficient learning of word representations and sentence classification. FastText builds on modern Mac OS and Linux distributions. Since it uses C++11 features, it requires a compiler with good C++11 support.</p>
<h2 id="Download-FastText"><a href="#Download-FastText" class="headerlink" title="Download FastText"></a>Download FastText</h2><p>Install FastText.</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">wget</span> https://github.com/facebookresearch/fastText/archive/v0.9.2.zip
<span class="token function">unzip</span> v0.9.2.zip<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>And move to the FastText directory and build it.</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">
<span class="token builtin class-name">cd</span> fastText-0.9.2
<span class="token function">make</span>
pip <span class="token function">install</span> <span class="token builtin class-name">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="Training-Process-2"><a href="#Training-Process-2" class="headerlink" title="Training Process"></a>Training Process</h2><p>Training word vectors using skipgram: </p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> ./fasttext skipgram -input news.tokens -output news-fasttext-skipgram-vectors300 -minn <span class="token number">3</span> -maxn <span class="token number">6</span> -dim <span class="token number">300</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>Training word vectors using cbow:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">sdudo ./fasttext cbow -input news.tokens -output news-fasttext-cbow-vectors300 -minn <span class="token number">3</span> -maxn <span class="token number">6</span> -dim <span class="token number">300</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>where <code>news.tokens</code> is the training file containing UTF-8 encoded text we used before. By default the word vectors will take into account character n-grams from 3 to 6 characters. At the end of optimization the program will save two files: <code>skipgram-model.bin</code> and <code>cbow-model.vec</code>. <code>model.vec</code> is a text file containing the word vectors, one per line. <code>model.bin</code> is a binary file containing the parameters of the model along with the dictionary and all hyper parameters. The binary file can be used later to compute word vectors or to restart the optimization.</p>
<p>Instead of training through command line, you can also train it using Python.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> fasttext
model <span class="token operator">=</span> fasttext<span class="token punctuation">.</span>train_unsupervised<span class="token punctuation">(</span><span class="token string">'news.tokens'</span><span class="token punctuation">,</span> 
                                    <span class="token string">"cbow"</span><span class="token punctuation">,</span> 
                                    minn<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> 
                                    maxn<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span> 
                                    dim<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">,</span> 
                                    epoch<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> 
                                    lr<span class="token operator">=</span><span class="token number">0.05</span><span class="token punctuation">,</span> 
                                    thread<span class="token operator">=</span><span class="token number">12</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>save_model<span class="token punctuation">(</span><span class="token string">"news-fasttext-cbow-vectors300.bin"</span><span class="token punctuation">)</span>
wv_fasttext_cbow <span class="token operator">=</span> fasttext<span class="token punctuation">.</span>load_model<span class="token punctuation">(</span><span class="token string">"news-fasttext-cbow-vectors300.bin"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>Depending on the quantity of data you have, you may want to change the parameters of the training. The <code>epoch</code> parameter controls how many times the model will loop over your data. By default, we loop over the dataset 5 times. If you dataset is extremely massive, you may want to loop over it less often. Another important parameter is the learning rate <code>-lr</code>. The higher the learning rate is, the faster the model converge to a solution but at the risk of overfitting to the dataset. The default value is <code>0.05</code> which is a good compromise. If you want to play with it we suggest to stay in the range of [0.01, 1]. Finally , fastText is multi-threaded and uses 12 threads by default. If you have less CPU cores (say 4), you can easily set the number of threads using the thread flag.</p>
<h2 id="Printing-Word-Vectors"><a href="#Printing-Word-Vectors" class="headerlink" title="Printing Word Vectors"></a>Printing Word Vectors</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">wv_fasttext_cbow<span class="token punctuation">.</span>get_word_vector<span class="token punctuation">(</span><span class="token string">"bitcoin"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<hr>
<pre class="line-numbers language-console" data-language="console"><code class="language-console">array([-4.72412445e-02,  2.85789132e-01,  3.42660360e-02,  2.09649026e-01,
       -4.54065323e-01, -1.91382036e-01, -5.00535131e-01,  1.86818153e-01,
        3.03504705e-01, -1.97448403e-01,  1.50050864e-01,  6.53051957e-02,
       -7.71196038e-02, -8.81627798e-02,  3.74232829e-02,  1.92417011e-01,
        3.55105817e-01,  3.28541487e-01, -3.44138265e-01, -4.90421832e-01,
       -2.13972241e-01,  1.74339145e-01, -3.67868505e-02,  1.09374836e-01,
        3.75284493e-01,  1.03113867e-01, -1.45857438e-01, -3.04340214e-01,
       -2.54121244e-01,  1.69611394e-01, -2.09063217e-01,  2.09711909e-01,
       -1.41518816e-01,  1.25664864e-02,  3.95129383e-01, -1.39495045e-01,
        8.94690026e-03,  4.83614445e-01,  7.68003613e-02, -1.72020838e-01,
        2.65787989e-01,  6.64022043e-02,  1.34228259e-01,  4.24850464e-01,
        5.29484272e-01,  7.14946613e-02, -1.55057460e-01,  6.64764345e-02,
       -1.79950804e-01,  2.07342580e-02, -5.48851252e-01,  2.00532869e-01,
        2.39266697e-02, -3.15076023e-01,  1.58537552e-01, -1.75947800e-01,
       -4.23456818e-01,  2.27220535e-01, -1.18757211e-01, -1.85626462e-01,
        2.09006771e-01, -1.08534403e-01,  2.79801786e-01, -1.84326231e-01,
        3.45385611e-01,  2.19469175e-01, -1.65827513e-01, -9.27144065e-02,
       -9.44910273e-02,  4.01960224e-01,  2.21235991e-01, -2.24734709e-01,
        5.92879727e-02,  3.68174642e-01, -1.62111774e-01, -3.60321164e-01,
       -3.73723418e-01, -2.35717162e-01, -4.61407304e-01, -1.32908091e-01,
        6.76851049e-02,  2.14217320e-01, -4.72074896e-01,  1.62981063e-01,
        3.71879905e-01,  1.01424217e-01, -2.97889352e-01, -3.91066521e-01,
       -2.46688813e-01,  5.42590201e-01, -1.35109276e-01,  3.26993912e-01,
        2.32391551e-01,  2.00287759e-01, -1.49581164e-01, -2.75721133e-01,
        4.79313314e-01,  2.26864532e-01, -1.83264613e-02,  1.18657842e-01,
        1.28447264e-01, -3.34220439e-01,  2.69317508e-01, -2.59843171e-01,
        3.10199022e-01,  2.16098920e-01, -1.86288506e-01,  5.94185330e-02,
       -4.23078507e-01,  5.34226038e-02,  2.08673358e-01, -1.05236337e-01,
        3.77959639e-01, -1.97113946e-01,  3.33479345e-01,  3.94979984e-01,
        1.35598034e-01,  7.51101971e-03,  2.95481265e-01, -2.15200692e-01,
        2.40353987e-01,  3.65436196e-01, -1.55092150e-01,  1.55085281e-01,
       -4.16599452e-01, -3.74957502e-01, -8.32035206e-03, -7.39385858e-02,
        2.17583347e-02, -3.48901063e-01, -9.27907787e-03,  1.24386065e-01,
        7.21558109e-02, -5.65859616e-01,  2.39448603e-02, -6.12365842e-01,
       -3.45480561e-01,  6.63597524e-01, -5.31071126e-01, -3.11197668e-01,
       -2.66234726e-01,  4.01567996e-01,  7.12649003e-02,  2.27668926e-01,
        3.60199302e-01,  1.40796080e-01, -1.30780600e-02, -4.35646117e-01,
       -3.15058351e-01,  1.79761440e-01, -7.38127008e-02, -1.57344565e-01,
       -1.30275175e-01, -2.29776427e-01, -3.11963826e-01,  2.51461089e-01,
       -7.77154416e-02, -1.93161428e-01, -1.22963764e-01,  1.19474560e-01,
       -1.70210376e-02, -6.77634845e-04,  7.12327287e-03, -2.26126343e-01,
        2.12814316e-01,  1.10432744e-01, -3.75197530e-01, -2.51778066e-01,
        2.61254579e-01, -1.91191047e-01,  1.73024654e-01, -1.69590712e-01,
        1.13725312e-01, -4.02675480e-01, -7.49008298e-01, -4.75077957e-01,
        4.30675596e-03, -5.70537090e-01, -3.68678004e-01, -1.18338585e-01,
        1.02712013e-01,  1.67967491e-02,  5.66727901e-03,  5.40452838e-01,
        4.11487877e-01,  6.39163136e-01,  4.11166042e-01, -2.50596225e-01,
       -1.04347736e-01, -2.55890310e-01,  1.25067562e-01,  3.32301527e-01,
        1.40600502e-01, -2.42391825e-01, -1.40091211e-01, -2.05069736e-01,
       -5.73189482e-02,  2.14646116e-01, -2.63260067e-01,  2.00784519e-01,
        2.35700160e-01,  3.53334904e-01,  5.38006604e-01,  1.59950554e-01,
        1.52627319e-01, -2.47434601e-01, -6.53754920e-02, -1.69809297e-01,
       -2.81990021e-01, -4.69022483e-01, -1.67136639e-01,  2.62764134e-02,
       -1.31334037e-01,  5.59901476e-01, -1.58817634e-01, -3.86552542e-01,
       -3.78590643e-01,  1.53091252e-01,  1.59801438e-01,  3.00560832e-01,
        9.51611772e-02, -1.25739768e-01, -2.82772869e-01, -2.11738721e-01,
       -1.44721761e-01,  3.01432371e-01, -2.95276958e-02, -4.21232760e-01,
        1.95821151e-01, -1.03478849e-01,  3.75818871e-02,  7.30549470e-02,
       -1.24263890e-01,  4.21253517e-02,  5.34670353e-02, -6.04710579e-02,
        4.18751776e-01, -1.89714432e-01,  7.75871202e-02,  2.64797509e-01,
        6.84403598e-01, -2.88427889e-01,  2.65219778e-01, -9.75028351e-02,
       -2.16612965e-01, -1.84845805e-01,  3.57705653e-01,  1.84521660e-01,
       -2.25650191e-01, -2.41775334e-01,  6.35201484e-02,  1.05721205e-01,
       -2.76269794e-01,  7.44905397e-02, -4.05652225e-01, -3.25192034e-01,
        1.33607000e-01, -2.70021617e-01, -5.09377658e-01,  8.15921091e-03,
        1.39862090e-01,  2.68142492e-01,  3.83002162e-01,  1.91613629e-01,
        2.66971558e-01, -2.08550826e-01, -1.84474185e-01,  2.28107542e-01,
       -1.41805783e-01, -3.34146500e-01,  5.33484481e-02,  1.27584279e-01,
        8.07003453e-02,  1.00570947e-01, -4.74314131e-02,  2.64507622e-01,
        5.04497468e-01,  8.56446847e-02,  4.17862684e-01,  1.42475590e-01,
       -1.79341078e-01, -2.17798918e-01,  8.03667828e-02, -1.44884512e-01,
       -2.44018864e-02, -7.17387274e-02,  8.83749798e-02,  1.36670202e-01,
       -1.49312671e-02, -4.16279852e-01,  1.23666152e-01,  4.03715611e-01,
        3.15533012e-01,  2.58996665e-01, -2.77972668e-01,  1.68511316e-01,
        1.92251951e-01,  1.12253219e-01, -4.47139591e-01,  2.39150673e-01],
      dtype&#x3D;float32)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="Nearest-neighbor-queries"><a href="#Nearest-neighbor-queries" class="headerlink" title="Nearest neighbor queries"></a>Nearest neighbor queries</h2><p>A simple way to check the quality of a word vector is to look at its nearest neighbors. This give an intuition of the type of semantic information the vectors are able to capture.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">wv_fasttext_cbow<span class="token punctuation">.</span>get_nearest_neighbors<span class="token punctuation">(</span><span class="token string">'bitcoin'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<hr>
<pre class="line-numbers language-console" data-language="console"><code class="language-console">[(0.8654916286468506, &#39;cryptocurrency&#39;),
 (0.8515545725822449, &#39;bitcoins&#39;),
 (0.8421329855918884, &#39;bitcointalk&#39;),
 (0.8405554890632629, &#39;cryptocurrencies&#39;),
 (0.8251032829284668, &#39;tcoin&#39;),
 (0.8214054703712463, &#39;bitcoiners&#39;),
 (0.8096168637275696, &quot;cryptocurrency&#39;s&quot;),
 (0.8051686882972717, &#39;crypto&#39;),
 (0.8023344278335571, &quot;bitcoin&#39;s&quot;),
 (0.7836618423461914, &#39;altcoin&#39;)]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>Even if the word is misspell, the fasttext model can also get the correct embedding.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">wv_fasttext_cbow<span class="token punctuation">.</span>get_nearest_neighbors<span class="token punctuation">(</span><span class="token string">'bittcoin'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<hr>
<pre class="line-numbers language-console" data-language="console"><code class="language-console">[(0.8647432923316956, &#39;tcoin&#39;),
 (0.8488795161247253, &#39;bitcoin&#39;),
 (0.8280304074287415, &#39;altcoin&#39;),
 (0.8253008127212524, &#39;virtcoin&#39;),
 (0.7866906523704529, &#39;basecoin&#39;),
 (0.7821307182312012, &#39;gatecoin&#39;),
 (0.7780086994171143, &#39;litecoin&#39;),
 (0.7758980989456177, &#39;estcoin&#39;),
 (0.7743834853172302, &#39;cryptocurrency&#39;),
 (0.7679258584976196, &#39;filecoin&#39;)]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>To sum up, FastText utilises subword information, while Word2Vec and GloVe don’t. The result does not make much sense when we take uncommon word like ‘weltschmerz’, most of these words are unrelated or not in the vocabulary. On the other hand, using subword information captures different variation around the word.</p>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>You can now perform various syntactic&#x2F;semantic NLP word tasks with the trained vectors! Cheers!</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        Author:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Yang-Tech-Blog/about" rel="external nofollow noreferrer">Yang Wang</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        Link:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://penguinwang96825.github.io/Yang-Tech-Blog/Yang-Tech-Blog/2021/03/02/2021-03-02-train-word-embedding-vectos-on-custom-corpus/">https://penguinwang96825.github.io/Yang-Tech-Blog/Yang-Tech-Blog/2021/03/02/2021-03-02-train-word-embedding-vectos-on-custom-corpus/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        Reprint policy:
                    </i>
                </span>
                <span class="reprint-info">
                    All articles in this blog are used except for special statements
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    reprint polocy. If reproduced, please indicate source
                    <a href="/Yang-Tech-Blog/about" target="_blank">Yang Wang</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>Copied successfully, please follow the reprint policy of this article</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">more</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Yang-Tech-Blog/tags/NLP/">
                                    <span class="chip bg-color">NLP</span>
                                </a>
                            
                                <a href="/Yang-Tech-Blog/tags/WSL/">
                                    <span class="chip bg-color">WSL</span>
                                </a>
                            
                                <a href="/Yang-Tech-Blog/tags/Ubuntu/">
                                    <span class="chip bg-color">Ubuntu</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Yang-Tech-Blog/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>WeChat swipe to share！</p>"></div>
    <script src="/Yang-Tech-Blog/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    
        <div class="disqus-card card" data-aos="fade-up">
    <div id="disqus_thread" class="card-content">
        <noscript>Please enable JavaScript to view the
            <a target="_blank" rel="noopener" href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
    </div>
</div>

<script type="text/javascript">
    disqus_config = function () {
        this.page.url = 'https://penguinwang96825.github.io/Yang-Tech-Blog/2021/03/02/2021-03-02-train-word-embedding-vectos-on-custom-corpus/';
        this.page.identifier = '/Yang-Tech-Blog/2021/03/02/2021-03-02-train-word-embedding-vectos-on-custom-corpus/';
        this.page.title = 'Train Word Embedding Vectors on Custom Corpus';
    };
    let disqus_shortname = 'penguinwang';

    (function () { // DON'T EDIT BELOW THIS LINE
        let d = document, s = d.createElement('script');
        // 如：s.src = 'https://blinkfox.disqus.com/embed.js';
        s.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;Previous</div>
            <div class="card">
                <a href="/Yang-Tech-Blog/2021/03/12/2021-03-12-easiest-explanation-for-p-value/">
                    <div class="card-image">
                        
                        <img src="https://github.com/penguinwang96825/penguinwang96825.github.io/blob/master/2021/03/12/2021-03-12-easiest-explanation-for-p-value/stephen-dawson.jpg?raw=true" class="responsive-img" alt="P-Value Easy Explanation">
                        
                        <span class="card-title">P-Value Easy Explanation</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            In Data Science interviews, one of the frequently asked questions is 'What is P-Value?'. It's hard to grasp the concept behind p-value. To understand p-value, you need to understand some background and context behind it.
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2021-03-12
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Yang-Tech-Blog/categories/Statistics/" class="post-category">
                                    Statistics
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Yang-Tech-Blog/tags/Python/">
                        <span class="chip bg-color">Python</span>
                    </a>
                    
                    <a href="/Yang-Tech-Blog/tags/Statistics/">
                        <span class="chip bg-color">Statistics</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                Next&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Yang-Tech-Blog/2021/02/07/2021-02-07-twitter-hate-speech-detection/">
                    <div class="card-image">
                        
                        <img src="https://github.com/penguinwang96825/penguinwang96825.github.io/blob/master/2021/02/07/2021-02-07-twitter-hate-speech-detection/alexander-shatov.jpg?raw=true" class="responsive-img" alt="Twitter Hate Speech Detection">
                        
                        <span class="card-title">Twitter Hate Speech Detection</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            The objective of this task is to detect hate speech in tweets. For the sake of simplicity, let's say a tweet contains hate speech if it has a racist or sexist sentiment associated with it. So, the task is to classify racist or sexist tweets from other tweets.
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2021-02-07
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/Yang-Tech-Blog/categories/NLP/" class="post-category">
                                    NLP
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Yang-Tech-Blog/tags/Python/">
                        <span class="chip bg-color">Python</span>
                    </a>
                    
                    <a href="/Yang-Tech-Blog/tags/PyTorch/">
                        <span class="chip bg-color">PyTorch</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Yang-Tech-Blog/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/Yang-Tech-Blog/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Yang-Tech-Blog/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Yang-Tech-Blog/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;TOC</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Yang-Tech-Blog/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h1, h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

    <!-- footer -->
    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Yang-Tech-Blog/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='true'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.3'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/Yang-Tech-Blog/libs/aplayer/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

    
    <div class="container row center-align" style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2018-2022</span>
            
            <span id="year">2018</span>
            <a href="/Yang-Tech-Blog/about" target="_blank">Yang Wang</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;Total site word count:&nbsp;<span
                class="white-color">116.2k</span>&nbsp;words
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;Total number of visits:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;times
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;Total number of visitors:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;people
            </span>
            
            <br>
            
            <span id="sitetime">Loading runtime...</span>
            <script>
                function siteTime() {
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2018";
                    var startMonth = "12";
                    var startDate = "3";
                    var startHour = "0";
                    var startMinute = "0";
                    var startSecond = "0";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "This site has been safely operated " + diffDays + " days " + diffHours +
                            " hours " + diffMinutes + " minutes " + diffSeconds + " seconds";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "This site has been safely operated " + diffYears + " years " + diffDays +
                            " days " + diffHours + " hours " + diffMinutes + " minutes " + diffSeconds + " seconds";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/penguinwang96825" class="tooltipped" target="_blank" data-tooltip="Visit my GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:penguinwang@smail.nchu.edu.tw" class="tooltipped" target="_blank" data-tooltip="Contact me by mail" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>













</div>
    </div>
</footer>

<div class="progress-bar"></div>

    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;Search</span>
            <input type="search" id="searchInput" name="s" placeholder="Please enter a search keyword"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/Yang-Tech-Blog/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Yang-Tech-Blog/libs/materialize/materialize.min.js"></script>
    <script src="/Yang-Tech-Blog/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Yang-Tech-Blog/libs/aos/aos.js"></script>
    <script src="/Yang-Tech-Blog/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Yang-Tech-Blog/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Yang-Tech-Blog/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Yang-Tech-Blog/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Yang-Tech-Blog/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

	
    

    

    
    <script type="text/javascript" src="/Yang-Tech-Blog/libs/background/ribbon-dynamic.js" async="async"></script>
    

    
    <script src="/Yang-Tech-Blog/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

<script>
    pseudocode.renderElement(document.getElementById("pseudocode"));
</script>

</html>
