<!DOCTYPE HTML>
<html lang="en">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Weighted Word Embedding, Yang&#39;s Blog">
    <meta name="description" content="CS Student / NLP Enthusiast / Tireless Coder">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Weighted Word Embedding | Yang&#39;s Blog</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 5.4.0"></head>




<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Yang&#39;s Blog</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>Index</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>Tags</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>Categories</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>Archives</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>About</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>Contact</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>Friends</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="Search" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Yang&#39;s Blog</div>
        <div class="logo-desc">
            
            CS Student / NLP Enthusiast / Tireless Coder
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			Index
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			Tags
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			Categories
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			Archives
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			About
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			Contact
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			Friends
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/penguinwang96825" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/penguinwang96825" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://github.com/penguinwang96825/penguinwang96825.github.io/blob/master/2021/01/25/2021-01-25-weighted-word-embedding/falloxbow-1058032.jpg?raw=true')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Weighted Word Embedding</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/Python/">
                                <span class="chip bg-color">Python</span>
                            </a>
                        
                            <a href="/tags/NLP/">
                                <span class="chip bg-color">NLP</span>
                            </a>
                        
                            <a href="/tags/Embedding/">
                                <span class="chip bg-color">Embedding</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/Speech-NLP/" class="post-category">
                                Speech NLP
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>Publish Date:&nbsp;&nbsp;
                    2021-01-25
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>Word Count:&nbsp;&nbsp;
                    2.3k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>Read Times:&nbsp;&nbsp;
                    14 Min
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>Read Count:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <p>We just had a long Christmas vacation. It’s time to get back to study mode! Today I’m going to summarise some important point about weighted word embedding for some specific NLP tasks. Frankly speaking, this is the topic I wish to write about a few months ago, however, I was so busy during my MSc.</p>
<h1 id="Load-the-Dataset"><a href="#Load-the-Dataset" class="headerlink" title="Load the Dataset"></a>Load the Dataset</h1><p>First things first, download IMDb dataset from HuggingFace’s <a target="_blank" rel="noopener" href="https://github.com/huggingface/datasets">Datasets</a> library: </p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"imdb"</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">dataset_to_dataframe</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    X_train<span class="token punctuation">,</span> y_train <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dataset<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span>
    X_test<span class="token punctuation">,</span> y_test <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dataset<span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"label"</span><span class="token punctuation">]</span>
    
    df_train <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">&#123;</span>
        <span class="token string">"text"</span><span class="token punctuation">:</span> X_train<span class="token punctuation">,</span> 
        <span class="token string">"label"</span><span class="token punctuation">:</span> y_train<span class="token punctuation">,</span> 
        <span class="token string">"tag"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token operator">*</span><span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
    
    df_test <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">&#123;</span>
        <span class="token string">"text"</span><span class="token punctuation">:</span> X_test<span class="token punctuation">,</span> 
        <span class="token string">"label"</span><span class="token punctuation">:</span> y_test<span class="token punctuation">,</span> 
        <span class="token string">"tag"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span><span class="token operator">*</span><span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token punctuation">&#125;</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> df_train<span class="token punctuation">,</span> df_test<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>I tranformed the format into <code>pd.DataFrame</code> format.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">"imdb"</span><span class="token punctuation">)</span>
df_train<span class="token punctuation">,</span> df_test <span class="token operator">=</span> dataset_to_dataframe<span class="token punctuation">(</span>dataset<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Shape of training data: &#123;&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>df_train<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Shape of tesing data: &#123;&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>df_test<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<p>There are 25000 samples for each training data and testing data.</p>
<h1 id="Tokenisation"><a href="#Tokenisation" class="headerlink" title="Tokenisation"></a>Tokenisation</h1><p>To tackle text related problem in NLP and ML area, tokenisation is one of the common pre-processing. There are various types of text processing techniques, such as lowercasing, stemming words, lemmetising words, and so on. In this article, I only went through handling work with tokenisation and lowercase.</p>
<p>There are many tools that support segmentation tool by all means, as I have listed below.</p>
<ol>
<li>English Segmentation Tools</li>
</ol>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/nltk/nltk">NLTK</a></li>
<li><a target="_blank" rel="noopener" href="https://spacy.io/api/tokenizer">spaCy</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/google/sentencepiece">SentencePiece</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/stanfordnlp/CoreNLP">Stanford CoreNLP</a></li>
</ul>
<ol start="2">
<li>Chinese Segmentation Tools</li>
</ol>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/fxsjy/jieba">Jieba</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/isnowfy/snownlp">SnowNLP</a></li>
<li><a target="_blank" rel="noopener" href="https://www.ltp-cloud.com/">LTP</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/hankcs/HanLP">HanNLP</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/lancopku/pkuseg-python">PKUSEG</a></li>
</ul>
<ol start="3">
<li>Japanese Segmentation Tools</li>
</ol>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/ikegami-yukino/mecab/releases">MeCab</a></li>
<li><a target="_blank" rel="noopener" href="https://www.dampfkraft.com/nlp/how-to-tokenize-japanese.html">Fugashi</a></li>
<li><a target="_blank" rel="noopener" href="https://mocobeta.github.io/janome/en/">Janome</a></li>
</ul>
<p> I tokenised the sentence in the simplest way using regex.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">tokenization</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    text <span class="token operator">=</span> re<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\W+'</span><span class="token punctuation">,</span> text<span class="token punctuation">)</span>
    <span class="token keyword">return</span> text

df_train<span class="token punctuation">[</span><span class="token string">"text_tokenised"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df_train<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> tokenization<span class="token punctuation">(</span>x<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
df_test<span class="token punctuation">[</span><span class="token string">"text_tokenised"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df_test<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> tokenization<span class="token punctuation">(</span>x<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h1 id="Word-Embedding-Model"><a href="#Word-Embedding-Model" class="headerlink" title="Word Embedding Model"></a>Word Embedding Model</h1><h2 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h2><p>Proposed by Tomas Mikolov et al. in their <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1309.4168v1.pdf">paper</a>, there are two architectures (CBOW and Skip-gram) of word2vec to learn the underlying word representations for each word by using neural networks. </p>
<p>In the CBOW model, the distributed representations of context (or surrounding words) are combined to predict the word in the middle. </p>
<img src="https://miro.medium.com/max/1050/1*zNtM3sUehDXg4Fpbt60U-w.jpeg" alt="Drawing" style="width: 500px;"/>

<p>While in the Skip-gram model, the distributed representation of the input word is used to predict the context.</p>
<img src="https://miro.medium.com/max/1050/1*evJZHepBAUET1wdk65MB0A.png" alt="Drawing" style="width: 500px;"/>

<h2 id="GloVe"><a href="#GloVe" class="headerlink" title="GloVe"></a>GloVe</h2><p>GloVe is an unsupervised learning algorithm, proposed by Jeffrey Pennington et al., for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space. The <a target="_blank" rel="noopener" href="https://nlp.stanford.edu/pubs/glove.pdf">paper</a> shows that the model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context<br>windows in a large corpus.</p>
<h2 id="FastText"><a href="#FastText" class="headerlink" title="FastText"></a>FastText</h2><p>FastText is capable of building word vectors for words that do not appear in the training set. For such words, the authors simply average the vector representation of its n-grams. This shows that they build robust word representations where prefixes and suffixes can be ignored if the grammatical form is not found in the dictionary.</p>
<p>There are two application of FastText.</p>
<ol>
<li>Using for learning word representations: P. Bojanowski, et al., <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1607.04606.pdf">Enriching Word Vectors with Subword Information</a></li>
<li>Using for text classification: A. Joulin, et al., <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1607.01759.pdf">Bag of Tricks for Efficient Text Classification</a></li>
</ol>
<h1 id="Load-Pre-trained-Model-from-Gensim"><a href="#Load-Pre-trained-Model-from-Gensim" class="headerlink" title="Load Pre-trained Model from Gensim"></a>Load Pre-trained Model from Gensim</h1><ul>
<li>Word2Vec pre-trained vectors <a target="_blank" rel="noopener" href="https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz">download</a><ul>
<li>Unzip the file: <pre class="line-numbers language-none"><code class="language-none">!gunzip .&#x2F;GoogleNews-vectors-negative300.bin.gz<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
</ul>
</li>
<li>GloVe pre-trained vectors <a target="_blank" rel="noopener" href="https://nlp.stanford.edu/projects/glove/">download</a><ul>
<li>Convert file into a gensim word2vec format: <pre class="line-numbers language-none"><code class="language-none">glove2word2vec(glove_input_file&#x3D;r&quot;glove.840B.300d.txt&quot;, word2vec_output_file&#x3D;r&quot;gensim_glove_vectors.txt&quot;)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
</ul>
</li>
<li>FastText pre-trained vectors <a target="_blank" rel="noopener" href="https://fasttext.cc/docs/en/crawl-vectors.html">download</a><ul>
<li>Convert file into a binary format: <pre class="line-numbers language-none"><code class="language-none">embedding_dict &#x3D; KeyedVectors.load_word2vec_format(r&quot;cc.en.300.vec&quot;, binary&#x3D;False)
embedding_dict.save_word2vec_format(MODEL_PATH, binary&#x3D;True)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
</ul>
</li>
</ul>
<p>While loading pre-trained model, you can grab a cup of tea or coffee, cause it will cost some time.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">w2v_model <span class="token operator">=</span> KeyedVectors<span class="token punctuation">.</span>load_word2vec_format<span class="token punctuation">(</span><span class="token string">"GoogleNews-vectors-negative300.bin"</span><span class="token punctuation">,</span> binary<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
glove_model <span class="token operator">=</span> KeyedVectors<span class="token punctuation">.</span>load_word2vec_format<span class="token punctuation">(</span><span class="token string">"gensim_glove_vectors.txt"</span><span class="token punctuation">,</span> binary<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
ft_model <span class="token operator">=</span> KeyedVectors<span class="token punctuation">.</span>load_word2vec_format<span class="token punctuation">(</span><span class="token string">"cc.en.300.bin"</span><span class="token punctuation">,</span> binary<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<h1 id="Weighted-Method"><a href="#Weighted-Method" class="headerlink" title="Weighted Method"></a>Weighted Method</h1><p>The aim of this section is to construct sentence embeddings, obtained from word embeddings. If the sentence $s$ consists of words $w_{1}$, …, $w_{n}$, let’s define an embedding vector $Emb_{s}(s) \in \mathbb{R}^d$ for some $d&gt;0$. We can compute sentence embedding from the embeddings of words $w_{i}$, let’s call them $Emb_{w}(w_{i})$, so that $Emb_{s}(s)$ is a linear combination of $Emb_{w}(w_{i})$ and has the same dimensionality $d$: </p>
<div>
    <span>
        $$Emb_{s}(s)=\sum_{w_{i} \in s}c_i \cdot Emb_{w}(w_i)$$
    </span>
</div>

<p>where $c_i \in \mathbb{R}$ are the coefficients (scalars).</p>
<h2 id="BoW"><a href="#BoW" class="headerlink" title="BoW"></a>BoW</h2><p>Averaging the component word vectors in every documents.</p>
<div>
    <span>
        $$v_{s} = \frac{1}{\lVert S \rVert}\sum_{w \in S}v_{w}$$
    </span>
</div>

<h2 id="TFIDF"><a href="#TFIDF" class="headerlink" title="TFIDF"></a>TFIDF</h2><p>Term frequency–inverse document frequency (TF-IDF) is a popular method to capture the significance of a token to a particular input with respect to all the inputs.</p>
<div>
    <span>
        $$w_{i,j} = tf_{i,j} \cdot log\frac{N}{df_i}$$
    </span>
</div>

<ul>
<li>$w_{i,j}$ is the tf-idf weight for term i in document j</li>
<li>$tf_{i,j}$ is number of time term i appear in document j</li>
<li>$N$ is the total number of documents</li>
<li>$df_i$ is the number of documents with token i</li>
</ul>
<h2 id="SIF"><a href="#SIF" class="headerlink" title="SIF"></a>SIF</h2><p>Instead of just averaging the component word vectors as suggested by this equation for BoW, SIF generate the sentence vector $v_s$ by multiplying each component vector $v_w$ by the inverse of its probability of occurrence. Here α is a smoothing constant, its default value as suggested in the paper is 0.001. We then sum these normalized smoothed word vectors and divide by the number of words.</p>
<div>
    <span>
        $$v_{s}=\frac{1}{\lVert S \rVert}\sum_{w \in S}\frac{\alpha}{\alpha + p_w}v_{w}$$
    </span>
</div>

<h1 id="Talk-is-Cheap-Show-me-the-Code"><a href="#Talk-is-Cheap-Show-me-the-Code" class="headerlink" title="Talk is Cheap, Show me the Code"></a>Talk is Cheap, Show me the Code</h1><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">EmbeddingVectorizer</span><span class="token punctuation">(</span>BaseEstimator<span class="token punctuation">,</span> TransformerMixin<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span>
    
    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self
    
    <span class="token keyword">def</span> <span class="token function">transform</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> X
    
    <span class="token keyword">def</span> <span class="token function">fit_transform</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
        
    <span class="token keyword">def</span> <span class="token function">progressbar</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> iteration<span class="token punctuation">,</span> prefix<span class="token operator">=</span><span class="token string">""</span><span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token builtin">file</span><span class="token operator">=</span>sys<span class="token punctuation">.</span>stdout<span class="token punctuation">)</span><span class="token punctuation">:</span>
        count <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>iteration<span class="token punctuation">)</span>
        <span class="token keyword">def</span> <span class="token function">show</span><span class="token punctuation">(</span>t<span class="token punctuation">)</span><span class="token punctuation">:</span>
            x <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>size<span class="token operator">*</span>t<span class="token operator">/</span>count<span class="token punctuation">)</span>
            <span class="token comment"># file.write("%s[%s%s] %i/%i\r" % (prefix, "#"*x, "."*(size-x), int(100*t/count), 100))</span>
            <span class="token builtin">file</span><span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"&#123;&#125;[&#123;&#125;&#123;&#125;] &#123;&#125;%\r"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>prefix<span class="token punctuation">,</span> <span class="token string">"█"</span><span class="token operator">*</span>x<span class="token punctuation">,</span> <span class="token string">"."</span><span class="token operator">*</span><span class="token punctuation">(</span>size<span class="token operator">-</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token operator">*</span>t<span class="token operator">/</span>count<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token builtin">file</span><span class="token punctuation">.</span>flush<span class="token punctuation">(</span><span class="token punctuation">)</span>
        show<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> item <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>iteration<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">yield</span> item
            show<span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token builtin">file</span><span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">)</span>
        <span class="token builtin">file</span><span class="token punctuation">.</span>flush<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">MeanEmbeddingVectorizer</span><span class="token punctuation">(</span>EmbeddingVectorizer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> word2vec<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>word2vec <span class="token operator">=</span> word2vec
        self<span class="token punctuation">.</span>dim <span class="token operator">=</span> word2vec<span class="token punctuation">.</span>vector_size

    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self

    <span class="token keyword">def</span> <span class="token function">transform</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>
            np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>word2vec<span class="token punctuation">[</span>w<span class="token punctuation">]</span> <span class="token keyword">for</span> w <span class="token keyword">in</span> words <span class="token keyword">if</span> w <span class="token keyword">in</span> self<span class="token punctuation">.</span>word2vec<span class="token punctuation">]</span>
                    <span class="token keyword">or</span> <span class="token punctuation">[</span>np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dim<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> words <span class="token keyword">in</span> self<span class="token punctuation">.</span>progressbar<span class="token punctuation">(</span>X<span class="token punctuation">,</span> prefix<span class="token operator">=</span><span class="token string">"Mean"</span><span class="token punctuation">)</span>
        <span class="token punctuation">]</span><span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">fit_transform</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">get_params</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> deep<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">&#123;</span><span class="token string">"word2vec"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>word2vec<span class="token punctuation">&#125;</span>

    <span class="token keyword">def</span> <span class="token function">set_params</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">**</span>parameters<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> parameter<span class="token punctuation">,</span> value <span class="token keyword">in</span> parameters<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token builtin">setattr</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> parameter<span class="token punctuation">,</span> value<span class="token punctuation">)</span>
        <span class="token keyword">return</span> self
    
<span class="token keyword">class</span> <span class="token class-name">TfidfEmbeddingVectorizer</span><span class="token punctuation">(</span>EmbeddingVectorizer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> word2vec<span class="token punctuation">,</span> use_idf<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>word2vec <span class="token operator">=</span> word2vec
        self<span class="token punctuation">.</span>word2weight <span class="token operator">=</span> <span class="token boolean">None</span>
        self<span class="token punctuation">.</span>use_idf <span class="token operator">=</span> use_idf
        self<span class="token punctuation">.</span>dim <span class="token operator">=</span> word2vec<span class="token punctuation">.</span>vector_size
        
    <span class="token keyword">def</span> <span class="token function">word2tf</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> term_list<span class="token punctuation">)</span><span class="token punctuation">:</span>
        term_freq <span class="token operator">=</span> Counter<span class="token punctuation">(</span>term_list<span class="token punctuation">)</span>
        total_len <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>term_freq<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        term_freq <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>term<span class="token punctuation">,</span> term_freq<span class="token punctuation">[</span>term<span class="token punctuation">]</span><span class="token operator">/</span>total_len<span class="token punctuation">)</span> <span class="token keyword">for</span> term<span class="token punctuation">,</span> count <span class="token keyword">in</span> term_freq<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token keyword">return</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>term_freq<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
        tfidf <span class="token operator">=</span> TfidfVectorizer<span class="token punctuation">(</span>analyzer<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">)</span>
        tfidf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
        max_idf <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>tfidf<span class="token punctuation">.</span>idf_<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>word2weight <span class="token operator">=</span> defaultdict<span class="token punctuation">(</span>
            <span class="token keyword">lambda</span><span class="token punctuation">:</span> max_idf<span class="token punctuation">,</span>
            <span class="token punctuation">[</span><span class="token punctuation">(</span>w<span class="token punctuation">,</span> tfidf<span class="token punctuation">.</span>idf_<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> w<span class="token punctuation">,</span> i <span class="token keyword">in</span> tfidf<span class="token punctuation">.</span>vocabulary_<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> self

    <span class="token keyword">def</span> <span class="token function">transform</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>
        transformed_X <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> doc <span class="token keyword">in</span> self<span class="token punctuation">.</span>progressbar<span class="token punctuation">(</span>X<span class="token punctuation">,</span> prefix<span class="token operator">=</span><span class="token string">"TF-IDF"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            weighted_array <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            <span class="token keyword">for</span> term <span class="token keyword">in</span> doc<span class="token punctuation">:</span>
                <span class="token keyword">if</span> term <span class="token keyword">in</span> self<span class="token punctuation">.</span>word2vec<span class="token punctuation">:</span>
                    <span class="token keyword">if</span> self<span class="token punctuation">.</span>use_idf<span class="token punctuation">:</span>
                        weighted_term <span class="token operator">=</span> self<span class="token punctuation">.</span>word2vec<span class="token punctuation">[</span>term<span class="token punctuation">]</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>word2tf<span class="token punctuation">(</span>doc<span class="token punctuation">)</span><span class="token punctuation">[</span>term<span class="token punctuation">]</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>word2weight<span class="token punctuation">[</span>term<span class="token punctuation">]</span>
                    <span class="token keyword">else</span><span class="token punctuation">:</span>
                        weighted_term <span class="token operator">=</span> self<span class="token punctuation">.</span>word2vec<span class="token punctuation">[</span>term<span class="token punctuation">]</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>word2tf<span class="token punctuation">(</span>doc<span class="token punctuation">)</span><span class="token punctuation">[</span>term<span class="token punctuation">]</span>
                    weighted_array<span class="token punctuation">.</span>append<span class="token punctuation">(</span>weighted_term<span class="token punctuation">)</span>
            weighted_array <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>weighted_array <span class="token keyword">or</span> <span class="token punctuation">[</span>np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dim<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
            transformed_X<span class="token punctuation">.</span>append<span class="token punctuation">(</span>weighted_array<span class="token punctuation">)</span>
        <span class="token keyword">return</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>transformed_X<span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">fit_transform</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">get_params</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> deep<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">&#123;</span><span class="token string">"word2vec"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>word2vec<span class="token punctuation">,</span> <span class="token string">"use_idf"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>use_idf<span class="token punctuation">&#125;</span>

    <span class="token keyword">def</span> <span class="token function">set_params</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">**</span>parameters<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> parameter<span class="token punctuation">,</span> value <span class="token keyword">in</span> parameters<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token builtin">setattr</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> parameter<span class="token punctuation">,</span> value<span class="token punctuation">)</span>
        <span class="token keyword">return</span> self
    
<span class="token keyword">class</span> <span class="token class-name">SifEmbeddingVectorizer</span><span class="token punctuation">(</span>EmbeddingVectorizer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> word2vec<span class="token punctuation">,</span> smoothing_constant<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>word2vec <span class="token operator">=</span> word2vec
        self<span class="token punctuation">.</span>word2weight <span class="token operator">=</span> <span class="token boolean">None</span>
        self<span class="token punctuation">.</span>dim <span class="token operator">=</span> word2vec<span class="token punctuation">.</span>vector_size
        self<span class="token punctuation">.</span>smoothing_constant <span class="token operator">=</span> smoothing_constant
        
    <span class="token keyword">def</span> <span class="token function">word2tf</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> term_list<span class="token punctuation">)</span><span class="token punctuation">:</span>
        term_freq <span class="token operator">=</span> Counter<span class="token punctuation">(</span>term_list<span class="token punctuation">)</span>
        total_len <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>term_freq<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        term_freq <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>term<span class="token punctuation">,</span> term_freq<span class="token punctuation">[</span>term<span class="token punctuation">]</span><span class="token operator">/</span>total_len<span class="token punctuation">)</span> <span class="token keyword">for</span> term<span class="token punctuation">,</span> count <span class="token keyword">in</span> term_freq<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token keyword">return</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>term_freq<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self

    <span class="token keyword">def</span> <span class="token function">transform</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>
        transformed_X <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> doc <span class="token keyword">in</span> self<span class="token punctuation">.</span>progressbar<span class="token punctuation">(</span>X<span class="token punctuation">,</span> prefix<span class="token operator">=</span><span class="token string">"SIF"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            weighted_array <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            <span class="token keyword">for</span> term <span class="token keyword">in</span> doc<span class="token punctuation">:</span>
                <span class="token keyword">if</span> term <span class="token keyword">in</span> self<span class="token punctuation">.</span>word2vec<span class="token punctuation">:</span>
                    <span class="token comment"># Compute smooth inverse frequency (SIF)</span>
                    weight <span class="token operator">=</span> self<span class="token punctuation">.</span>smoothing_constant <span class="token operator">/</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>smoothing_constant <span class="token operator">+</span> self<span class="token punctuation">.</span>word2tf<span class="token punctuation">(</span>doc<span class="token punctuation">)</span><span class="token punctuation">[</span>term<span class="token punctuation">]</span><span class="token punctuation">)</span>
                    weighted_term <span class="token operator">=</span> self<span class="token punctuation">.</span>word2vec<span class="token punctuation">[</span>term<span class="token punctuation">]</span> <span class="token operator">*</span> weight
                    weighted_array<span class="token punctuation">.</span>append<span class="token punctuation">(</span>weighted_term<span class="token punctuation">)</span>
            weighted_array <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>weighted_array <span class="token keyword">or</span> <span class="token punctuation">[</span>np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dim<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
            transformed_X<span class="token punctuation">.</span>append<span class="token punctuation">(</span>weighted_array<span class="token punctuation">)</span>
        transformed_X <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>transformed_X<span class="token punctuation">)</span>
            
        <span class="token comment"># Common component removal: remove the projections of the average vectors on their first singular vector</span>
        svd <span class="token operator">=</span> TruncatedSVD<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> n_iter<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        svd<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>transformed_X<span class="token punctuation">)</span>
        pc <span class="token operator">=</span> svd<span class="token punctuation">.</span>components_
        transformed_X <span class="token operator">=</span> transformed_X <span class="token operator">-</span> transformed_X<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>pc<span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token punctuation">.</span>dot<span class="token punctuation">(</span>pc<span class="token punctuation">)</span>
        <span class="token keyword">return</span> transformed_X
    
    <span class="token keyword">def</span> <span class="token function">fit_transform</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    
    <span class="token keyword">def</span> <span class="token function">get_params</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> deep<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">&#123;</span><span class="token string">"word2vec"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>word2vec<span class="token punctuation">,</span> <span class="token string">"smoothing_constant"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>smoothing_constant<span class="token punctuation">&#125;</span>

    <span class="token keyword">def</span> <span class="token function">set_params</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">**</span>parameters<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> parameter<span class="token punctuation">,</span> value <span class="token keyword">in</span> parameters<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token builtin">setattr</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> parameter<span class="token punctuation">,</span> value<span class="token punctuation">)</span>
        <span class="token keyword">return</span> self<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>After constructing all needed class for weighted word embedding, next step is to see which combination of the embedding method performs the best.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Word2Vec</span>
vectoriser_w2v_mean <span class="token operator">=</span> MeanEmbeddingVectorizer<span class="token punctuation">(</span>word2vec<span class="token operator">=</span>w2v_model<span class="token punctuation">)</span>
feature_train_w2v_mean <span class="token operator">=</span> vectoriser_w2v_mean<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>df_train<span class="token punctuation">[</span><span class="token string">"text_tokenised"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>
vectoriser_w2v_tfidf <span class="token operator">=</span> TfidfEmbeddingVectorizer<span class="token punctuation">(</span>word2vec<span class="token operator">=</span>w2v_model<span class="token punctuation">)</span>
feature_train_w2v_tfidf <span class="token operator">=</span> vectoriser_w2v_tfidf<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>df_train<span class="token punctuation">[</span><span class="token string">"text_tokenised"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>
vectoriser_w2v_sif <span class="token operator">=</span> SifEmbeddingVectorizer<span class="token punctuation">(</span>word2vec<span class="token operator">=</span>w2v_model<span class="token punctuation">)</span>
feature_train_w2v_sif <span class="token operator">=</span> vectoriser_w2v_sif<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>df_train<span class="token punctuation">[</span><span class="token string">"text_tokenised"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># GloVe</span>
vectoriser_glove_mean <span class="token operator">=</span> MeanEmbeddingVectorizer<span class="token punctuation">(</span>word2vec<span class="token operator">=</span>glove_model<span class="token punctuation">)</span>
feature_train_glove_mean <span class="token operator">=</span> vectoriser_glove_mean<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>df_train<span class="token punctuation">[</span><span class="token string">"text_tokenised"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>
vectoriser_glove_tfidf <span class="token operator">=</span> TfidfEmbeddingVectorizer<span class="token punctuation">(</span>word2vec<span class="token operator">=</span>glove_model<span class="token punctuation">)</span>
feature_train_glove_tfidf <span class="token operator">=</span> vectoriser_glove_tfidf<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>df_train<span class="token punctuation">[</span><span class="token string">"text_tokenised"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>
vectoriser_glove_sif <span class="token operator">=</span> SifEmbeddingVectorizer<span class="token punctuation">(</span>word2vec<span class="token operator">=</span>glove_model<span class="token punctuation">)</span>
feature_train_glove_sif <span class="token operator">=</span> vectoriser_glove_sif<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>df_train<span class="token punctuation">[</span><span class="token string">"text_tokenised"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># FastText</span>
vectoriser_ft_mean <span class="token operator">=</span> MeanEmbeddingVectorizer<span class="token punctuation">(</span>word2vec<span class="token operator">=</span>ft_model<span class="token punctuation">)</span>
feature_train_ft_mean <span class="token operator">=</span> vectoriser_ft_mean<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>df_train<span class="token punctuation">[</span><span class="token string">"text_tokenised"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>
vectoriser_ft_tfidf <span class="token operator">=</span> TfidfEmbeddingVectorizer<span class="token punctuation">(</span>word2vec<span class="token operator">=</span>ft_model<span class="token punctuation">)</span>
feature_train_ft_tfidf <span class="token operator">=</span> vectoriser_ft_tfidf<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>df_train<span class="token punctuation">[</span><span class="token string">"text_tokenised"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>
vectoriser_ft_sif <span class="token operator">=</span> SifEmbeddingVectorizer<span class="token punctuation">(</span>word2vec<span class="token operator">=</span>ft_model<span class="token punctuation">)</span>
feature_train_ft_sif <span class="token operator">=</span> vectoriser_ft_sif<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>df_train<span class="token punctuation">[</span><span class="token string">"text_tokenised"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>I stored these into dictionaries.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">vectorisers <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token string">"word2vec"</span><span class="token punctuation">:</span> <span class="token punctuation">&#123;</span>
        <span class="token string">"mean"</span><span class="token punctuation">:</span> vectoriser_w2v_mean<span class="token punctuation">,</span> 
        <span class="token string">"tfidf"</span><span class="token punctuation">:</span> vectoriser_w2v_tfidf<span class="token punctuation">,</span> 
        <span class="token string">"sif"</span><span class="token punctuation">:</span> vectoriser_w2v_sif
    <span class="token punctuation">&#125;</span><span class="token punctuation">,</span> 
    <span class="token string">"glove"</span><span class="token punctuation">:</span> <span class="token punctuation">&#123;</span>
        <span class="token string">"mean"</span><span class="token punctuation">:</span> vectoriser_glove_mean<span class="token punctuation">,</span> 
        <span class="token string">"tfidf"</span><span class="token punctuation">:</span> vectoriser_glove_tfidf<span class="token punctuation">,</span> 
        <span class="token string">"sif"</span><span class="token punctuation">:</span> vectoriser_glove_sif
    <span class="token punctuation">&#125;</span><span class="token punctuation">,</span> 
    <span class="token string">"fasttext"</span><span class="token punctuation">:</span> <span class="token punctuation">&#123;</span>
        <span class="token string">"mean"</span><span class="token punctuation">:</span> vectoriser_ft_mean<span class="token punctuation">,</span> 
        <span class="token string">"tfidf"</span><span class="token punctuation">:</span> vectoriser_ft_tfidf<span class="token punctuation">,</span> 
        <span class="token string">"sif"</span><span class="token punctuation">:</span> vectoriser_ft_sif
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span>
features <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token string">"word2vec"</span><span class="token punctuation">:</span> <span class="token punctuation">&#123;</span>
        <span class="token string">"mean"</span><span class="token punctuation">:</span> feature_train_w2v_mean<span class="token punctuation">,</span> 
        <span class="token string">"tfidf"</span><span class="token punctuation">:</span> feature_train_w2v_tfidf<span class="token punctuation">,</span> 
        <span class="token string">"sif"</span><span class="token punctuation">:</span> feature_train_w2v_sif
    <span class="token punctuation">&#125;</span><span class="token punctuation">,</span> 
    <span class="token string">"glove"</span><span class="token punctuation">:</span> <span class="token punctuation">&#123;</span>
        <span class="token string">"mean"</span><span class="token punctuation">:</span> feature_train_glove_mean<span class="token punctuation">,</span> 
        <span class="token string">"tfidf"</span><span class="token punctuation">:</span> feature_train_glove_tfidf<span class="token punctuation">,</span> 
        <span class="token string">"sif"</span><span class="token punctuation">:</span> feature_train_glove_sif
    <span class="token punctuation">&#125;</span><span class="token punctuation">,</span> 
    <span class="token string">"fasttext"</span><span class="token punctuation">:</span> <span class="token punctuation">&#123;</span>
        <span class="token string">"mean"</span><span class="token punctuation">:</span> feature_train_ft_mean<span class="token punctuation">,</span> 
        <span class="token string">"tfidf"</span><span class="token punctuation">:</span> feature_train_ft_tfidf<span class="token punctuation">,</span> 
        <span class="token string">"sif"</span><span class="token punctuation">:</span> feature_train_ft_sif
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h1 id="Build-Models"><a href="#Build-Models" class="headerlink" title="Build Models"></a>Build Models</h1><p>Finally, we could test it with machine learning model! </p>
<p>Define a cross validation function <code>cross_val()</code> to prevent models from overfitting.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">cross_val</span><span class="token punctuation">(</span>Xtrain<span class="token punctuation">,</span> ytrain<span class="token punctuation">,</span> clf<span class="token punctuation">,</span> cv<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    best_clf <span class="token operator">=</span> <span class="token boolean">None</span>
    best_score <span class="token operator">=</span> <span class="token number">0.0</span>
    num_folds <span class="token operator">=</span> <span class="token number">0</span>
    cv_scores <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    kfold <span class="token operator">=</span> KFold<span class="token punctuation">(</span>n_splits<span class="token operator">=</span>cv<span class="token punctuation">)</span>
    <span class="token keyword">for</span> train<span class="token punctuation">,</span> val <span class="token keyword">in</span> kfold<span class="token punctuation">.</span>split<span class="token punctuation">(</span>Xtrain<span class="token punctuation">)</span><span class="token punctuation">:</span>
        Xctrain<span class="token punctuation">,</span> Xctest<span class="token punctuation">,</span> yctrain<span class="token punctuation">,</span> yctest <span class="token operator">=</span> Xtrain<span class="token punctuation">[</span>train<span class="token punctuation">]</span><span class="token punctuation">,</span> Xtrain<span class="token punctuation">[</span>val<span class="token punctuation">]</span><span class="token punctuation">,</span> ytrain<span class="token punctuation">[</span>train<span class="token punctuation">]</span><span class="token punctuation">,</span> ytrain<span class="token punctuation">[</span>val<span class="token punctuation">]</span>
        clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>Xctrain<span class="token punctuation">,</span> yctrain<span class="token punctuation">)</span>
        score <span class="token operator">=</span> clf<span class="token punctuation">.</span>score<span class="token punctuation">(</span>Xctest<span class="token punctuation">,</span> yctest<span class="token punctuation">)</span>
        <span class="token keyword">if</span> score <span class="token operator">></span> best_score<span class="token punctuation">:</span>
            best_score <span class="token operator">=</span> score
            best_clf <span class="token operator">=</span> clf
        <span class="token keyword">if</span> verbose<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Fold &#123;:d&#125;: score: &#123;:.4f&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>num_folds<span class="token punctuation">,</span> score<span class="token punctuation">)</span><span class="token punctuation">)</span>
        cv_scores<span class="token punctuation">.</span>append<span class="token punctuation">(</span>score<span class="token punctuation">)</span>
        num_folds <span class="token operator">+=</span> <span class="token number">1</span>
    <span class="token keyword">return</span> best_clf<span class="token punctuation">,</span> cv_scores

<span class="token keyword">def</span> <span class="token function">test_eval</span><span class="token punctuation">(</span>Xtest<span class="token punctuation">,</span> ytest<span class="token punctuation">,</span> clf<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Test set results"</span><span class="token punctuation">)</span>
    ytest_ <span class="token operator">=</span> clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>Xtest<span class="token punctuation">)</span>
    accuracy <span class="token operator">=</span> accuracy_score<span class="token punctuation">(</span>ytest<span class="token punctuation">,</span> ytest_<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Accuracy: &#123;:.4f&#125;"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>accuracy<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>Let the training begin!</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">results <span class="token operator">=</span> defaultdict<span class="token punctuation">(</span><span class="token builtin">dict</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> embedding <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">"word2vec"</span><span class="token punctuation">,</span> <span class="token string">"glove"</span><span class="token punctuation">,</span> <span class="token string">"fasttext"</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> weighting <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">"mean"</span><span class="token punctuation">,</span> <span class="token string">"tfidf"</span><span class="token punctuation">,</span> <span class="token string">"sif"</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Training with </span><span class="token interpolation"><span class="token punctuation">&#123;</span>embedding<span class="token punctuation">&#125;</span></span><span class="token string">-</span><span class="token interpolation"><span class="token punctuation">&#123;</span>weighting<span class="token punctuation">&#125;</span></span><span class="token string"> model..."</span></span><span class="token punctuation">)</span>
        clf <span class="token operator">=</span> xgboost<span class="token punctuation">.</span>XGBClassifier<span class="token punctuation">(</span>n_estimators<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">,</span> max_depth<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
        clf<span class="token punctuation">,</span> cv_scores <span class="token operator">=</span> cross_val<span class="token punctuation">(</span>features<span class="token punctuation">[</span>embedding<span class="token punctuation">]</span><span class="token punctuation">[</span>weighting<span class="token punctuation">]</span><span class="token punctuation">,</span> df_train<span class="token punctuation">.</span>label<span class="token punctuation">.</span>values<span class="token punctuation">,</span> clf<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        results<span class="token punctuation">[</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>embedding<span class="token punctuation">&#125;</span></span><span class="token string">-</span><span class="token interpolation"><span class="token punctuation">&#123;</span>weighting<span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"classifer"</span><span class="token punctuation">]</span> <span class="token operator">=</span> clf
        results<span class="token punctuation">[</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>embedding<span class="token punctuation">&#125;</span></span><span class="token string">-</span><span class="token interpolation"><span class="token punctuation">&#123;</span>weighting<span class="token punctuation">&#125;</span></span><span class="token string">"</span></span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"cv_result"</span><span class="token punctuation">]</span> <span class="token operator">=</span> cv_scores
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Done with training model!"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>You can also play around with putting these customised functions in Scikit-Learn pipeline. We have seen that some estimators can transform data and that some estimators can predict variables. We can also create combined estimators like the following:</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">pca <span class="token operator">=</span> PCA<span class="token punctuation">(</span><span class="token punctuation">)</span>
logistic <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span>max_iter<span class="token operator">=</span><span class="token number">10000</span><span class="token punctuation">,</span> tol<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>
pipe <span class="token operator">=</span> Pipeline<span class="token punctuation">(</span>steps<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">"word2vec vectorizer (tfidf)"</span><span class="token punctuation">,</span> TfidfEmbeddingVectorizer<span class="token punctuation">(</span>w2v_model<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
                       <span class="token punctuation">(</span><span class="token string">'pca'</span><span class="token punctuation">,</span> pca<span class="token punctuation">)</span><span class="token punctuation">,</span> 
                       <span class="token punctuation">(</span><span class="token string">'logistic'</span><span class="token punctuation">,</span> logistic<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment"># Parameters of pipelines can be set using ‘__’ separated parameter names:</span>
param_grid <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token string">'pca__n_components'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">]</span>
<span class="token punctuation">&#125;</span>
search <span class="token operator">=</span> GridSearchCV<span class="token punctuation">(</span>pipe<span class="token punctuation">,</span> param_grid<span class="token punctuation">,</span> n_jobs<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> cv<span class="token operator">=</span>StratifiedKFold<span class="token punctuation">(</span>n_splits<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
search<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>Plot the PCA specturm.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">X_embed <span class="token operator">=</span> TfidfEmbeddingVectorizer<span class="token punctuation">(</span>w2v_model<span class="token punctuation">)</span><span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>
pca<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_embed<span class="token punctuation">)</span>

fig<span class="token punctuation">,</span> <span class="token punctuation">(</span>ax0<span class="token punctuation">,</span> ax1<span class="token punctuation">)</span> <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span>nrows<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> sharex<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
ax0<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> pca<span class="token punctuation">.</span>n_components_ <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
         pca<span class="token punctuation">.</span>explained_variance_ratio_<span class="token punctuation">,</span> <span class="token string">'+'</span><span class="token punctuation">,</span> linewidth<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
ax0<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'PCA explained variance ratio'</span><span class="token punctuation">)</span>
ax0<span class="token punctuation">.</span>axvline<span class="token punctuation">(</span>search<span class="token punctuation">.</span>best_estimator_<span class="token punctuation">.</span>named_steps<span class="token punctuation">[</span><span class="token string">'pca'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>n_components<span class="token punctuation">,</span>
            linestyle<span class="token operator">=</span><span class="token string">':'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'N Components Chosen'</span><span class="token punctuation">)</span>
ax0<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>prop<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token number">12</span><span class="token punctuation">)</span><span class="token punctuation">,</span> loc<span class="token operator">=</span><span class="token string">"upper right"</span><span class="token punctuation">)</span>
ax0<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># For each number of components, find the best classifier results</span>
results <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>search<span class="token punctuation">.</span>cv_results_<span class="token punctuation">)</span>
components_col <span class="token operator">=</span> <span class="token string">'param_pca__n_components'</span>
best_clfs <span class="token operator">=</span> results<span class="token punctuation">.</span>groupby<span class="token punctuation">(</span>components_col<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>
    <span class="token keyword">lambda</span> g<span class="token punctuation">:</span> g<span class="token punctuation">.</span>nlargest<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'mean_test_score'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
best_clfs<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token operator">=</span>components_col<span class="token punctuation">,</span> y<span class="token operator">=</span><span class="token string">'mean_test_score'</span><span class="token punctuation">,</span> yerr<span class="token operator">=</span><span class="token string">'std_test_score'</span><span class="token punctuation">,</span>
               legend<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> ax<span class="token operator">=</span>ax1<span class="token punctuation">)</span>
ax1<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'Classification accuracy (val)'</span><span class="token punctuation">)</span>
ax1<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">'N Components'</span><span class="token punctuation">)</span>
ax1<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">130</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<img src="/2021/01/25/2021-01-25-weighted-word-embedding/pca.png" class="">

<h1 id="Perfomance"><a href="#Perfomance" class="headerlink" title="Perfomance"></a>Perfomance</h1><p>Some algorithms favor simple averaging, some algorithms perform better with TF-IDF weighting. Let’s see what’s the best in this text classification task.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> seaborn <span class="token keyword">as</span> sns

plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>boxplot<span class="token punctuation">(</span><span class="token punctuation">[</span>c<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> c <span class="token keyword">in</span> cv_list<span class="token punctuation">]</span><span class="token punctuation">,</span> labels<span class="token operator">=</span><span class="token punctuation">[</span>c<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> c <span class="token keyword">in</span> cv_list<span class="token punctuation">]</span><span class="token punctuation">,</span> showmeans<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<img src="/2021/01/25/2021-01-25-weighted-word-embedding/performance.png" class="">

<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>Distributed representation of word is an interesting field that is actively studied. Furthermore, it can be applied to many downstream tasks and real-life application. I hope this article will help you understand the basic concept of word embedding. I have been posting information and tutorials on my <a target="_blank" rel="noopener" href="https://github.com/penguinwang96825">GitHub</a>, if you are interested in these fields, PLEASE FOLLOW ME!!!</p>
<h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><ol>
<li><a target="_blank" rel="noopener" href="https://www.kaggle.com/reiinakano/basic-nlp-bag-of-words-tf-idf-word2vec-lstm">https://www.kaggle.com/reiinakano/basic-nlp-bag-of-words-tf-idf-word2vec-lstm</a></li>
<li><a target="_blank" rel="noopener" href="http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/">http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/</a></li>
<li><a target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/">https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/</a></li>
<li><a target="_blank" rel="noopener" href="https://jonathan-hui.medium.com/nlp-word-embedding-glove-5e7f523999f6">https://jonathan-hui.medium.com/nlp-word-embedding-glove-5e7f523999f6</a></li>
</ol>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        Author:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">Yang Wang</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        Link:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://penguinwang96825.github.io/2021/01/25/2021-01-25-weighted-word-embedding/">https://penguinwang96825.github.io/2021/01/25/2021-01-25-weighted-word-embedding/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        Reprint policy:
                    </i>
                </span>
                <span class="reprint-info">
                    All articles in this blog are used except for special statements
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    reprint polocy. If reproduced, please indicate source
                    <a href="/about" target="_blank">Yang Wang</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>Copied successfully, please follow the reprint policy of this article</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">more</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/Python/">
                                    <span class="chip bg-color">Python</span>
                                </a>
                            
                                <a href="/tags/NLP/">
                                    <span class="chip bg-color">NLP</span>
                                </a>
                            
                                <a href="/tags/Embedding/">
                                    <span class="chip bg-color">Embedding</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;Previous</div>
            <div class="card">
                <a href="/2021/01/25/2021-01-25-simplest-way-to-build-web-crawler/">
                    <div class="card-image">
                        
                        <img src="https://github.com/penguinwang96825/penguinwang96825.github.io/blob/master/2021/01/25/2021-01-26-simplest-way-to-build-web-crawler/nhu-nguyen.jpg?raw=true" class="responsive-img" alt="Simplest way to Build Web Crawler">
                        
                        <span class="card-title">Simplest way to Build Web Crawler</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            A web crawler, sometimes called a spiderbot or scraper, is an internet bot that systematically browses the net. We can get the information we need without copy-paste. The goal of this article is to let you know how I scrape web and store it into database or csv file.
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2021-01-25
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Crawler/" class="post-category">
                                    Crawler
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Python/">
                        <span class="chip bg-color">Python</span>
                    </a>
                    
                    <a href="/tags/Crawler/">
                        <span class="chip bg-color">Crawler</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                Next&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2021/01/22/2021-01-22-train-word2vec-on-wsl/">
                    <div class="card-image">
                        
                        <img src="https://github.com/penguinwang96825/penguinwang96825.github.io/blob/master/2021/01/22/2021-01-22-train-word2vec-on-wsl/michael.jpg?raw=true" class="responsive-img" alt="Train Word2Vec Model on WSL">
                        
                        <span class="card-title">Train Word2Vec Model on WSL</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            In this article, I'm going to build my own pre-trained word embedding on WSL, which stands for Windows Subsystem for Linux, and it is a compatibility layer for running Linux binary executables (in ELF format) natively on Windows 10.. The reason why I train the model on Linux instead of Windows is that it's not user-freiendly to run C++ and some other packages on Windows.
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2021-01-22
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/NLP/" class="post-category">
                                    NLP
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Python/">
                        <span class="chip bg-color">Python</span>
                    </a>
                    
                    <a href="/tags/WSL/">
                        <span class="chip bg-color">WSL</span>
                    </a>
                    
                    <a href="/tags/Ubuntu/">
                        <span class="chip bg-color">Ubuntu</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + 'From: Yang&#39;s Blog<br />'
            + 'Author: Yang Wang<br />'
            + 'Link: <a href="' + url + '">' + url + '</a><br />'
            + 'The copyright of this article belongs to the author, please indicate the source of any form of reproduction.';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>


<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;TOC</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h1, h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

    
    <div class="container row center-align" style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2018-2021</span>
            
            <span id="year">2018</span>
            <a href="/about" target="_blank">Yang Wang</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">45.6k</span>&nbsp;字
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
                <span id="busuanzi_container_site_pv" style='display:none'>
                    <i class="fa fa-heart-o"></i>
                    本站总访问量 <span id="busuanzi_value_site_pv" class="white-color"></span>
                </span>
            
            
                <span id="busuanzi_container_site_uv" style='display:none'>
                    人次,&nbsp;访客数 <span id="busuanzi_value_site_uv" class="white-color"></span> 人.
                </span>
            
            <br>
            
            <span id="sitetime">载入运行时间...</span>
            <script>
                function siteTime() {
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2018";
                    var startMonth = "12";
                    var startDate = "3";
                    var startHour = "0";
                    var startMinute = "0";
                    var startSecond = "0";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffDays + " 天 " + diffHours +
                            " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffYears + " 年 " + diffDays +
                            " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/penguinwang96825" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:penguinwang@smail.nchu.edu.tw" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>













</div>
    </div>
</footer>

<div class="progress-bar"></div>

<script>
    $(document).ready(function () {

        var int = setInterval(fixCount, 50);  // 50ms周期检测函数
        var pvcountOffset = 80000;  // 初始化首次数据
        var uvcountOffset = 20000;

        function fixCount() {
            if (document.getElementById("busuanzi_container_site_pv").style.display != "none") {
                $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + pvcountOffset);
                clearInterval(int);
            }
            if ($("#busuanzi_container_site_pv").css("display") != "none") {
                $("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html()) + uvcountOffset); // 加上初始数据 
                clearInterval(int); // 停止检测
            }
        }
    });
</script>

<script language=javascript>
    function siteTime() {
        window.setTimeout("siteTime()", 1000);
        var seconds = 1000;
        var minutes = seconds * 60;
        var hours = minutes * 60;
        var days = hours * 24;
        var years = days * 365;
        var today = new Date();
        var todayYear = today.getFullYear();
        var todayMonth = today.getMonth() + 1;
        var todayDate = today.getDate();
        var todayHour = today.getHours();
        var todayMinute = today.getMinutes();
        var todaySecond = today.getSeconds();
        /* Date.UTC() -- 返回date对象距世界标准时间(UTC)1970年1月1日午夜之间的毫秒数(时间戳)
        year - 作为date对象的年份，为4位年份值
        month - 0-11之间的整数，做为date对象的月份
        day - 1-31之间的整数，做为date对象的天数
        hours - 0(午夜24点)-23之间的整数，做为date对象的小时数
        minutes - 0-59之间的整数，做为date对象的分钟数
        seconds - 0-59之间的整数，做为date对象的秒数
        microseconds - 0-999之间的整数，做为date对象的毫秒数 */
        var t1 = Date.UTC(2017, 09, 11, 00, 00, 00); //北京时间2018-2-13 00:00:00
        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
        var diff = t2 - t1;
        var diffYears = Math.floor(diff / years);
        var diffDays = Math.floor((diff / days) - diffYears * 365);
        var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
        var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) / minutes);
        var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours - diffMinutes * minutes) / seconds);
        document.getElementById("sitetime").innerHTML = "本站已运行 " +diffYears+" 年 "+diffDays + " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
    }/*因为建站时间还没有一年，就将之注释掉了。需要的可以取消*/
    siteTime();
</script>

    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;Search</span>
            <input type="search" id="searchInput" name="s" placeholder="Please enter a search keyword"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

	
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
